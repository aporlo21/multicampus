{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Python is an interpreted, high-level, general-purpose programming language.',\n",
       " \"Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\",\n",
       " 'Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.',\n",
       " '[27] Python is dynamically typed and garbage-collected.',\n",
       " 'It supports multiple programming paradigms, including procedural, object-oriented, and functional programming.',\n",
       " \"Python is often described as a 'batteries included' language due to its comprehensive standard library.\",\n",
       " '[28]']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import *\n",
    "from nltk.stem import *\n",
    "from konlpy.tag import Kkma\n",
    "from nltk.tokenize import *\n",
    "from nltk.tag import *\n",
    "import nltk\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras import *\n",
    "from keras.datasets import mnist\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "\n",
    "text=\"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.[27] Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is often described as a 'batteries included' language due to its comprehensive standard library.[28]\"\n",
    "text=sent_tokenize(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['python', 'interpreted', 'high-level', 'general-purpose', 'programming', 'language'], ['created', 'guido', 'van', 'rossum', 'first', 'released', '1991', 'python', 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'notable', 'use', 'significant', 'whitespace'], ['language', 'constructs', 'object-oriented', 'approach', 'aim', 'help', 'programmers', 'write', 'clear', 'logical', 'code', 'small', 'large-scale', 'projects'], ['python', 'dynamically', 'typed', 'garbage-collected'], ['supports', 'multiple', 'programming', 'paradigms', 'including', 'procedural', 'object-oriented', 'functional', 'programming'], ['python', 'often', 'described', \"'batteries\", 'included', 'language', 'due', 'comprehensive', 'standard', 'library'], []]\n"
     ]
    }
   ],
   "source": [
    "voc=Counter()\n",
    "sentences = []\n",
    "stop_words = stopwords.words('english')\n",
    "for i in text:\n",
    "    sentence=word_tokenize(i)\n",
    "    res = []\n",
    "    for word in sentence: \n",
    "        word=word.lower()\n",
    "        if word not in stop_words: \n",
    "            if len(word) > 2:\n",
    "                res.append(word)\n",
    "                voc[word]=voc[word]+1\n",
    "    sentences.append(res) \n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'python': 4,\n",
       "         'interpreted': 1,\n",
       "         'high-level': 1,\n",
       "         'general-purpose': 1,\n",
       "         'programming': 3,\n",
       "         'language': 3,\n",
       "         'created': 1,\n",
       "         'guido': 1,\n",
       "         'van': 1,\n",
       "         'rossum': 1,\n",
       "         'first': 1,\n",
       "         'released': 1,\n",
       "         '1991': 1,\n",
       "         'design': 1,\n",
       "         'philosophy': 1,\n",
       "         'emphasizes': 1,\n",
       "         'code': 2,\n",
       "         'readability': 1,\n",
       "         'notable': 1,\n",
       "         'use': 1,\n",
       "         'significant': 1,\n",
       "         'whitespace': 1,\n",
       "         'constructs': 1,\n",
       "         'object-oriented': 2,\n",
       "         'approach': 1,\n",
       "         'aim': 1,\n",
       "         'help': 1,\n",
       "         'programmers': 1,\n",
       "         'write': 1,\n",
       "         'clear': 1,\n",
       "         'logical': 1,\n",
       "         'small': 1,\n",
       "         'large-scale': 1,\n",
       "         'projects': 1,\n",
       "         'dynamically': 1,\n",
       "         'typed': 1,\n",
       "         'garbage-collected': 1,\n",
       "         'supports': 1,\n",
       "         'multiple': 1,\n",
       "         'paradigms': 1,\n",
       "         'including': 1,\n",
       "         'procedural': 1,\n",
       "         'functional': 1,\n",
       "         'often': 1,\n",
       "         'described': 1,\n",
       "         \"'batteries\": 1,\n",
       "         'included': 1,\n",
       "         'due': 1,\n",
       "         'comprehensive': 1,\n",
       "         'standard': 1,\n",
       "         'library': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': 1, 'programming': 2, 'language': 3, 'code': 4, 'object-oriented': 5}\n"
     ]
    }
   ],
   "source": [
    "# voc # 클래스 객체 . 딕셔너리 구조\n",
    "voc.items() # 객체 # 리스트구조 # 각각의 요소 참조, n번째 : 토큰 단어 N : 반도\n",
    "voc_sorted = sorted(voc.items(), key = lambda a:a[1], reverse=True) # 정렬완료\n",
    "voc_sorted\n",
    "# 빈도수가 2이상인 데이터 저장\n",
    "res={}\n",
    "i=0\n",
    "for (w,f) in voc_sorted:\n",
    "    if f>1:\n",
    "        i+=1\n",
    "        res[w] = i\n",
    "print(res)                \n",
    "# 번호는 특별한 의미 x, 인덱싱이다\n",
    "\n",
    "# 각각의 단어에 대해 오름차순 정렬완료 \n",
    "# 각각의 단어에 대해 내림차순 정렬완료 \n",
    "# 1번 인덱스에 있는 데이터 정렬하고자 할때 두번째 옵션 : key \n",
    "# a : a[1] # 정렬기준 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KERAS ModE 로 바꾸어 작업\n",
    "# 케라스 문자열 처리\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "tok = Tokenizer() # 객체생성\n",
    "tok.fit_on_texts(text)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'python': 2, 'is': 3, 'programming': 4, 'language': 5, 'its': 6, 'code': 7, 'object': 8, 'oriented': 9, 'to': 10, 'an': 11, 'interpreted': 12, 'high': 13, 'level': 14, 'general': 15, 'purpose': 16, 'created': 17, 'by': 18, 'guido': 19, 'van': 20, 'rossum': 21, 'first': 22, 'released': 23, 'in': 24, '1991': 25, \"python's\": 26, 'design': 27, 'philosophy': 28, 'emphasizes': 29, 'readability': 30, 'with': 31, 'notable': 32, 'use': 33, 'of': 34, 'significant': 35, 'whitespace': 36, 'constructs': 37, 'approach': 38, 'aim': 39, 'help': 40, 'programmers': 41, 'write': 42, 'clear': 43, 'logical': 44, 'for': 45, 'small': 46, 'large': 47, 'scale': 48, 'projects': 49, '27': 50, 'dynamically': 51, 'typed': 52, 'garbage': 53, 'collected': 54, 'it': 55, 'supports': 56, 'multiple': 57, 'paradigms': 58, 'including': 59, 'procedural': 60, 'functional': 61, 'often': 62, 'described': 63, 'as': 64, 'a': 65, \"'batteries\": 66, \"included'\": 67, 'due': 68, 'comprehensive': 69, 'standard': 70, 'library': 71, '28': 72}\n"
     ]
    }
   ],
   "source": [
    "print(tok.word_index)\n",
    "# 텍스트 fit \n",
    "# 단어 단위로 \n",
    "# 결국에는 정렬(빈도수) 하고 => 인덱싱이 들어감\n",
    "# 글자수제한은 안걸렷지만 내부작업진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('python', 3), ('is', 3), ('an', 1), ('interpreted', 1), ('high', 1), ('level', 1), ('general', 1), ('purpose', 1), ('programming', 3), ('language', 3), ('created', 1), ('by', 1), ('guido', 1), ('van', 1), ('rossum', 1), ('and', 5), ('first', 1), ('released', 1), ('in', 1), ('1991', 1), (\"python's\", 1), ('design', 1), ('philosophy', 1), ('emphasizes', 1), ('code', 2), ('readability', 1), ('with', 1), ('its', 3), ('notable', 1), ('use', 1), ('of', 1), ('significant', 1), ('whitespace', 1), ('constructs', 1), ('object', 2), ('oriented', 2), ('approach', 1), ('aim', 1), ('to', 2), ('help', 1), ('programmers', 1), ('write', 1), ('clear', 1), ('logical', 1), ('for', 1), ('small', 1), ('large', 1), ('scale', 1), ('projects', 1), ('27', 1), ('dynamically', 1), ('typed', 1), ('garbage', 1), ('collected', 1), ('it', 1), ('supports', 1), ('multiple', 1), ('paradigms', 1), ('including', 1), ('procedural', 1), ('functional', 1), ('often', 1), ('described', 1), ('as', 1), ('a', 1), (\"'batteries\", 1), (\"included'\", 1), ('due', 1), ('comprehensive', 1), ('standard', 1), ('library', 1), ('28', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(tok.word_counts) # 정렬(빈도수) # 리스트 # 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 11, 12, 13, 14, 15, 16, 4, 5], [17, 18, 19, 20, 21, 1, 22, 23, 24, 25, 26, 27, 28, 29, 7, 30, 31, 6, 32, 33, 34, 35, 36], [6, 5, 37, 1, 8, 9, 38, 39, 10, 40, 41, 42, 43, 44, 7, 45, 46, 1, 47, 48, 49], [50, 2, 3, 51, 52, 1, 53, 54], [55, 56, 57, 4, 58, 59, 60, 8, 9, 1, 61, 4], [2, 3, 62, 63, 64, 65, 66, 67, 5, 68, 10, 6, 69, 70, 71], [72]]\n"
     ]
    }
   ],
   "source": [
    "print(tok.texts_to_sequences(text)) # 인덱스순서대로 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### keras 관련함수 ####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'interpreted',\n",
       " 'high',\n",
       " 'level',\n",
       " 'general',\n",
       " 'purpose',\n",
       " 'created',\n",
       " 'by',\n",
       " 'guido',\n",
       " 'van',\n",
       " 'rossum',\n",
       " 'first',\n",
       " 'released',\n",
       " 'in',\n",
       " '1991',\n",
       " \"python's\",\n",
       " 'design',\n",
       " 'philosophy',\n",
       " 'emphasizes',\n",
       " 'readability',\n",
       " 'with',\n",
       " 'notable',\n",
       " 'use',\n",
       " 'of',\n",
       " 'significant',\n",
       " 'whitespace',\n",
       " 'constructs',\n",
       " 'approach',\n",
       " 'aim',\n",
       " 'help',\n",
       " 'programmers',\n",
       " 'write',\n",
       " 'clear',\n",
       " 'logical',\n",
       " 'for',\n",
       " 'small',\n",
       " 'large',\n",
       " 'scale',\n",
       " 'projects',\n",
       " '27',\n",
       " 'dynamically',\n",
       " 'typed',\n",
       " 'garbage',\n",
       " 'collected',\n",
       " 'it',\n",
       " 'supports',\n",
       " 'multiple',\n",
       " 'paradigms',\n",
       " 'including',\n",
       " 'procedural',\n",
       " 'functional',\n",
       " 'often',\n",
       " 'described',\n",
       " 'as',\n",
       " 'a',\n",
       " \"'batteries\",\n",
       " \"included'\",\n",
       " 'due',\n",
       " 'comprehensive',\n",
       " 'standard',\n",
       " 'library',\n",
       " '28']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tok.word_counts.items() # 리스트내 요소 내장\n",
    "\n",
    "# 내 연습\n",
    "# words_freq = {}\n",
    "# # 빈도수가 2보다 작은 단어들을 저장\n",
    "# for token not in tokens:\n",
    "#     if token < 2:\n",
    "        \n",
    "words_freq = [ w for w,c in tok.word_counts.items() if c < 2] # 단어, 빈도수  // 단어만 추출돼\n",
    "words_freq\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'an'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-13deba05b515>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#     print(tok.word_index[w]) # 각 단어 인덱스\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     print(tok.word_counts[w]) # 각단어 빈도수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mdel\u001b[0m \u001b[0mtok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 각 단어 인덱스\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mtok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 각단어 빈도수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# 빈도수가 1 미만인거 빠진다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'an'"
     ]
    }
   ],
   "source": [
    "# 케라스 제공함수 # 도서 내 ) 케라스 문자열 처리쪽 단원 \n",
    "for w in words_freq:\n",
    "#     print(tok.word_index[w]) # 각 단어 인덱스 \n",
    "#     print(tok.word_counts[w]) # 각단어 빈도수 \n",
    "    del tok.word_index[w] # 각 단어 인덱스 \n",
    "    del tok.word_counts[w] # 각단어 빈도수 \n",
    "    # 빈도수가 1 미만인거 빠진다\n",
    "print(tok.texts_to_sequences(text)) # 각단어들에 대한 인덱스가 나오는함수\n",
    "# 빈도수가 1미만인거 뺀 집단에 대해서 출력 ( 인덱스 가 나옴 )\n",
    "print('*'*84)\n",
    "print(tok.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('java', 3), ('ds', 2)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk 유용 클래스 \n",
    "# frequency _ 각각의 토근이 몇개냐 확인 함수\n",
    "words=['java', 'python', 'ds', 'ds', 'java', 'java']\n",
    "# 각각의 단어들에 대해 몇 번반복됬는지 확인\n",
    "from nltk import FreqDist\n",
    "fd = FreqDist(words)\n",
    "fd.N()  # N() 함수 \n",
    "# 전체 단어가 몇개 있느냐\n",
    "fd.freq('java') # 전체단어중 해당단어 나올 확률 ( % ) 도출\n",
    "fd.freq('ds')\n",
    "fd['ds'] # 해당단어 출현 빈도수 \n",
    "fd.most_common(2) # 가장 빈도수가 높은 2개 단어 추출 # 리스트형식으로 나누어 반환됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['나', '는', '자연어', '처리', '를', '공부', '하고', '있습니다']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one - hot incoding \n",
    "# text에 대해서 인코딩\n",
    "from konlpy.tag import Okt # 대문자로 시작하는 건 _ 클래스 Okt_Twitter\n",
    "okt = Okt()\n",
    "tok = okt.morphs('나는 자연어 처리를 공부하고 있습니다')\n",
    "tok\n",
    "# 형태소 단위 분리\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '공부': 5, '하고': 6, '있습니다': 7}\n"
     ]
    }
   ],
   "source": [
    "# 각각의 형태소 별로 인덱싱\n",
    "word2ldx={}\n",
    "for t in tok:\n",
    "    if t not in word2ldx.keys():\n",
    "        word2ldx[t] = len(word2ldx) # 저장된요소 갯수 \n",
    "print(word2ldx)\n",
    "\n",
    "# 만약에 내가 구문을 인덱스가 \n",
    "# 각 단어별로 인덱싱 부여하여 \n",
    "# 나 key \n",
    "# 인덱스에 대해서 원핫안코당해줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2Idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-934567e94db8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mohv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mohe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'공부'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2Idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 출력 00000100  # 이중하나 만 1을 반환한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# 위치가 1로변한다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word2Idx' is not defined"
     ]
    }
   ],
   "source": [
    "# def ohe(w, word2Idx):\n",
    "#     one_hot_vector = [0]*( len(word2Idx) )\n",
    "#     index = word2Idx[w]\n",
    "#     one_hot_vector[index] = 1\n",
    "#     return one_hot_vector\n",
    "def ohe(w, word2Idx):\n",
    "    ohv = [0]*len(word2Idx)\n",
    "    #     ohv = [0] * 8\n",
    "    p = word2Idx[w]\n",
    "    ohv[p] = 1\n",
    "    return ohv\n",
    "\n",
    "print(ohe('공부', word2Idx)) # 출력 00000100  # 이중하나 만 1을 반환한다 \n",
    "\n",
    "# 위치가 1로변한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '오늘 메뉴는 뼈다귀 해장국입니다. 맛있게 먹어요. 국산이래요. 뼈다귀 최고 뼈다귀 최고'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'뼈다귀': 1,\n",
       " '최고': 2,\n",
       " '오늘': 3,\n",
       " '메뉴는': 4,\n",
       " '해장국입니다': 5,\n",
       " '맛있게': 6,\n",
       " '먹어요': 7,\n",
       " '국산이래요': 8}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras_preprocessing.text import Tokenizer\n",
    "tok = Tokenizer()\n",
    "tok.fit_on_texts([text])\n",
    "tok.word_counts\n",
    "tok.word_index # 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = '뼈다귀 관련 음식을 가장 맛있게 먹어요'\n",
    "res = tok.texts_to_sequences([text2]) # 뼈다귀 - 1번인덱스\n",
    "res[0] # 2차원 # 안쪽 list 참조 [0]\n",
    "res[0][0] # 요소하나 참조\n",
    "# 관련 단어 위주 # corpus # 인덱싱 표현 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 -> 01000000\n",
    "# 6 -> 00000010\n",
    "vLen = len(tok.word_index)\n",
    "from keras.utils import to_categorical # keras ohe 함수\n",
    "pres = to_categorical(res, num_classes=vLen+1) # 클래스 개수 vLen \n",
    "# 뼈다귀 text는 0번 인덱스없으므로 강제로 1을더해 인덱싱을 맞춰주고 ohe한다\n",
    "pres \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ohe 문제점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe 문제점\n",
    "# 1) 음식, 식사, 점심, 날씨 => ohe => 크기 ( 숮자네자리씩 ) => size : 4\n",
    "# 연관성이 전혀없다\n",
    "# 각각의 벡터가 해당단어의 축이된다 { 음식 축, 식사 축. 점심 축, 날씨 축 } 제각각이다\n",
    "# => 단어들간의 유사한정도 파악할수 없다#\n",
    "\n",
    "# 2) 공간을 많이 차지\n",
    "# 메모리 낭비가 심하다 => sparsity -> dense matrix 변환필요 (=차원축소하겠다)\n",
    "\n",
    "# 3) 연관검색어 표현이 어려움 \n",
    "# ex) 뼈다귀 = '뼈다귀 해장국''뼈다귀 국물''뼈다귀 감자탕'\n",
    "\n",
    "# 문제점해결을위한 수많은 노력\n",
    "# 1) LSA : 카운트 기반으로 단어의 의미를 벡터화하는 알고리즘 // 단어의 개수가 몇개인지\n",
    "# 2) Word2Vec : 단어를 벡터공간으로 표현 (거리계산 단어들간의미이해)  \n",
    "# 3) Seq2Seq, RNNLM ,,,, (RNN 기반)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언어모델 ( 자연어 처리 분야 널리 사용 )\n",
    "# : 기계가 사람들이 일상 언어를 이해하고 의미를 파악할수 있게하는것\n",
    "# 언어모델을 만든다 : 기계가 이해할수 있게하려면, 모든언어를 다알고있어야한다\n",
    "# 어떤말이든 이해해야함\n",
    "# vocabulary : 단어사전 |=>| 기계가 학습한 단어의 집합\n",
    "\n",
    "# __OVV__기계가 학습안한 단어들 = out of voca ( OVV ) 가 모델성능에 중요하다 \n",
    "\n",
    "# ex) 등벼다귀 _ revenshutain algorithsm\n",
    "# revenshutain algorithsm # text 관련 접근 알고리즘 \n",
    "# ngram (dgram, trigram) : 문맥의 의미를 파악한후 단어의미를 유추\n",
    "# 유사 단어를 벡터공간내에서 찾는디 \n",
    "# Word2Vec : 단어를 벡터공간으로 표현 (거리계산 단어들간의미이해)  \n",
    "\n",
    "# => BPE, WPM 알고리즘 ( 데이터 전처리 필수 )\n",
    "# corpus : 관심갖는 도메인의 단어들의 집합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPE : 연속으로 가장많이 등장한 글지의 쌍 => 한글자로 표현\n",
    "# ___ (aa) OR (ab) # 변환\n",
    "# 문자열 : aaabadaaabac\n",
    "# Z = aa\n",
    "# 문자열 : ZabadZabac\n",
    "# Y = ab # (ab) OR (Za)\n",
    "# 문자열 : ZYadZYac\n",
    "# X = ZY\n",
    "# 문자열 : XadXac\n",
    "# W = Xa    \n",
    "# 문자열 : WdWc\n",
    "# => 압축완료\n",
    "# but the issue is 압축해제시 위 코드 과정이 저장되어져있어야한다는 비효율성 지님\n",
    "\n",
    "# 허프만 인코딩 ( 트리 ) 효율짱좋음 \n",
    "\n",
    "# {'low </w>' : 5 (빈도수), 'lower </w>' : 2}\n",
    "# dic exprain ) train data 등장 단어 and 단어출현빈도수 \n",
    "# 원소개수 = voca size \n",
    "# 다른단어등장시 문제 OVV 에 대한 처리능력\n",
    "\n",
    "# BPE => 00V 에 대한 문제점 해결\n",
    "\n",
    "# 문자열 처리 알고리즘 _ KMP 보이어무어 레벤슈타인거리 (검색)\n",
    "\n",
    "# 1) 모든 단어들을 글자로 분리\n",
    "# { 'l o w' : 5 (빈도수), 'l o w e r' : 2,  # 딕셔너리 초기상태\n",
    "# 'newest' : 6, 'widest' : 3 }\n",
    "# -> 글자단위로 나눠\n",
    "# => l,o,w,e,r,n,w,s,t,i,d 글자단위 분리\n",
    "\n",
    "# 2) 빈도가 가장높은 문자들의 쌍을 검색\n",
    "# => es가 가장 많이 등장 ( 9 ) => es를 묶음 6 + 3\n",
    "# { 'low' : 5 (빈도수), 'lower' : 2, \n",
    "# 'n e w es t' : 6, 'w i d es t' : 3 }\n",
    "\n",
    "# 3) => es t 가장 많이등장 ( 9 ) => est를 묶음  #번거로울수잇따\n",
    "# 따로 저장한다 \n",
    "# => l,o,w,e,r,n,w,s,t,i,d, (+ es), (+ est) 글자단위 분리\n",
    "\n",
    "# 4) lo 가 가장 많이등장 ( 9 ) => lo 를 묶음\n",
    "# { 'lo w' : 5, 'lo w e r' }\n",
    "\n",
    "# 5) 과정을 반복 ( 10 번 )\n",
    "# 1. 원래 lowest => OOV 인데, 추가된 딕셔너리에서 찾는다 \n",
    "# 2. lowest 단어를 글자로 나눈다. ( 6글자 )\n",
    "#  좌 우 측끝부터 해석하기 위함 목적 ... 접두 접미어의 의미근간... 중간부터 시작 x \n",
    "\n",
    "# 6) 최다 빈출단어부터 탐색, 구간화\n",
    "# 9 - > es, est\n",
    "# 7 - > lo, low\n",
    "# 6 -> ne, new, newest\n",
    "# 3 -> wi, wid, widest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. BPE 알고리즘 구현 ( 연습문제 )\n",
    "# 2. 상품분류 ( 10 가지 _ ) 미니 프로젝트\n",
    "# 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "fasion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fasion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape \n",
    "train_labels.shape\n",
    "# test_images.shape\n",
    "# test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b200cc1160>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.imshow(train_images[512], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 상품분류 ( 10 가지 _ ) 미니 프로젝트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-96da76d4a700>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
