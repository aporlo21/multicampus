{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57087022/how-can-i-iterate-through-a-list\n",
      "How can I iterate through a list?\n",
      "\n",
      "\n",
      "I'm super new to Python, \n",
      "I want to do a simple loop that iterates through a list which has the name of the months: \n",
      "I tried For loops like:\n",
      "months=[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
      "Max=[]\n",
      "hours=[]\n",
      "for m in months:\n",
      "    time=m.count()/96  # when it goes to \"Jan\" it has 2976 elements\n",
      "    for i in range(1,int(time)+1): \n",
      "        a=Rdata.m[Rdata.m['Day'] == i].dem.max() # Rdata.Jan is a df which has columsn Day and dem\n",
      "        b=Rdata.m.loc[Rdata.m['dem']== a,'Time']\n",
      "     Max.append(a)\n",
      "     hours.append(b)\n",
      "\n",
      "Just to add more information\n",
      "I created a list :\n",
      "month= (Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec)\n",
      "\n",
      "in which\n",
      "Jan = Series which contains  2976 elements\n",
      "\n",
      "And I keep getting the error \"count() takes at least 1 argument (0 given)\"\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086997/flask-can-i-whitelist-a-api-to-exceed-the-limit-of-max-content-length\n",
      "Flask: Can I whitelist a API to exceed the limit of MAX_CONTENT_LENGTH?\n",
      "\n",
      "\n",
      "Most API should be limit size <= 16MB, which is configured by MAX_CONTENT_LENGTH.\n",
      "But there's a API (POST /api/upload/backups), which allows inner admins upload backup files exceeds 160MB.\n",
      "I don't want to update MAX_CONTENT_LENGTH to 160MB and set app.before_request for most APIs. \n",
      "So can I whitelist the API(POST /api/upload/backups ) to exceeds the limit of MAX_CONTENT_LENGTH ?\n",
      "And How?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086991/how-to-import-3d-data-like-obj-or-3d-dxf-formats-in-qgis\n",
      "how to import 3d data (like .obj or 3d dxf) formats in QGIS\n",
      "\n",
      "\n",
      "I have a 3d file with .obj and 3d dxf format and I want to show it in UBUNTU QGIS3.4. In fact I want to show 3d Rasters in QGIS. The formats that I have are Autodesk 3D Max exporting format. Please help me with this.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086936/how-to-trace-curvy-lines-in-an-image-in-python\n",
      "How to trace curvy lines in an image in Python?\n",
      "\n",
      "\n",
      "I'm trying to trace a few curvy lines (vessels) in a retina image. The vessels are very clear in the image, so I thought this would be very straight forward, but I'm having a hard time figuring this out. Here is a link to the actual image:\n",
      "https://drive.google.com/open?id=1cRTk37U7LSeaV6rhvg0K6FKYsnDhlQZr\n",
      " \n",
      "And I'm looking for the following tracing. Also would like to have that red tracing in a separate file:\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086935/is-there-any-elegant-way-to-define-a-dataframe-with-column-of-dtype-array\n",
      "Is there any elegant way to define a dataframe with column of dtype array?\n",
      "\n",
      "\n",
      "I want to process stock level-2 data in pandas. Suppose there are four kinds data in each row for simplicity:\n",
      "\n",
      "millis: timestamp, int64 \n",
      "last_price: the last trade price, float64,\n",
      "ask_queue: the volume of ask side, a fixed size (200) array of int32\n",
      "bid_queue: the volume of bid side, a fixed size (200) array of int32\n",
      "\n",
      "Which can be easily defined as a structured dtype in numpy:\n",
      "dtype = np.dtype([\n",
      "   ('millis', 'int64'), \n",
      "   ('last_price', 'float64'), \n",
      "   ('ask_queue', ('int32', 200)), \n",
      "   ('bid_queue', ('int32', 200))\n",
      "])\n",
      "\n",
      "And in that way, I can access the ask_queue and bid_queue like:\n",
      "In [17]: data = np.random.randint(0, 100, 1616 * 5).view(dtype)\n",
      "\n",
      "% compute the average of ask_queue level 5 ~ 10\n",
      "In [18]: data['ask_queue'][:, 5:10].mean(axis=1)  \n",
      "Out[18]: \n",
      "array([33.2, 51. , 54.6, 53.4, 15. , 37.8, 29.6, 58.6, 32.2, 51.6, 34.4,\n",
      "       43.2, 58.4, 26.8, 54. , 59.4, 58.8, 38.8, 35.2, 71.2])\n",
      "\n",
      "My question is how to define a DataFrame include the data?\n",
      "There are two solutions here:\n",
      "A. set the ask_queue and bid_queue as two columns with array values as following:\n",
      "In [5]: df = pd.DataFrame(data.tolist(), columns=data.dtype.names)\n",
      "\n",
      "In [6]: df.dtypes\n",
      "Out[6]: \n",
      "millis          int64\n",
      "last_price    float64\n",
      "ask_queue      object\n",
      "bid_queue      object\n",
      "dtype: object\n",
      "\n",
      "However, there at least two problems in this solution:\n",
      "\n",
      "The ask_queue and bid_queue lost the dtype of 2D array and all\n",
      "the convenient methods; \n",
      "Performance, since it become a array of objects rather than a 2D\n",
      "array.\n",
      "\n",
      "B. flatten the ask_queue and bid_quene to 2 * 200 columns:\n",
      "In [8]: ntype = np.dtype([('millis', 'int64'), ('last_price', 'float64')] + \n",
      "   ...:                  [(f'{name}{i}', 'int32') for name in ['ask', 'bid'] for i in range(200)])\n",
      "\n",
      "In [9]: df = pd.DataFrame.from_records(data.view(ntype))\n",
      "\n",
      "In [10]: df.dtypes\n",
      "Out[10]: \n",
      "millis          int64\n",
      "last_price    float64\n",
      "ask0            int32\n",
      "ask1            int32\n",
      "ask2            int32\n",
      "ask3            int32\n",
      "ask4            int32\n",
      "ask5            int32\n",
      "...\n",
      "\n",
      "It's better than solution A. But the 2 * 200 columns looks redundant.\n",
      "Is there any solution can take the advantage as the structured dtype in numpy?\n",
      "I wonder if the ExtensionArray or `ExtensionDtype' can solve this.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086910/im-having-an-issue-parsing-an-xml-string-with-python\n",
      "I'm having an issue parsing an XML string with Python\n",
      "\n",
      "\n",
      "I'm having trouble parsing an xml table using python. I'm new to parsing these types of files. I'm currently using the ElementTree library. Id like to grab specific attributes for each row of the \"UsedPartTab\" table using a for loop. More specifically I'd like to assign the following attributes to a variable...PartNo, UsedQty, InvoiceNo. What would be the best way for me to go about doing this?\n",
      "I've tried indexing the specific tag within the root document with no success. I've also tried the findall, find, and get methods.\n",
      "    def GetPartsUsedList():\n",
      "        request = GET_TICKET_INFO\n",
      "        response = requests.post(url=GSPN_URL, verify=False, proxies=proxies, headers={\"content-type\": \"text/xml;charset=UTF-8\", \"SOAPAction\": '\"www.samsungasc.com/GetTicketInfo\"'}, data=request)\n",
      "        xml = ET.fromstring(response.text)\n",
      "        root = xml[0][0][0]\n",
      "        print(root.text)\n",
      "\n",
      "GetPartsUsedList()\n",
      "\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n",
      "<rootdoc>\n",
      "    <RetCode>0</RetCode>\n",
      "    <ErrMsg></ErrMsg>\n",
      "    <Carrier></Carrier>\n",
      "    <CarrierName></CarrierName>\n",
      "    <TicketNo>4149142579</TicketNo>\n",
      "    <SCode1>01</SCode1>\n",
      "    <SCode2></SCode2>\n",
      "    <SCode3></SCode3>\n",
      "    <SCode4>XC</SCode4>\n",
      "    <IrisDefectCode>ARCS</IrisDefectCode>\n",
      "    <IrisRepairCode>DPRT</IrisRepairCode>\n",
      "    <AlertMessage></AlertMessage>\n",
      "    <HighRisk></HighRisk>\n",
      "    <Table>\n",
      "        <Name>UsedPartTab</Name>\n",
      "        <Column>\n",
      "            <Name>SeqNo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>PartStatus</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>PartNo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>Description</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>Location</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>UsedQty</Name>\n",
      "            <Type>Decimal</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>RequestNo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>PONo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>SONo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>InvoiceNo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>InvoiceItemNo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>DefectSerialNo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>POStatus</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>TrackingNo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>TrackingHyperLink</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>PostGoodsIssue</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <ROW>\n",
      "            <SeqNo>0001</SeqNo>\n",
      "            <PartStatus>Used</PartStatus>\n",
      "            <PartNo>0M75P-21-ESGN</PartNo>\n",
      "            <Description></Description>\n",
      "            <Location></Location>\n",
      "            <UsedQty>1</UsedQty>\n",
      "            <RequestNo></RequestNo>\n",
      "            <PONo></PONo>\n",
      "            <SONo></SONo>\n",
      "            <InvoiceNo></InvoiceNo>\n",
      "            <InvoiceItemNo>0</InvoiceItemNo>\n",
      "            <DefectSerialNo></DefectSerialNo>\n",
      "            <POStatus></POStatus>\n",
      "            <TrackingNo></TrackingNo>\n",
      "            <TrackingHyperLink></TrackingHyperLink>\n",
      "            <PostGoodsIssue>N</PostGoodsIssue>\n",
      "        </ROW>\n",
      "        <ROW>\n",
      "            <SeqNo>0002</SeqNo>\n",
      "            <PartStatus>Used</PartStatus>\n",
      "            <PartNo>DE26-00126B</PartNo>\n",
      "            <Description>TRANS H.V;SHV-U1870D,120V,2545,2385V/3.4</Description>\n",
      "            <Location></Location>\n",
      "            <UsedQty>1</UsedQty>\n",
      "            <RequestNo></RequestNo>\n",
      "            <PONo></PONo>\n",
      "            <SONo></SONo>\n",
      "            <InvoiceNo>8424097053</InvoiceNo>\n",
      "            <InvoiceItemNo>0</InvoiceItemNo>\n",
      "            <DefectSerialNo></DefectSerialNo>\n",
      "            <POStatus></POStatus>\n",
      "            <TrackingNo></TrackingNo>\n",
      "            <TrackingHyperLink></TrackingHyperLink>\n",
      "            <PostGoodsIssue>P</PostGoodsIssue>\n",
      "        </ROW>\n",
      "        <ROW>\n",
      "            <SeqNo>0003</SeqNo>\n",
      "            <PartStatus>Used</PartStatus>\n",
      "            <PartNo>DE60-20066A</PartNo>\n",
      "            <Description>BOLT-FLAT;MSWR,L100,UNF1/4</Description>\n",
      "            <Location></Location>\n",
      "            <UsedQty>1</UsedQty>\n",
      "            <RequestNo></RequestNo>\n",
      "            <PONo></PONo>\n",
      "            <SONo></SONo>\n",
      "            <InvoiceNo>8456512557</InvoiceNo>\n",
      "            <InvoiceItemNo>0</InvoiceItemNo>\n",
      "            <DefectSerialNo></DefectSerialNo>\n",
      "            <POStatus></POStatus>\n",
      "            <TrackingNo></TrackingNo>\n",
      "            <TrackingHyperLink></TrackingHyperLink>\n",
      "            <PostGoodsIssue>P</PostGoodsIssue>\n",
      "        </ROW>\n",
      "        <ROW>\n",
      "            <SeqNo>0004</SeqNo>\n",
      "            <PartStatus>Used</PartStatus>\n",
      "            <PartNo>DE94-03275A</PartNo>\n",
      "            <Description>ASSY PANEL OUTER;MD4,BLACK,P/OUTER+ASSY-</Description>\n",
      "            <Location></Location>\n",
      "            <UsedQty>1</UsedQty>\n",
      "            <RequestNo></RequestNo>\n",
      "            <PONo></PONo>\n",
      "            <SONo></SONo>\n",
      "            <InvoiceNo>8456512595</InvoiceNo>\n",
      "            <InvoiceItemNo>0</InvoiceItemNo>\n",
      "            <DefectSerialNo></DefectSerialNo>\n",
      "            <POStatus></POStatus>\n",
      "            <TrackingNo></TrackingNo>\n",
      "            <TrackingHyperLink></TrackingHyperLink>\n",
      "            <PostGoodsIssue>P</PostGoodsIssue>\n",
      "        </ROW>\n",
      "        <ROW>\n",
      "            <SeqNo>0005</SeqNo>\n",
      "            <PartStatus>Used</PartStatus>\n",
      "            <PartNo>DE96-00269A</PartNo>\n",
      "            <Description>ASSY HVC;SMH7175,-,-,0.91UF HVC,-,-</Description>\n",
      "            <Location></Location>\n",
      "            <UsedQty>1</UsedQty>\n",
      "            <RequestNo></RequestNo>\n",
      "            <PONo></PONo>\n",
      "            <SONo></SONo>\n",
      "            <InvoiceNo>8456090576</InvoiceNo>\n",
      "            <InvoiceItemNo>0</InvoiceItemNo>\n",
      "            <DefectSerialNo></DefectSerialNo>\n",
      "            <POStatus></POStatus>\n",
      "            <TrackingNo></TrackingNo>\n",
      "            <TrackingHyperLink></TrackingHyperLink>\n",
      "            <PostGoodsIssue>P</PostGoodsIssue>\n",
      "        </ROW>\n",
      "    </Table>\n",
      "    <Table>\n",
      "        <Name>RecommendedPartTab</Name>\n",
      "        <Column>\n",
      "            <Name>PartNo</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>Description</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "        <Column>\n",
      "            <Name>Comments</Name>\n",
      "            <Type>String</Type>\n",
      "        </Column>\n",
      "    </Table>\n",
      "\n",
      "Answer\n",
      "\n",
      "You can try like this\n",
      "import xml.etree.ElementTree as ET\n",
      "tree = ET.parse('./sample2.xml')\n",
      "root = tree.getroot()\n",
      "for table in root.findall('Table'):\n",
      "    if table.find('Name').text == 'UsedPartTab':\n",
      "        for child in table.findall('Column'):\n",
      "            print (child.find('Name').text)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086905/for-loop-for-bokeh-in-databricks\n",
      "For loop for bokeh in databricks\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi i would like to loop through for loop eg. few times code below to get few times the same graph in one databricks cell:\n",
      "I imported library:\n",
      "from bokeh.plotting import figure\n",
      "from bokeh.embed import components, file_html\n",
      "from bokeh.resources import CDN\n",
      "\n",
      "x = [1, 2, 3, 4, 5]\n",
      "y = [6, 7, 2, 4, 5]\n",
      "\n",
      "p = figure(title='test', x_axis_label = 'x values', y_axis_label='y values')\n",
      "p.line(x,y, line_width =2)\n",
      "html = file_html(p,CDN,'plot')\n",
      "displayHTML(html)\n",
      "\n",
      "I was trying to use for loop but still i am obtaining only one single graph in a cell. \n",
      "Could you help me with the syntax for for loop to get it multiple times?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086900/how-to-create-an-independent-transaction-or-separate-session-in-flask-to-log-m\n",
      "How to create an independent transaction (or separate session) in flask to log messages in db\n",
      "\n",
      "\n",
      "I am trying to log statements in flask application while an API call is in process. I want to log statements directly to DB. The problem is that I have db session commits and rollbacks everywhere. I want to log statements irrespective of the API call session\n",
      "For instance\n",
      "new_log = Log()\n",
      "db.session.add(new_log)\n",
      "...\n",
      "if some logic:\n",
      "   db.session.rollback()\n",
      "else:\n",
      "   db.session.commit()\n",
      "\n",
      "In the above code I want new_log to be committed irrespective of \"some logic\"\n",
      "I have tried (and it seems that I was successful) to create a separate db session in my main app file using\n",
      "db = SQLAlchemy(app)\n",
      "logger_db = SQLAlchemy(app)\n",
      "\n",
      "Now my code looks like\n",
      "new_log = Log()\n",
      "logger_db.session.add(new_log)\n",
      "logger_db.session.commit()\n",
      "...\n",
      "if some logic:\n",
      "   db.session.rollback()\n",
      "else:\n",
      "   db.session.commit()\n",
      "\n",
      "This seems to be working. But I wanted to know if there is an alternative better solution for the same. Also if anyone can point out cases in which this solution won't work, it would be great.\n",
      "P.S.: I would be using logging everywhere in the application, so I am a bit worried about performance as well. Also I know that I can log into a file as well but for now, I would like to stick to db approach only\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086892/newspaper3k-library-scraping-behind-paywalls\n",
      "Newspaper3k Library - scraping behind paywalls\n",
      "\n",
      "\n",
      "Is there a way to use the Newspaper3k library to scrape behind paywalls if you have a subscription? \n",
      "As we don't have direct access to the URL request method, I'm not sure how we can, for example, pass in a session cookie. Is there any way, maybe better, to do this?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086884/how-to-use-python-code-in-android-studio-app\n",
      "How to use python code in Android Studio app\n",
      "\n",
      "\n",
      "I have some python code and I want to use it in my Android Studio app as a module. How I can use it ?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086868/how-to-append-2-numpy-image-arrays-with-different-dimensions-and-shapes-using-nu\n",
      "How to append 2 numpy Image Arrays with different dimensions and shapes using numpy\n",
      "\n",
      "\n",
      "I am making an input dataset which will have couple of thousands of images which all don't have same sizes but have same number of channels. I need to make these different images into one stack.\n",
      "orders = (channels, size, size)\n",
      "Image sizes = (3,240,270), (3,100,170), etc\n",
      "I have tried appending it to axis of 0 and one and inserting too.\n",
      "Images = append(Images, image, axis = 0)\n",
      "\n",
      "\n",
      "  File \"d:/Python/advanced3DFacePointDetection/train.py\", line 25, in <module>\n",
      "    Images = np.append(Images, item, axis=0)\n",
      "  File \"C:\\Users\\NIK\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\function_base.py\", line 4694, in append\n",
      "    return concatenate((arr, values), axis=axis)\n",
      "ValueError: all the input array dimensions except for the concatenation axis must match exactly\n",
      "\n",
      "Ideal output shape is like (number of images, 3) 3 for number of channels and it contains different shapes of images after that.\n",
      "\n",
      "Answer\n",
      "\n",
      "If you don't want to resize the image, choose the biggest one and padding all picture become same shape with it, i used to answer how to pad in this question: Can we resize an image from 64x64 to 256x256 without increasing the size\n",
      ".\n",
      "When run that script in loop for all your image, create a list to save all their shape. When you want to take the original image, just take image at index x in your array and shape x in your list then crop padding image with original size.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086853/how-to-get-combinations-of-an-array-with-condition-that-there-are-at-least-4-of\n",
      "How to get combinations of an array with condition that there are at-least 4 of each type of element (or x of each type)?\n",
      "\n",
      "\n",
      "I am trying to write a python function to get all combinations of length n of an input array where there are at-least 4 (or certain # x ) of each type of specific element (example below)\n",
      "input = ['m1','m2','m3','m4','m5','m6','t1','t2','t3','t4','t5','t6','w1','w2','w3','w4','w5','w6']\n",
      "\n",
      "output = list of combinations where there are atleast 4 of every type of element (i.e. 4 for each day of the week IF those elements are present at all (if 0, doesnt matter))\n",
      "for combination in itertools.combinations(input_array, 12):\n",
      "For example from the input array, a valid output for n=12 would below\n",
      "out = ['m1','m2','m3','m4,','t3','t4,'t5','t6','w1','w2','w3','w4']\n",
      "\n",
      "while an invalid output that it generates would be \n",
      "out = ['m1','m2','m3','t2','t3','t4,'t5','t6','w1','w2','w3','w4']\n",
      "\n",
      "Is there a more efficient way of generating combinations where there are atleast 4 of every type (i.e. 4 entries with 'm', 4 entries with 't', 4 entries with 'w'). Right now I simply loop through all combinations as \n",
      "it comes and if it passes that check I put it into an array, but with larger input arrays this can take a very long time. If there is another method other than combinations that would also work.\n",
      "\n",
      "Answer\n",
      "\n",
      "You can use recursion with a generator:\n",
      "import re\n",
      "data = ['m1','m2','m3','m4','m5','m6','t1','t2','t3','t4','t5','t6','w1','w2','w3','w4','w5','w6']\n",
      "def combo(d, c = []):\n",
      "  if len(c) == 12:\n",
      "     yield c\n",
      "  else:\n",
      "     for i in d:\n",
      "        if i not in c and sum(re.findall('^[a-zA-Z]+', j)[0] == re.findall('^[a-zA-Z]+', i)[0] for j in c+[i]) <= 4:\n",
      "          yield from combo(d, c+[i])\n",
      "\n",
      "result = combo(data)\n",
      "for _ in range(10): #first 10 results from generator\n",
      "  print(next(result))\n",
      "\n",
      "Output:\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w3', 'w4']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w3', 'w5']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w3', 'w6']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w4', 'w3']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w4', 'w5']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w4', 'w6']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w5', 'w3']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w5', 'w4']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w5', 'w6']\n",
      "['m1', 'm2', 'm3', 'm4', 't1', 't2', 't3', 't4', 'w1', 'w2', 'w6', 'w3']\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086840/decorator-class-and-missing-required-positional-arguments\n",
      "Decorator class and missing required positional arguments\n",
      "\n",
      "\n",
      "I'm having problems with a wrapper class, and can't figure out what I'm doing wrong.\n",
      "How do I go about getting that wrapper working with any class function with the 'self' argument?\n",
      "This is for Python 3.7.3.\n",
      "The thing is I remember the wrapper working before, but it seems something has changed...maybe I'm just doing something wrong now that I wasn't before.\n",
      "class SomeWrapper:\n",
      "\n",
      "    def __init__(self, func):\n",
      "        self.func = func\n",
      "\n",
      "    def __call__(self, *args, **kwargs):\n",
      "        # this fails because self is not passed\n",
      "        # ERROR: __init__() missing 1 required positional argument: 'self'\n",
      "        func_ret = self.func(*args, **kwargs)\n",
      "\n",
      "        # this fails because self.func is not the function's \"self\"\n",
      "        # ERROR: 'function' object has no attribute 'some_func'\n",
      "        # func_ret = self.func(self.func, *args, **kwargs)\n",
      "\n",
      "        # this is also wrong, because that's the wrong \"self\"\n",
      "        # ERROR: 'SomeWrapper' object has no attribute 'some_func'\n",
      "        # func_ret = self.func(self, *args, **kwargs)\n",
      "\n",
      "        print(\"Success\")\n",
      "\n",
      "        return func_ret\n",
      "\n",
      "\n",
      "class SomeClass:\n",
      "\n",
      "    @SomeWrapper\n",
      "    def __init__(self):\n",
      "        self.some_func()\n",
      "\n",
      "    def some_func(self):\n",
      "        pass\n",
      "\n",
      "\n",
      "SomeClass()\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086838/python-how-to-delete-bloody-blank-lines\n",
      "python: how to delete bloody blank lines?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is designed to contain multiple lines of answer from the user, all the white spaces at the start need to be deleted, I have down that by using line.strip(). However, I cannot figure out a way to delete the input blank lines between each line of the answer. \n",
      "print(\"after press enter and add a quit at end of your code\")\n",
      "print(\"copy and paste your code here\")\n",
      "text = \"\"\n",
      "stop_word = \"end\"\n",
      "while True:\n",
      "    line = input()\n",
      "    if line.strip() == stop_word:\n",
      "        break\n",
      "    text += \"%s\\n\" % line.strip()\n",
      "print(text)\n",
      "\n",
      "Answer\n",
      "\n",
      "You can detect a blank line in your code by checking the value of the line.\n",
      "if line == \"\":\n",
      "    # start the next iteration without finishing this one\n",
      "    continue\n",
      "\n",
      "The following code discards a line if it is empty:\n",
      "print(\"after press enter and add a quit at end of your code\")\n",
      "print(\"copy and paste your code here\")\n",
      "text = \"\"\n",
      "stop_word = \"end\"\n",
      "while True:\n",
      "    line = input()\n",
      "    if line == \"\":\n",
      "        continue\n",
      "\n",
      "    if line.strip() == stop_word:\n",
      "        break\n",
      "    text += \"%s\\n\" % line.strip()\n",
      "print(text)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086834/generating-features-from-log-file-sequences-in-python\n",
      "Generating features from log file sequences in Python\n",
      "\n",
      "\n",
      "I'm working on an ML problem where I have a dataset of user log files containing various interaction information and a label with an overall satisfaction outcome. The goal is to build a predictor (in H2O) that can detect the user's overall satisfaction given their usage pattern on the platform. \n",
      "I am having trouble identifying the best approach to how I should go about building the model. The data seems like it is ripe for a time series analysis but the outcome is categorical. I am assuming that in order to create this model I would need to aggregate and generate summary features for each user taking their time into consideration but user interactions vary in length and location. \n",
      "What is the best way to aggregate this kind of data, generate these features eventually model the data in python?\n",
      "Sample data:\n",
      "data = [{'User_ID': '12345', 'Type': 'HomePage', 'Item': 'LoginSelection', 'ExtendedInfo':'', 'EventTime': '2017-02-10 14:44:54', 'Outcome':'Satisfied'},\n",
      "        {'User_ID': '12345', 'Type': 'HomePage', 'Item': 'HelpSelection', 'ExtendedInfo':'', 'EventTime': '2017-02-10 14:45:57', 'Outcome':'Satisfied'},\n",
      "        {'User_ID': '12345', 'Type': 'Help', 'Item': 'Dropdown', 'ExtendedInfo':'', 'EventTime': '2017-02-10 14:46:54', 'Outcome':'Satisfied'},\n",
      "        {'User_ID': '12345', 'Type': 'Help', 'Item': 'Dropdown', 'ExtendedInfo':'', 'EventTime': '2017-02-10 14:47:10', 'Outcome':'Satisfied'},\n",
      "        {'User_ID': '12345', 'Type': 'Help', 'Item': 'HelpSearch', 'ExtendedInfo':'where to pay my bills', 'EventTime': '2017-02-10 14:47:35', 'Outcome':'Satisfied'},\n",
      "        {'User_ID': '12345', 'Type': 'Help', 'Item': 'HelpSearch', 'ExtendedInfo':'late payment options', 'EventTime': '2017-02-10 14:49:15', 'Outcome':'Satisfied'},\n",
      "        {'User_ID': '12888', 'Type': 'HomePage', 'Item': 'LoginSelection', 'ExtendedInfo':'', 'EventTime': '2017-02-11 13:24:54', 'Outcome':'Dissatisfied'},\n",
      "        {'User_ID': '12888', 'Type': 'HomePage', 'Item': 'HelpSelection', 'ExtendedInfo':'', 'EventTime': '2017-02-11 13:25:57', 'Outcome':'Dissatisfied'},\n",
      "        {'User_ID': '12888', 'Type': 'Help', 'Item': 'Dropdown', 'ExtendedInfo':'', 'EventTime': '2017-02-10 13:26:51', 'Outcome':'Dissatisfied'},\n",
      "        {'User_ID': '12888', 'Type': 'Help', 'Item': 'Dropdown', 'ExtendedInfo':'', 'EventTime': '2017-02-10 13:27:11', 'Outcome':'Dissatisfied'},\n",
      "        {'User_ID': '12888', 'Type': 'Help', 'Item': 'HelpSearch', 'ExtendedInfo':'some more search test', 'EventTime': '2017-02-11 13:27:35', 'Outcome':'Dissatisfied'},\n",
      "        {'User_ID': '12888', 'Type': 'Help', 'Item': 'HelpSearch', 'ExtendedInfo':'just an example', 'EventTime': '2017-02-11 13:59:15', 'Outcome':'Dissatisfied'}]\n",
      "\n",
      "example_df = pd.DataFrame(data, columns=['User_ID', 'Type', 'Item', 'ExtendedInfo', 'EventTime', 'Outcome'])\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086822/how-to-use-multiple-functions-on-jupyter-notebook-as-an-api-and-call-this-api-fr\n",
      "How to use multiple functions on Jupyter Notebook as an api and call this api from Django?\n",
      "\n",
      "\n",
      "I am making a movies prediction model in Jupyter Notebook and want to use this model in Django where I am making web application. But I don't know how to do it\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086817/tensorflow-valueerror-cannot-reshape-array-of-size-62842880-into-shape-4352-36\n",
      "Tensorflow ValueError: cannot reshape array of size 62842880 into shape (4352,3610,3)\n",
      "\n",
      "\n",
      "I tried running this code that I have for object detection. It works on any ordinary image that I download from the internet. However, I tried grabbing some pictures that were stitched together for mapping. And I get the error below. There seems to be a problem on the reshape() function.\n",
      "Traceback (most recent call last):\n",
      "  File \"final.py\", line 260, in <module>\n",
      "    image_np,imwidth,imheight = load_image_into_numpy_array(image)\n",
      "  File \"final.py\", line 213, in load_image_into_numpy_array\n",
      "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8),im_width,im_height\n",
      "ValueError: cannot reshape array of size 62842880 into shape (4352,3610,3)\n",
      "\n",
      "I haven't tried anything particular since there weren't much help in other forums.\n",
      "import cv2\n",
      "import numpy as np\n",
      "import os\n",
      "import sys,time\n",
      "import tensorflow as tf\n",
      "from distutils.version import StrictVersion\n",
      "from collections import defaultdict\n",
      "from io import StringIO\n",
      "import matplotlib.pyplot as plt\n",
      "from PIL import Image\n",
      "\n",
      "\n",
      "\n",
      "########################################################\n",
      "###################    PARAMETERS    ###################\n",
      "########################################################\n",
      "\n",
      "cntAreaMax = 1200000\n",
      "cntAreaMin = 100\n",
      "dilateIte = 1\n",
      "erosionIte = 5\n",
      "trackbarEnable = 1\n",
      "\n",
      "\n",
      "HSVmin = np.array([30,33,0])\n",
      "HSVmax = np.array([68,255,75])\n",
      "\n",
      "\n",
      "cntLine = 3\n",
      "enableErode = 1\n",
      "enableDilate = 0\n",
      "color_detect = 1\n",
      "\n",
      "\n",
      "obj_detect = 1\n",
      "detection_classes=[\"tree\",\"structure\",\"road\"]\n",
      "color_BGR=[(0,255,0),(255,0,0),(0,0,255)]\n",
      "starting_img_index = 3\n",
      "ending_img_index = 91\n",
      "detection_score_threshold = 0.5\n",
      "out_img_name = \"OUT-IMG-\"\n",
      "max_size = [4000,2000]\n",
      "min_size = [600,400]\n",
      "box_thickness = 3\n",
      "font = cv2.FONT_HERSHEY_SIMPLEX\n",
      "max_area = 500000\n",
      "min_area = 100\n",
      "filter_byArea = 1\n",
      "\n",
      "\n",
      "\n",
      "######## IMPORT IMAGE HERE ########\n",
      "image_name = \"odm_orthophoto\"\n",
      "image_extension = \".tif\"\n",
      "\n",
      "PATH_TO_IMAGE = os.path.join('test_images', image_name+image_extension)\n",
      "frame = cv2.imread(PATH_TO_IMAGE)\n",
      "print((frame.shape[1],frame.shape[0]))\n",
      "\n",
      "if frame.shape[1] >=1920 or frame.shape[0] >=1080:\n",
      "    if frame.shape[0]>frame.shape[1]:\n",
      "        fc=frame.shape[0]/1080\n",
      "        tuple = (int(frame.shape[1]//fc),int(frame.shape[0]//fc))\n",
      "        frame2 = cv2.resize(frame,tuple)\n",
      "        print(1)\n",
      "    elif frame.shape[1]>frame.shape[0]:\n",
      "        fc = frame.shape[1]/1920\n",
      "        #tuple = (int(frame.shape[1]//fc),int(frame.shape[0]//fc))\n",
      "        tuple=(1600,800)\n",
      "        frame2 = cv2.resize(frame,tuple)\n",
      "        print(2)\n",
      "    else:\n",
      "        fc = frame.shape[1]/1080\n",
      "        tuple = (int(frame.shape[1]//fc),int(frame.shape[0]//fc))\n",
      "        frame2 = cv2.resize(frame,tuple)\n",
      "        print(3)\n",
      "    print(tuple)\n",
      "else:\n",
      "    frame2=frame\n",
      "\n",
      "if color_detect:\n",
      "    if trackbarEnable:\n",
      "        def nothing(x):\n",
      "            pass\n",
      "        cv2.namedWindow(\"Trackbars\")\n",
      "        cv2.createTrackbar(\"L - H\", \"Trackbars\", 0, 179, nothing)\n",
      "        cv2.createTrackbar(\"L - S\", \"Trackbars\", 0, 255, nothing)\n",
      "        cv2.createTrackbar(\"L - V\", \"Trackbars\", 0, 255, nothing)\n",
      "        cv2.createTrackbar(\"U - H\", \"Trackbars\", 179, 179, nothing)\n",
      "        cv2.createTrackbar(\"U - S\", \"Trackbars\", 255, 255, nothing)\n",
      "        cv2.createTrackbar(\"U - V\", \"Trackbars\", 255, 255, nothing)\n",
      "        while True:\n",
      "            ##\n",
      "            hsv = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)\n",
      "            l_h = cv2.getTrackbarPos(\"L - H\", \"Trackbars\")\n",
      "            l_s = cv2.getTrackbarPos(\"L - S\", \"Trackbars\")\n",
      "            l_v = cv2.getTrackbarPos(\"L - V\", \"Trackbars\")\n",
      "            u_h = cv2.getTrackbarPos(\"U - H\", \"Trackbars\")\n",
      "            u_s = cv2.getTrackbarPos(\"U - S\", \"Trackbars\")\n",
      "            u_v = cv2.getTrackbarPos(\"U - V\", \"Trackbars\")\n",
      "            lower_blue = np.array([l_h, l_s, l_v])\n",
      "            upper_blue = np.array([u_h, u_s, u_v])\n",
      "            mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
      "            result = cv2.bitwise_and(frame2, frame2, mask=mask)\n",
      "            #cv2.imshow(\"frame\", frame)\n",
      "            #cv2.imshow(\"mask\", mask)\n",
      "            cv2.imshow(\"result\", result)\n",
      "            key = cv2.waitKey(1)\n",
      "            if key == 27:\n",
      "                break\n",
      "        print(\"HSV RANGE: H:{}-{}, S:{}-{}, V:{}-{}\".format(l_h,u_h,l_v,u_v,l_s,u_s))\n",
      "        cv2.destroyAllWindows()\n",
      "        lower_blue=np.array([l_h,l_s,l_v])\n",
      "        upper_blue=np.array([u_h,u_s,u_v])\n",
      "    else:\n",
      "        lower_blue=HSVmin\n",
      "        upper_blue=HSVmax\n",
      "\n",
      "\n",
      "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
      "    res = cv2.inRange(hsv, lower_blue, upper_blue)\n",
      "    cv2.imwrite(\"1-Range.jpg\",res)\n",
      "    temp = res\n",
      "    res = 255-res\n",
      "    element=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
      "    cv2.imwrite(\"2-MORPHELI.jpg\",element)\n",
      "    if enableDilate:\n",
      "        dil = cv2.dilate(res,element,iterations = dilateIte)\n",
      "        cv2.imwrite(\"4-DILATE.jpg\",dil)\n",
      "    if enableErode:\n",
      "        res = cv2.erode(res, element, iterations=erosionIte)\n",
      "        cv2.imwrite(\"3-ERODE.jpg\",res)\n",
      "\n",
      "    params = cv2.SimpleBlobDetector_Params()\n",
      "    contours, _ = cv2.findContours(res, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
      "    counter = 0\n",
      "    ji = 0\n",
      "    for contour in contours:\n",
      "        if cv2.contourArea(contour) > cntAreaMin and cv2.contourArea(contour)<=cntAreaMax:\n",
      "            mask = np.zeros(frame.shape[:2], np.uint8)\n",
      "            cv2.drawContours(mask, contour, -1, 255, -1)\n",
      "\n",
      "            mean = cv2.mean(frame, mask=mask)\n",
      "            #print(type(np.asarray(mean)))\n",
      "            mean = cv2.cvtColor(np.uint8([[[mean[0],mean[1],mean[2]]]]), cv2.COLOR_BGR2HSV)\n",
      "            #print(mean)\n",
      "            cv2.drawContours(frame, contour, -1, (0, 255, 0), cntLine)\n",
      "            counter+=1\n",
      "\n",
      "    cv2.imwrite(\"12-MASK.jpg\",mask)\n",
      "    cv2.imwrite(\"11-CONTOUR.jpg\",frame)\n",
      "\n",
      "    params.filterByColor = True\n",
      "    params.blobColor = 0\n",
      "    params.minThreshold = 0\n",
      "    params.maxThreshold = 100\n",
      "    #params.blobColor = 0\n",
      "    params.minArea = 100\n",
      "    params.maxArea = 1000000\n",
      "    params.filterByCircularity = False\n",
      "    params.filterByConvexity = False\n",
      "    params.minCircularity = 0\n",
      "    params.maxCircularity = 1\n",
      "\n",
      "    det = cv2.SimpleBlobDetector_create(params)\n",
      "    keypts = det.detect(res)\n",
      "    i = 0\n",
      "\n",
      "    print(\"CONTOUR LENGTH: %d\" %counter)\n",
      "    print(\"BLOBS IN CONTOUR: %d\" %i)\n",
      "    #res = cv2.cvtColor(res, cv2.COLOR_HSV2BGR)\n",
      "    #print(res[3000-1,4000-1])\n",
      "    cv2.imwrite(\"9-OUT.jpg\",res)\n",
      "\n",
      "\n",
      "if obj_detect:\n",
      "    print(\"Initializing Tensorflow\")\n",
      "    # This is needed since the notebook is stored in the object_detection folder.\n",
      "    sys.path.append(\"..\")\n",
      "    from object_detection.utils import ops as utils_ops\n",
      "\n",
      "    if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
      "        raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
      "\n",
      "    from utils import label_map_util\n",
      "    from utils import visualization_utils as vis_util\n",
      "    print(\"Preparing Object Detection Model\")\n",
      "\n",
      "    MODEL_NAME = 'output_inference_graph_v2.pb'\n",
      "    # Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
      "    PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
      "    # List of the strings that is used to add correct label for each box.\n",
      "    PATH_TO_LABELS = os.path.join('annotations', 'label_map.pbtxt')\n",
      "    # ## Load a (frozen) Tensorflow model into memory.\n",
      "\n",
      "    print(\"Importing Label Map\")\n",
      "    detection_graph = tf.Graph()\n",
      "    with detection_graph.as_default():\n",
      "        od_graph_def = tf.GraphDef()\n",
      "        with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
      "            serialized_graph = fid.read()\n",
      "            od_graph_def.ParseFromString(serialized_graph)\n",
      "            tf.import_graph_def(od_graph_def, name='')\n",
      "\n",
      "    # ## Loading label map\n",
      "    # Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\n",
      "\n",
      "\n",
      "    category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
      "\n",
      "    def load_image_into_numpy_array(image):\n",
      "        (im_width, im_height) = image.size\n",
      "        return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8),im_width,im_height\n",
      "\n",
      "    print(\"Organizing Images\")\n",
      "    IMAGE_SIZE = (12, 8)\n",
      "\n",
      "    def run_inference_for_single_image(image, graph):\n",
      "        with graph.as_default():\n",
      "            with tf.Session() as sess:\n",
      "                # Get handles to input and output tensors\n",
      "                ops = tf.get_default_graph().get_operations()\n",
      "                all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
      "                tensor_dict = {}\n",
      "                for key in ['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes', 'detection_masks']:\n",
      "                    tensor_name = key + ':0'\n",
      "                    if tensor_name in all_tensor_names:\n",
      "                        tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
      "                if 'detection_masks' in tensor_dict:\n",
      "                    # The following processing is only for single image\n",
      "                    detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
      "                    detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
      "                    # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
      "                    real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
      "                    detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
      "                    detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
      "                    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
      "                    detection_masks_reframed = tf.cast(tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
      "                    # Follow the convention by adding back the batch dimension\n",
      "                    tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n",
      "\n",
      "                image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
      "\n",
      "                # Run inference\n",
      "                output_dict = sess.run(tensor_dict,feed_dict={image_tensor: image})\n",
      "\n",
      "                # all outputs are float32 numpy arrays, so convert types as appropriate\n",
      "                output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
      "                output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.int64)\n",
      "                output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
      "                output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
      "                if 'detection_masks' in output_dict:\n",
      "                    output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
      "        return output_dict\n",
      "\n",
      "    print(\"Opening Image\"+image_name)\n",
      "    image = Image.open(PATH_TO_IMAGE)\n",
      "    # the array based representation of the image will be used later in order to prepare the\n",
      "    # result image with boxes and labels on it.\n",
      "    image_np,imwidth,imheight = load_image_into_numpy_array(image)\n",
      "\n",
      "    if imwidth >= max_size[0] and imheight >= max_size[1]:\n",
      "        thickness = 5\n",
      "        fontsize = 0.9\n",
      "    elif imwidth <= min_size[0] and imheight <= min_size[1]:\n",
      "        thickness = 1\n",
      "        fontsize = 0.5\n",
      "    else:\n",
      "        thickness = 3\n",
      "        fontsize = 0.7\n",
      "\n",
      "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
      "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
      "    # Actual detection.\n",
      "    print(\"Running Object Detection on Image\"+image_name)\n",
      "    timer=time.time()\n",
      "    output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
      "    # Visualization of the results of a detection.\n",
      "    #print(output_dict['detection_boxes'])\n",
      "    #vis_util.visualize_boxes_and_labels_on_image_array(image_np,output_dict['detection_boxes'],output_dict['detection_classes'],output_dict['detection_scores'],category_index,instance_masks=output_dict.get('detection_masks'),use_normalized_coordinates=True,line_thickness=8)\n",
      "    coords=[]\n",
      "    ci=0\n",
      "    for i in output_dict['detection_boxes']:\n",
      "        cj=0\n",
      "        array=[]\n",
      "        for j in i:\n",
      "            if cj%2==0:\n",
      "                val=output_dict['detection_boxes'][ci][cj]*imheight\n",
      "            else:\n",
      "                val=output_dict['detection_boxes'][ci][cj]*imwidth\n",
      "            array.append(val)\n",
      "            cj+=1\n",
      "        coords.append(array)\n",
      "        ci+=1\n",
      "    accepted_indeces=[]\n",
      "    sci=0\n",
      "    for sc in output_dict['detection_scores']:\n",
      "        if sc >= detection_score_threshold:\n",
      "            accepted_indeces.append(sci)\n",
      "        sci+=1\n",
      "    #vis_util.visualize_boxes_and_labels_on_image_array(image_np,output_dict['detection_boxes'],output_dict['detection_classes'],output_dict['detection_scores'],category_index,instance_masks=output_dict.get('detection_masks'),use_normalized_coordinates=True,line_thickness=8)\n",
      "    print(\"Saving as \"+out_img_name+\"{}. Detection Time: {}\".format(starting_img_index, time.time()-timer))\n",
      "    ck=0\n",
      "    boxes=[]\n",
      "    num_boxes = 0\n",
      "    for k in output_dict['detection_boxes']:\n",
      "        if ck in accepted_indeces:\n",
      "            w = -int(coords[ck][1]-coords[ck][3])\n",
      "            h = -int(coords[ck][0]-coords[ck][2])\n",
      "            x = int((coords[ck][1]+coords[ck][3])/2)\n",
      "            y = int((coords[ck][0]+coords[ck][2])/2)\n",
      "            boxes.append([x,y,w,h])\n",
      "            if res[y,x]==0:\n",
      "                if filter_byArea:\n",
      "                    if w*h <= max_area and w*h >= min_area:\n",
      "                        cv2.rectangle(image_np,(int(coords[ck][1]),int(coords[ck][0])),(int(coords[ck][3]),int(coords[ck][2])),color_BGR[output_dict['detection_classes'][ck]-1],thickness)\n",
      "                        cv2.putText(image_np,detection_classes[output_dict['detection_classes'][ck]-1]+\": \"+str(int(output_dict['detection_scores'][ck]*100))+\"%\",(int(coords[ck][1]),int(coords[ck][0])), font, fontsize,(255,255,255),1,cv2.LINE_AA)\n",
      "                        num_boxes+=1\n",
      "                        #print(w*h)\n",
      "                else:\n",
      "                    cv2.rectangle(image_np,(int(coords[ck][1]),int(coords[ck][0])),(int(coords[ck][3]),int(coords[ck][2])),color_BGR[output_dict['detection_classes'][ck]-1],thickness)\n",
      "                    cv2.putText(image_np,detection_classes[output_dict['detection_classes'][ck]-1]+\": \"+str(int(output_dict['detection_scores'][ck]*100))+\"%\",(int(coords[ck][1]),int(coords[ck][0])), font, fontsize,(255,255,255),1,cv2.LINE_AA)\n",
      "                    num_boxes+=1\n",
      "                            #print(w*h)\n",
      "        ck+=1\n",
      "    print(\"Saving as \"+image_name+\"-OUT\"+image_extension)\n",
      "    cv2.imwrite(image_name+\"-OUT\"+image_extension, image_np)\n",
      "\n",
      "As said before, I get the following errors:\n",
      "Traceback (most recent call last):\n",
      "  File \"final.py\", line 260, in <module>\n",
      "    image_np,imwidth,imheight = load_image_into_numpy_array(image)\n",
      "  File \"final.py\", line 213, in load_image_into_numpy_array\n",
      "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8),im_width,im_height\n",
      "ValueError: cannot reshape array of size 62842880 into shape (4352,3610,3)\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086793/how-to-generalise-the-python-used-for-docker-images\n",
      "How to generalise the python used for Docker images?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry if this is a bad question, I am still a beginner at Docker so I seek your understanding on this.\n",
      "I am attempting to dockerize an application. In the application, there is a json config file which states the python's file path. For example, /home/ubuntu/miniconda3/bin/python.\n",
      "However aftering dockerizing the app and trying to run my image on another machine, the following error shows up: \n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/ubuntu/miniconda3/bin/python': '/home/ubuntu/miniconda3/bin/python'\n",
      "Hence, I was wondering how does Docker package the python required exactly when building an image? Also, how can I change the json file such that it generalizes across all machines?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086782/tkinter-animation-becomes-unresponsive-and-crashes-unless-calling-root-update\n",
      "Tkinter animation becomes unresponsive and crashes unless calling root.update() on each frame\n",
      "\n",
      "\n",
      "I'm trying to play some simple animations on a window. It's my first time using Tkinter, so I set a call to root.update() at each frame to ensure that it gets shown on screen (the frame rate was a bit erratic otherwise). I have now learned that this is very bad practice, and tried to either remove it completely, or substitute it with a call to root.update_idletasks(). The weird thing is that when I do that, the window becomes unresponsive and eventually crashes.\n",
      "I tried stripping my code down to its bare minimum (shown below), but the problem still persists.\n",
      "from tkinter import *\n",
      "from tkinter import ttk\n",
      "from PIL import ImageTk, Image\n",
      "\n",
      "class Application():\n",
      "    def __init__(self):\n",
      "        # WINDOW SETUP\n",
      "        self.root = Tk()\n",
      "        self.root.geometry('512x512')\n",
      "        self.root.protocol('WM_DELETE_WINDOW', self.Annihilation)\n",
      "\n",
      "        self.screen = ttk.Label(self.root)\n",
      "        self.screen.place(relx=.5, rely=.5, anchor=\"c\")\n",
      "\n",
      "        # CALL THE ANIMATION FUNCTION\n",
      "        self.state = 'Idle'\n",
      "        self.Animation(self.state, [self.Idle1, self.Idle2], 500)\n",
      "\n",
      "        self.root.mainloop()\n",
      "\n",
      "\n",
      "    # ANIMATION FUNCTION\n",
      "    def Animation(self, State, framelist, frameduration):\n",
      "        for i in range(len(framelist)):\n",
      "            if self.state == State:\n",
      "                frame = framelist[i]()\n",
      "                self.screen.configure(image = frame)\n",
      "                self.root.update() # THIS IS THE LINE I WANT TO REMOVE\n",
      "                self.root.after(frameduration)          \n",
      "            else:\n",
      "                return\n",
      "\n",
      "        self.Animation(State, framelist, frameduration)\n",
      "\n",
      "    # LIST OF IMAGES\n",
      "    def Idle1(self):\n",
      "        return ImageTk.PhotoImage(Image.open('Image1.tif').resize((512, 512)))\n",
      "    def Idle2(self):\n",
      "        return ImageTk.PhotoImage(Image.open('Image2.tif').resize((512, 512)))\n",
      "\n",
      "\n",
      "    def Annihilation(self):\n",
      "        self.root.eval('::ttk::CancelRepeat')\n",
      "        self.state = 'Quitting'\n",
      "        self.root.destroy()\n",
      "\n",
      "Application()\n",
      "\n",
      "This smells of \"There's a much bigger mistake in your code that your first mistake is accidentally keeping at bay\", but I'm out of ideas and I haven't been able to Google this one. Any help would be greatly appreciated.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086774/how-to-share-mutliprocessing-queue-object-between-multiple-computers\n",
      "How to share mutliprocessing queue object between multiple computers\n",
      "\n",
      "\n",
      "I followed the doc on Python's multiprocessing module. There is an example on how to use multiprocessing.managers.BaseManager to share the same Queue between the multiple machines. The server example is pretty simple:\n",
      "from multiprocessing.managers import BaseManager\n",
      "import Queue\n",
      "queue = Queue.Queue()\n",
      "class QueueManager(BaseManager): pass\n",
      "QueueManager.register('get_queue', callable=lambda:queue)\n",
      "m = QueueManager(address=('0.0.0.0', 50000), authkey='abracadabra')\n",
      "s = m.get_server()\n",
      "s.serve_forever()\n",
      "\n",
      "The client is even simpler:\n",
      "from multiprocessing.managers import BaseManager\n",
      "class QueueManager(BaseManager): pass\n",
      "QueueManager.register('get_queue')\n",
      "m = QueueManager(address=('localhost', 50000), authkey='abracadabra')\n",
      "m.connect()\n",
      "queue = m.get_queue()\n",
      "queue.put('hello')\n",
      "\n",
      "The problem is that the client can't connect to server. What needs to be changed in order to establish communication between the client and server?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086731/how-can-i-use-a-variable-pre-defined-as-none-in-dynamic-placeholder-in-lambda\n",
      "How can I use a variable pre-defined as “None” in dynamic placeholder in Lambda layer?\n",
      "\n",
      "\n",
      "I'm trying to use keras Lambda layer to reshape data tensor in the middle of the whole model. The shape of Lambda layer's input returns None in depth (how many frames do I input for one time). However, I need the exact number for for-loop to run. \n",
      "If directly using the number x.shape passed, Nonetype object cannot be used as integer for for-loop;\n",
      "If I define it as a constant (for example, 300, which is the depth of train set), when I call model.fit the number will not match with validation set depth.\n",
      "def repacking(x):\n",
      "    #----------------------------get shape from input tensor---------------------------------\n",
      "    (AMOUNT, TARGET_HEIGHT, TARGET_WIDTH, tmp) = x.shape\n",
      "    #----------------------------pack frame one by one---------------------------------------\n",
      "    for i in range(AMOUNT):\n",
      "        ...\n",
      "\n",
      "    package_set = tf.reshape(package_set, (AMOUNT, DEPTH, TARGET_HEIGHT, TARGET_WIDTH, 1))\n",
      "    return package_set\n",
      "\n",
      "How should I define a dynamic varibale that can changed according to real cases?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086685/slicing-object-as-argument-didnt-change-after-running-a-function-in-python\n",
      "Slicing object as argument didn't change after running a function in python\n",
      "\n",
      "\n",
      "Passing a mutable object to a function, we can modify its value without return. But if I pass a slice of a mutable object, seems that after running the function, the values of that object didn't change.\n",
      "Here is my code:\n",
      "def reverse(self, x):\n",
      "    \"\"\"\n",
      "    :type x: int\n",
      "    :rtype: int\n",
      "    \"\"\"\n",
      "    s = list(str(x))\n",
      "    if s[0] == \"-\":\n",
      "        #if s=['-','1','2','3'], then s[1:]=['1','2','3'], after running self.reverseCore, s still is ['-','1','2','3']\n",
      "        print(id(s[1:]))\n",
      "        self.reverseCore(s[1:])\n",
      "        print(s)\n",
      "    else:\n",
      "        #if s=['1','2','3'], after running self.reverseCore, s will be['3','2','1']\n",
      "        self.reverseCore(s)\n",
      "        print(s)\n",
      "def reverseCore(self, s):\n",
      "    print(id(s))\n",
      "    if len(s)<= 1:\n",
      "        return\n",
      "    l = len(s)\n",
      "    k = l//2\n",
      "    for i in range(0, k):\n",
      "        s[i], s[l-i-1] = s[l-i-1], s[i]\n",
      "\n",
      "s[1:] is also a mutable object, then why it didn't change?\n",
      "\n",
      "Answer\n",
      "\n",
      "When you slice an array in python, the data is deep copied. This means that you are passing an entirely new object. Now, if you set a variable to the slice, that variable should be modified. For example,\n",
      "z = s[1:]\n",
      "\n",
      "self.reverseCore(z)\n",
      "\n",
      "The the variable z will contain the updated values. If you don't wish to copy the data, you can try implementing some for of range. As in, only preforming the operation on a subsection of the list with a start and stop.\n",
      "Here is an example of setting s to the slice:\n",
      "def reverse(self, x):\n",
      "    \"\"\"\n",
      "    :type x: int\n",
      "    :rtype: int\n",
      "    \"\"\"\n",
      "    s = list(str(x))\n",
      "    if s[0] == \"-\":\n",
      "        #if s=['-','1','2','3'], then s[1:]=['1','2','3'], after running self.reverseCore, s still is ['-','1','2','3']\n",
      "        s = s[1:]\n",
      "        print(id(s[1:]))\n",
      "        self.reverseCore(s)\n",
      "    else:\n",
      "        #if s=['1','2','3'], after running self.reverseCore, s will be['3','2','1']\n",
      "        self.reverseCore(s)\n",
      "        print(s)\n",
      "def reverseCore(self, s):\n",
      "    print(id(s))\n",
      "    if len(s)<= 1:\n",
      "        return\n",
      "    l = len(s)\n",
      "    k = l//2\n",
      "    for i in range(0, k):\n",
      "        s[i], s[l-i-1] = s[l-i-1], s[i]\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086666/python-remove-duplicate-elements-from-json-based-on-value-within-json\n",
      "Python - Remove duplicate elements from JSON based on value within JSON\n",
      "\n",
      "\n",
      "I have a JSON object which may contain duplicate items and locations and I want to keep the one with the highest risk (and only one of them)\n",
      "[{\n",
      "'item': 'itemone',\n",
      "'location': 'locationone',\n",
      "'risk_level': 'Low'\n",
      "#Other values are omitted\n",
      "},\n",
      "{\n",
      "'item': 'itemone',\n",
      "'location': 'locationone',\n",
      "'risk_level': 'High'\n",
      "},\n",
      "{\n",
      "'item': 'itemone',\n",
      "'location': 'locationone',\n",
      "'risk_level': 'Moderate'\n",
      "},\n",
      "{\n",
      "'item': 'itemone',\n",
      "'location': 'locationone',\n",
      "'risk_level': 'High'\n",
      "},\n",
      "{\n",
      "'item': 'itemtwo',\n",
      "'location': 'locationtwo',\n",
      "'risk_level': 'Low'\n",
      "}]\n",
      "\n",
      "I have tried converting it into a pandas dataframe, ordering it based on risk_level and using the drop_duplicates however this causes issues with other values in the JSON (e.g. converting None into NaN, int into floats etc.) so I don't think it's feasible.\n",
      "    #Convert to dataframe and drop identical insights with lowest severities\n",
      "    dfInsights = pd.DataFrame(response['data'])\n",
      "    dfInsights = dfInsights.reindex(columns=list(response['data'][0].keys()))\n",
      "    dfInsights.sort_values(['risk_level'], inplace=True)\n",
      "    dfInsights.drop_duplicates(['item','location'], keep='first', inplace=True)\n",
      "    dfToJSON = dfInsights.to_dict(orient='records')\n",
      "\n",
      "I would like the result to be:\n",
      "[{\n",
      "'item': 'itemone',\n",
      "'location': 'locationone',\n",
      "'risk_level': 'High'\n",
      "},\n",
      "{\n",
      "'item': 'itemtwo',\n",
      "'location': 'locationtwo',\n",
      "'risk_level': 'Low'\n",
      "}]\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086635/how-to-login-into-an-ssh-server-with-exscript-framework-automatically\n",
      "How to login into an ssh server with Exscript framework automatically?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to login into an SSH server and execute multiple \"ROS\" commands on the same session. I looked for a framework who stay connected after the first command and the only who did well was the Exscript framework. My code is simple, i pick the Username, Port, Client and Address from an XML file, and login with that credentials. But i always receive the error Connection Refused or Finally Down when i use the Account class for an automatic login (without the prompt asking the input for user and password) as the Exscript Tutorial recommends. However if i run my code without trying to automatic login, similar to the Getting Start Code and with the same values from the XML to login, everything works fine. Cam someone help with that please?\n",
      "Obs: Already tried the codes in this thread, and none of that codes worked (even without the use of the XML)\n",
      "# -*- coding: utf-8 -*-\n",
      "from Exscript.util.start import start\n",
      "from Exscript.util.interact import read_login\n",
      "from Exscript import Host, Account\n",
      "import Exscript\n",
      "from Exscript.protocols import SSH2\n",
      "try:\n",
      "    import xml.etree.cElementTree as et\n",
      "except ImportError:\n",
      "    import xml.etree.ElementTree as et\n",
      "\n",
      "# Reads the XML File\n",
      "xmlFile = et.parse('environment.xml')\n",
      "# Find the root element from the file (in this case \"environment\")\n",
      "root = xmlFile.getroot()\n",
      "\n",
      "\n",
      "address = root.findtext('TURTLEBOT_IP')\n",
      "usernameClient = root.findtext('USERNAME')\n",
      "passwordClient = root.findtext('PASSWORD')\n",
      "portClient = root.findtext('PORT')\n",
      "\n",
      "myIP = root.findtext('MY_IP')\n",
      "masterIP = root.findtext('MASTER_IP')\n",
      "rosMasterURI = root.findtext('ROS_MASTER_URI')\n",
      "rosHostname = root.findtext('ROS_HOSTNAME')\n",
      "rosNamespace = root.findtext('ROS_NAMESPACE')\n",
      "address = root.findtext('TURTLEBOT_IP')\n",
      "usernameClient = root.findtext('USERNAME')\n",
      "passwordClient = root.findtext('PASSWORD')\n",
      "portClient = root.findtext('PORT')\n",
      "perspectiveLocation = root.findtext('PERSPECTIVE_LOCATION')\n",
      "rosSource = root.findtext(\"ROS_SOURCE\")\n",
      "rosEtc = root.findtext('ROS_ETC_DIRECTORY')\n",
      "rosRoot = root.findtext('ROS_ROOT')\n",
      "\n",
      "exportIP = str('ROS_IP='+myIP)\n",
      "exportMasterIP = str('MASTER_IP='+myIP)\n",
      "exportMasterIPURI = str('export ROS_MASTER_URI=http://$MASTER_IP:11311/')\n",
      "exportRosIP = str('export ROS_IP=$MY_IP')\n",
      "exportHostname = str('export ROS_HOSTNAME_IP=$MY_IP')\n",
      "exportNamespace = str('export ROS_NAMESPACE='+rosNamespace)\n",
      "print(exportMasterIP)\n",
      "print(exportRosIP)\n",
      "print(exportHostname)\n",
      "print(exportNamespace)\n",
      "# print(address)\n",
      "\n",
      "accountLogin = [Account(usernameClient, passwordClient)]\n",
      "conn = SSH2()\n",
      "host1 = Host(address)\n",
      "host1.set_account(accountLogin)\n",
      "conn.connect(address)\n",
      "\n",
      "\n",
      "def cmd(job, host, conn):\n",
      "    conn.execute(str(exportIP+'\\n'+exportMasterIP+'\\n'+exportMasterIPURI+'\\n'+\n",
      "                     exportRosIP+'\\n'+exportHostname+'\\n'+exportNamespace))\n",
      "    conn.execute('roscore')\n",
      "    conn.execute('roslaunch turtlebot_bringup minimal.launch')\n",
      "    conn.execute('roslaunch turtlebot_teleop keyboard_teleop.launch')\n",
      "    conn.execute()\n",
      "\n",
      "\n",
      "start(accountLogin, host1, cmd, max_threads=2)\n",
      "\n",
      "# conn.send('quit\\r')\n",
      "# conn.close()\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086634/modify-the-text-value-of-child-node-in-xml-file-and-save-it-using-python\n",
      "Modify the text value of child node in xml file and save it (using python)\n",
      "\n",
      "\n",
      "My xml file is :\n",
      "<annotation>\n",
      "    <folder>cancer</folder>\n",
      "    <filename>cancer1.jpg</filename>\n",
      "    <path>/Volumes/Windows/tongue-img/cancer/cancer1.jpg</path>\n",
      "    <source>\n",
      "        <database>Unknown</database>\n",
      "    </source>\n",
      "    <size>\n",
      "        <width>3088</width>\n",
      "        <height>2056</height>\n",
      "        <depth>3</depth>\n",
      "    </size>\n",
      "    <segmented>0</segmented>\n",
      "    <object>\n",
      "        <name>cancer</name>\n",
      "        <pose>Unspecified</pose>\n",
      "        <truncated>0</truncated>\n",
      "        <difficult>0</difficult>\n",
      "        <bndbox>\n",
      "            <xmin>1090</xmin>\n",
      "            <ymin>869</ymin>\n",
      "            <xmax>1807</xmax>\n",
      "            <ymax>1379</ymax>\n",
      "        </bndbox>\n",
      "    </object>\n",
      "</annotation>\n",
      "\n",
      "I want to change the text value of child node of  1090\n",
      "to the value by performing some arithmetic operations on it like subtract 10 from it.\n",
      "The operation is performed and value is changed but its not saved to xml file i.e xml file is not updated it remains same.\n",
      "Python code is :\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "tree = ET.parse('/Users/sripdeep/Desktop/Tongue_Cancer/leuko32.xml')  \n",
      "root = tree.getroot()\n",
      "X=10\n",
      "print (root[6][4][0].text)\n",
      "v1=root[6][4][0].text\n",
      "v1 = int(v1) - X\n",
      "print('New:')\n",
      "print (v1)\n",
      "\n",
      "print (root[6][4][1].text)\n",
      "print (root[6][4][2].text)\n",
      "print (root[6][4][3].text)\n",
      "\n",
      "tree.write(open('C1.xml'))\n",
      "\n",
      "The file C1.xml is not updated. \n",
      "The output is (when the values are printed while running python):\n",
      "Old text value:\n",
      "1090\n",
      "New text value:\n",
      "1080\n",
      "869\n",
      "1807\n",
      "1379\n",
      "\n",
      "But the value remains 1090 in the modified xml file\n",
      "\n",
      "Answer\n",
      "\n",
      "I think what you are looking for is to modify the text. You have gotten the value, but not changed it in the underlying tree. To change to, you would just use the = operator.\n",
      "root[6][4][0].text = v1\n",
      "\n",
      "Your final code would look like this:\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "tree = ET.parse('/Users/sripdeep/Desktop/Tongue_Cancer/leuko32.xml')  \n",
      "root = tree.getroot()\n",
      "X=10\n",
      "print (root[6][4][0].text)\n",
      "v1=root[6][4][0].text\n",
      "v1 = int(v1) - X\n",
      "print('New:')\n",
      "print (v1)\n",
      "\n",
      "root[6][4][0].text = str(v1)\n",
      "\n",
      "print (root[6][4][1].text)\n",
      "print (root[6][4][2].text)\n",
      "print (root[6][4][3].text)\n",
      "\n",
      "tree.write(open('C1.xml', 'w'))\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "tree = ET.parse('./sample.xml')  \n",
      "root = tree.getroot()\n",
      "X=10\n",
      "print (root[6][4][0].text)\n",
      "v1=root[6][4][0].text\n",
      "v1 = int(v1) - X\n",
      "print('New:')\n",
      "print (v1)\n",
      "\n",
      "root[6][4][0].text = str(v1)\n",
      "print (root[6][4][1].text)\n",
      "print (root[6][4][2].text)\n",
      "print (root[6][4][3].text)\n",
      "\n",
      "tree.write('C1.xml')\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086631/anacondaset-conda-force-32bit-1-not-work\n",
      "anaconda“set CONDA_FORCE_32BIT=1” not work\n",
      "\n",
      "\n",
      "I want to load a 32-bit liba.so file in python,but when i load it ,it have an error:\n",
      ">>> from ctypes import *\n",
      ">>> liba = cdll.LoadLibrary(\"./liba.so\")\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "  File \"/root/anaconda3/envs/py35_32/lib/python3.5/ctypes/__init__.py\", line 429, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/root/anaconda3/envs/py35_32/lib/python3.5/ctypes/__init__.py\", line 351, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: ./liba.so: wrong ELF class: ELFCLASS32\n",
      "\n",
      "I google this problem, find it should use the 32-bit python.\n",
      "I'm using the 64-bit ubuntu adn i have install the anaconda-64bit.\n",
      "I found the follow code can create a 32-bit python virtual env.\n",
      "set CONDA_FORCE_32BIT=1 \n",
      "conda create -n env_name python=3.5\n",
      "conda activate env_name\n",
      "\n",
      "But it seems not work. \n",
      "root@ubunut:conda info|grep platform\n",
      "          platform : linux-64\n",
      "root@ubunut:set CONDA_FORCE_32BIT=1\n",
      "root@ubunut:conda info|grep platform\n",
      "          platform : linux-64\n",
      "root@ubunut:conda create -n py35_32 python=3.5 -y\n",
      "root@ubunut:conda activate py35_32\n",
      "(py35_32)root@ubunut:python -c 'import struct;print( 8*struct.calcsize(\"P\"))'\n",
      "          64       \n",
      "(py35_32)root@ubunut:python\n",
      ">>> from ctypes import *\n",
      ">>> liba = cdll.LoadLibrary(\"./liba.so\")\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "  File \"/root/anaconda3/envs/py35_32/lib/python3.5/ctypes/__init__.py\", line 429, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/root/anaconda3/envs/py35_32/lib/python3.5/ctypes/__init__.py\", line 351, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: ./liba.so: wrong ELF class: ELFCLASS32\n",
      "\n",
      "\n",
      "\n",
      "As you can see, it 64-bit python,not 32-bit.\n",
      "Did i make mistakes in some steps? How can i install the 32-bit python ?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086622/recursionerror-maximum-recursion-depth-exceeded-when-using-kmeans\n",
      "RecursionError: maximum recursion depth exceeded when using kmeans\n",
      "\n",
      "\n",
      "My code-\n",
      "import xlrd,statistics,numpy\n",
      "\n",
      "loc= r\"Re.xlsx\"\n",
      "\n",
      "wb = xlrd.open_workbook(loc) \n",
      "sheet = wb.sheet_by_index(0); \n",
      "\n",
      "\n",
      "\n",
      "x=[]\n",
      "def get_col_index(u):\n",
      "    for j in range(sheet.ncols):\n",
      "        if sheet.cell_value(0, j)== u:\n",
      "            return j\n",
      "\n",
      "def get_model_list():\n",
      "    p=[]\n",
      "    f= get_col_index('bikeModel')\n",
      "    print(f)\n",
      "    for j in range(sheet.nrows):\n",
      "        c= sheet.cell_value(j,f)\n",
      "        if c not in p:\n",
      "            if c!='':\n",
      "                p.append(c)\n",
      "\n",
      "\n",
      "    return p                    \n",
      "def averag(x):\n",
      "    bd= sum(x)\n",
      "    ct= len(x)\n",
      "    av= bd/ct\n",
      "    return av\n",
      "\n",
      "def k_means(x):\n",
      "    serviceType_len= len(x)\n",
      "    if len(x)<=2:\n",
      "        print([numpy.average(x), numpy.std(x)])\n",
      "        return [numpy.average(x), numpy.std(x)]    \n",
      "    #arrange data list and stored in 'y'\n",
      "    y=sorted(x)\n",
      "    mini=min(y)\n",
      "    maxi=max(y)\n",
      "    ran=maxi-mini\n",
      "\n",
      "    #get initial centroids c1, c2, c3, c4 in C\n",
      "    q1=[]\n",
      "    q2=[]\n",
      "    q3=[]\n",
      "    q4=[]\n",
      "    for i in y:\n",
      "        if i<= (ran/4+mini):\n",
      "            q1.append(i)\n",
      "        elif i<=(mini+ran/2):\n",
      "             q2.append(i)\n",
      "        elif i<=(mini+3*ran/4):\n",
      "            q3.append(i)\n",
      "        else:\n",
      "            q4.append(i)\n",
      "\n",
      "    Cd=[]        \n",
      "    if len(q1)!=0:\n",
      "        q1.sort()\n",
      "        c1=[]\n",
      "        Cd.append(q1[0])\n",
      "    else:\n",
      "        c1='NULL'\n",
      "    if len(q2)!=0:\n",
      "        q2.sort()\n",
      "        c2=[]\n",
      "        Cd.append(q2[0])\n",
      "    else:\n",
      "\n",
      "        c2='NULL'    \n",
      "    if len(q3)!=0:\n",
      "        q3.sort()\n",
      "        c3=[]\n",
      "        Cd.append(q3[0])\n",
      "    else:\n",
      "\n",
      "        c3='NULL'\n",
      "    if len(q4)!=0:\n",
      "        q4.sort()\n",
      "        c4=[]\n",
      "        Cd.append(q4[0])\n",
      "    else:\n",
      "\n",
      "        c4='NULL'\n",
      "\n",
      "\n",
      "    print(Cd)\n",
      "    cl=[]\n",
      "    rty= cluster(y,Cd,cl)\n",
      "\n",
      "    return rty\n",
      "\n",
      "def cluster(y,Cd,cl):\n",
      "    if len(y)<=2:\n",
      "        return numpy.average(y)    \n",
      "    else:\n",
      "        ncl=[]\n",
      "        ocl=cl\n",
      "        ncl1=[]\n",
      "        ncl2=[]\n",
      "        ncl.append(ncl1)\n",
      "        ncl.append(ncl2)\n",
      "\n",
      "        if len(Cd)>2:\n",
      "\n",
      "            ncl3=[]\n",
      "\n",
      "            ncl.append(ncl3)\n",
      "        if len(Cd)>3:\n",
      "\n",
      "            ncl4=[]    \n",
      "            ncl.append(ncl4)\n",
      "\n",
      "        pc=0\n",
      "        for i in y:\n",
      "            print(Cd[0])\n",
      "            diff=abs(i-Cd[0])\n",
      "\n",
      "            for k in Cd:\n",
      "                if abs(i-k)<diff:\n",
      "                    diff= abs(i-k)\n",
      "                    pc=Cd.index(k)\n",
      "            ncl[pc].append(i)\n",
      "        print(\"appended\")\n",
      "        if len(Cd)>=1:\n",
      "\n",
      "            Cd[0]= averag(ncl[0])\n",
      "            print(Cd[0])\n",
      "        if len(Cd)>=2:    \n",
      "            Cd[1]= averag(ncl2)\n",
      "        if len(Cd)>2:\n",
      "            Cd[2]= averag(ncl3)\n",
      "            if len(Cd)>3:\n",
      "                Cd[3]=averag(ncl4)\n",
      "        if ocl==ncl:\n",
      "\n",
      "            ncl.sort(key=len)\n",
      "            ncl.reverse()\n",
      "            ncl[0].sort()\n",
      "\n",
      "\n",
      "            ncl[1].sort()\n",
      "\n",
      "            if len(Cd)>2:\n",
      "                ncl[2].sort()\n",
      "\n",
      "\n",
      "\n",
      "            if len(Cd)>3:\n",
      "                ncl[3].sort()\n",
      "\n",
      "            ll=[ncl[0]]\n",
      "            for we in ncl:\n",
      "                if we!=ncl[0]:\n",
      "                    if ((len(ncl[0])- len(we)))<20*len(y)/100:\n",
      "                        ll.append(ncl[ncl.index(we)])\n",
      "\n",
      "            finl=[]\n",
      "\n",
      "            for h in ll:\n",
      "                for b in h:\n",
      "                    finl.append(b)\n",
      "            finl.sort()\n",
      "\n",
      "            countr=0\n",
      "            if  numpy.average(finl) <= numpy.std(finl)  or numpy.std(finl)>= 0.50 * numpy.average(finl):\n",
      "                print(\"kmeans called again\")\n",
      "                if countr<=5:\n",
      "                    k_means(finl)\n",
      "                    countr=countr+1\n",
      "\n",
      "            else:\n",
      "                print([numpy.average(finl),numpy.std(finl)] )    \n",
      "\n",
      "\n",
      "        else:\n",
      "            cluster(y,Cd,ncl)   \n",
      "\n",
      "\n",
      "serviceTypeIndex= get_col_index('jobType')\n",
      "totalAmountIndex= get_col_index('rate')\n",
      "bikeModelIndex=get_col_index('bikeModel')\n",
      "serviceTypeList= ['Paid Job','Warranty Repair','Free Service']           \n",
      "\n",
      "gml= get_model_list()\n",
      "n=len(gml)\n",
      "\n",
      "gml.remove('bikeModel')\n",
      "\n",
      "for k in gml:\n",
      "\n",
      "    cost1=[]\n",
      "    cost2=[];cost3=[];cost4=[];cost5=[];cost6=[];cost7=[];cost8=[]\n",
      "    r=[cost1,cost2,cost3,cost4,cost5,cost6,cost7,cost8]\n",
      "\n",
      "    for i in range(sheet.nrows):\n",
      "        if sheet.cell_value(i,bikeModelIndex)==k:\n",
      "\n",
      "            if sheet.cell_value(i,serviceTypeIndex) in serviceTypeList:\n",
      "\n",
      "                ind= serviceTypeList.index(sheet.cell_value(i,serviceTypeIndex))\n",
      "\n",
      "                c= sheet.cell_value(i,totalAmountIndex)\n",
      "\n",
      "                r[ind].append(c)\n",
      "\n",
      "    print( \"Information of \"+k+\" :\")\n",
      "    print(\"\")\n",
      "    for h in serviceTypeList:\n",
      "        index= serviceTypeList.index(h)\n",
      "\n",
      "        z= r[index]\n",
      "        if len(z)!=0 :\n",
      "            print(\"Is the effective cost and standard deviation of \"+h+\"  \"+ str(k_means(r[index])))\n",
      "\n",
      "    print(\"\")            \n",
      "\n",
      "I am trying to implement k-means using a recursive approach. I think the problem is with the cluster function in the else condition cluster(y,Cd,ncl) it it getting called endlessly till depth is reached.\n",
      "the traceback-\n",
      "print(\"Is the effective cost and standard deviation of \"+h+\"  \"+ str(k_means(r[index])))\n",
      "  File \"abcdef.py\", line 92, in k_means\n",
      "    rty= cluster(y,Cd,cl)\n",
      "  File \"abcdef.py\", line 180, in cluster\n",
      "    cluster(y,Cd,ncl)\n",
      "  File \"abcdef.py\", line 180, in cluster\n",
      "    cluster(y,Cd,ncl)\n",
      "  File \"abcdef.py\", line 180, in cluster\n",
      "    cluster(y,Cd,ncl)   \n",
      "\n",
      "so as we can see from the traceback the cluster(y,Cd,ncl) is called again n again.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086565/attributeerror-when-validating-schema-with-marshmallow\n",
      "AttributeError when validating schema with marshmallow\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am creating a POST and PUT route with marshmallow schema and sqlalchemy template but when I do the PUT or POST request I get an error. This error is generated when I validate to verify that the received object corresponds to the schema.\n",
      "\n",
      "Model SQLAlchemy\n",
      "\n",
      "class EquipmentModel(db.Model):\n",
      "    __tablename__ = \"equipments\"\n",
      "\n",
      "    id = db.Column(db.Integer, db.Sequence('equipment_id_seq'), primary_key=True, autoincrement=True)\n",
      "    model = db.Column(db.String(50), nullable=False)\n",
      "    serial_number = db.Column(db.String(50), nullable=False)\n",
      "    brand = db.Column(db.String(50), nullable=False)\n",
      "\n",
      "    def __init__(self, model, serial_number, brand, *args):\n",
      "        super().__init__(*args)\n",
      "        self.model = model\n",
      "        self.serial_number = serial_number\n",
      "        self.brand = brand\n",
      "\n",
      "    def __repr__(self):\n",
      "        return \"<EquipmentModel('%d', '%s')>\" % (self.id, self.brand)\n",
      "\n",
      "\n",
      "Schema Marshmallow\n",
      "\n",
      "from flask_marshmallow import Marshmallow\n",
      "from marshmallow import fields\n",
      "\n",
      "ma = Marshmallow()\n",
      "\n",
      "class EquipmentSchema(ma.ModelSchema):\n",
      "    id = fields.Integer(dump_only=True)\n",
      "    brand = fields.String(required=True)\n",
      "    model = fields.String(required=True)\n",
      "    serial_number = fields.String(required=True)\n",
      "\n",
      "\n",
      "Validation\n",
      "\n",
      "schema = EquipmentSchema()\n",
      "body = request.get_json(silent=True, force=True)\n",
      "body, errors = schema.load(body)\n",
      "\n",
      "\n",
      "When I do this I get the following error:\n",
      "\n",
      "AttributeError: 'NoneType' object has no attribute '__mapper__'\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086526/remove-specific-brackets-from-string\n",
      "Remove specific brackets from string\n",
      "\n",
      "\n",
      "I have a list of say: \n",
      "(UH[0], UH[1], UH[2], UH[3].... )\n",
      "\n",
      "I want to use re.sub to remove everything from each element of the list except the number so that it is \n",
      "(0 , 1 , 2 , 3 .....)\n",
      "\n",
      "I tried with: \n",
      "re.sub ('[UH^[]]' ,'', each_element)\n",
      "\n",
      "but it doesn't work.\n",
      "\n",
      "Answer\n",
      "\n",
      "re.findall might be an option too:\n",
      "import re\n",
      "\n",
      "string = 'UH[0], UH[1], UH[2], UH[3].... '\n",
      "print(re.findall(r'\\d+', string))\n",
      "\n",
      "Output\n",
      "['0', '1', '2', '3']\n",
      "You can try to replace them like\n",
      "In [1]: x = \"UH[0], UH[1], UH[2], UH[3]\"\n",
      "\n",
      "In [2]: result = x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"UH\", \"\")\n",
      "\n",
      "In [3]: result\n",
      "Out[3]: '0, 1, 2, 3'\n",
      "\n",
      "Hope it helps.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086522/in-python-how-to-go-from-a-value-to-the-name-of-the-variable-it-came-from\n",
      "In python, how to go from a value to the name of the variable it came from? [duplicate]\n",
      "\n",
      "\n",
      "This question already has an answer here:\n",
      "\n",
      "\n",
      "Getting the name of a variable as a string\n",
      "\n",
      "                    15 answers\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "For example, we have the scores of three courses stored in LIST.\n",
      "English, Maths, Physics = 89, 92, 93\n",
      "LIST = [English, Maths, Physics]\n",
      "for i in range(len(LIST)):\n",
      "    print(LIST[i])\n",
      "\n",
      "And I want the print style to be like English, 89, Maths, 92, Physics, 93. Here is a solution that defines another list LIST_name\n",
      "English, Maths, Physics = 89, 92, 93\n",
      "LIST = [English, Maths, Physics]\n",
      "LIST_name = ['English', 'Maths', 'Physics']\n",
      "for i in range(len(LIST)):\n",
      "    print(LIST_name[i], LIST[i])\n",
      "\n",
      "I am wondering if there is a built-in function or some other tricks that can help me directly convert English to \"English\", without defining LIST_name? And if so, how? As Barmar commented below, what I am looking for is how to go from a value to the name of the variable it came from?\n",
      "\n",
      "Answer\n",
      "\n",
      "You can have a method that takes variable keyword args as input and gives you dict with key value pair\n",
      " def marks(**m):\n",
      "  return m\n",
      "\n",
      " d=marks(English=90,Maths=100,Physics=90)  #call method with keyword args\n",
      " print(d)\n",
      "\n",
      "Output :\n",
      "   {'English': 90, 'Maths': 100, 'Physics': 90}\n",
      "\n",
      "You can also iterate dict\n",
      "for k,v in d.items():\n",
      "  print(k,v,sep=', ')\n",
      "\n",
      "Output\n",
      "English, 90\n",
      "Maths, 100\n",
      "Physics, 90\n",
      "Adding to @Deadpool's answer, you can use:\n",
      ">>> dict(English=82,Maths=92,Physics=93)\n",
      "{'English': 82, 'Maths': 92, 'Physics': 93}\n",
      ">>> \n",
      "\n",
      "More matching your case would be:\n",
      ">>> print('\\n'.join(map(lambda x: ', '.join(map(str, x)), dict(English=82,Maths=92,Physics=93).items())))\n",
      "English, 82\n",
      "Maths, 92\n",
      "Physics, 93\n",
      ">>>\n",
      "Define a class that represents the object that you're working with and override the __str__ (and optionally __repr__) function(s):\n",
      "class Course(object):\n",
      "    def __init__(self, name, score):\n",
      "        self.name = name\n",
      "        self.score = score\n",
      "    def __str__(self):\n",
      "        return self.name + ', ' + str(self.score)\n",
      "    def __repr__(self):\n",
      "        return '<{0}.{1} object at {2}> {3}'.format(self.__class__.__module__,\n",
      "                                            self.__class__.__name__,\n",
      "                                            hex(id(self)), str(self))\n",
      "\n",
      "English, Maths, Physics = list(map(lambda x:Course(*x), zip(['English','Math','Physics'],[89,92,93])))\n",
      "\n",
      "Or, combine with the other suggestions using dict:\n",
      "English,Maths,Physics = list(map(lambda x:Course(*x), dict(English=82,Maths=92,Physics=93).items()))\n",
      "\n",
      "And then you can:\n",
      ">>> LIST = [English, Maths, Physics]\n",
      ">>> for i in LIST:\n",
      "...     print(i)\n",
      "...\n",
      "English, 89\n",
      "Math, 92\n",
      "Physics, 93\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086495/runtime-error-element-0-of-tensors-does-not-require-grad-and-does-not-have-a\n",
      "[RUNTIME ERROR]: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "\n",
      "I’m working on a classification problem. I’m trying to classify URLs as malicious or benign. I’m implementing logistic regression for this problem, and here is my code:\n",
      "import torch\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import torch.nn as nn\n",
      "import torch.utils.data\n",
      "from torch.autograd import Variable\n",
      "\n",
      "class LogisticRegressionModel(nn.Module):\n",
      "\n",
      "    def __init__(self, in_dim, num_classes):\n",
      "        super().__init__()\n",
      "        self.linear = nn.Linear(in_dim, num_classes)\n",
      "\n",
      "    def forward(self, x):\n",
      "        out = self.linear(x)\n",
      "        return out\n",
      "\n",
      "class Train(LogisticRegressionModel):\n",
      "\n",
      "\n",
      "    def __init__(self, in_dim, num_classes, lr, batch_size):\n",
      "        super().__init__(in_dim, num_classes)\n",
      "        self.batch_size = batch_size\n",
      "        self.learning_rate = lr\n",
      "        self.input_layer_dim = in_dim\n",
      "        self.output_layer_dim = num_classes\n",
      "        self.criterion = nn.CrossEntropyLoss()\n",
      "        self.model = LogisticRegressionModel(self.input_layer_dim, self.output_layer_dim)\n",
      "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "        self.model = self.model.to(self.device)\n",
      "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = self.learning_rate)  \n",
      "\n",
      "    def epochs(self, iterations, train_dataset, batch_size):\n",
      "        epochs = int(iterations/(len(train_dataset)/batch_size))\n",
      "        return epochs\n",
      "\n",
      "    def train_model(self, training_data, n_iters):\n",
      "        batch = self.batch_size\n",
      "        epochs = self.epochs(n_iters, training_data, batch)\n",
      "        training_data = torch.utils.data.DataLoader(dataset = training_data, batch_size = batch, shuffle = False)\n",
      "\n",
      "        for epoch in range(epochs):\n",
      "            for i, data in enumerate(training_data):\n",
      "\n",
      "                X_train = data[:, :-1]\n",
      "                Y_train = data[:, -1]\n",
      "\n",
      "                if torch.cuda.is_available():\n",
      "                    x = Variable(X_train).cuda()\n",
      "                    y = Variable(Y_train).cuda()\n",
      "\n",
      "                else:\n",
      "                    x = X_train.float()\n",
      "                    y = Y_train.type(torch.LongTensor)\n",
      "\n",
      "                self.optimizer.zero_grad()\n",
      "                out = self.model(x).data\n",
      "                loss = self.criterion(out, y)\n",
      "                loss.backward()\n",
      "                self.optimizer.step()\n",
      "\n",
      "batch_size = 1000\n",
      "train_class = Train((training_set.shape[1]-1), number_of_target_labels+1, 0.001, batch_size)\n",
      "rain_class.train_model(training_set, batch_size)\n",
      "\n",
      "However, I get the following error when I run this code block:\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "I don't know why that is the case. If you'd like to have a look at my Notebook and the dataset, here is the link to it: https://github.com/islamaymansais/Malicious-URL-Classifier\n",
      "This is a classification project to classify URLs as benign or a malicious category (phishing, defacement, spam, malware). Let me know if you have any questions that I can clarify.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086486/accessing-the-list-of-list-specific-number-elements-and-merging-using-python\n",
      "Accessing the list of list specific number elements and merging using python\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a list of list elements in that i have to access specific number elements and merge them using python code.\n",
      "I have tried using list Comprehension but it is not working.\n",
      "myList = [['a:', 'b:', '4,80', 'c:', 'b:', '5,00', ':', '4,91', 'Pass'], ['a:', 'b:', '1,45', 'c:', 'b:', '1,55', 'd:', '1,51', 'Pass'], ['a:', 'b:', '-1,15', 'a:', 'b:', '-0,95', 'c:', '-1,07', 'Pass']]\n",
      "test = [myList [i] for i in [2,5,7]]\n",
      "            str1 = ''.join(test)\n",
      "            remove = int(str1.replace(',',''))\n",
      "            add_commas= \"{:,}\".format(remove)\n",
      "            conv_list = add_commas.split(',')\n",
      "            ac,ll,ut = conv_list[0],conv_list[1],conv_list[2]\n",
      "            print(ac,ll,ut)\n",
      "\n",
      "The expected output should be:\n",
      "[[480,500,491],[145,155,151],[-115,-095,-107]]\n",
      "\n",
      "Answer\n",
      "\n",
      "If you gather up just the characters you want, then you can return them with a function like:\n",
      "GOOD_CHARS = set('0123456789-+')\n",
      "\n",
      "def to_number(num_str):\n",
      "    return ''.join(c for c in num_str if c in GOOD_CHARS)\n",
      "\n",
      "Then if you drop any empty strings you will get what you are after.\n",
      "Test Code:\n",
      "my_list = [['a:', 'b:', '4,80', 'c:', 'b:', '5,00', ':', '4,91', 'Pass'],\n",
      "          ['a:', 'b:', '1,45', 'c:', 'b:', '1,55', 'd:', '1,51', 'Pass'],\n",
      "          ['a:', 'b:', '-1,15', 'a:', 'b:', '-0,95', 'c:', '-1,07', 'Pass']]\n",
      "\n",
      "print([[int(to_number(x)) for x in row if to_number(x)] for row in my_list])\n",
      "\n",
      "Results:\n",
      "[[480, 500, 491], [145, 155, 151], [-115, -95, -107]]\n",
      "Use isdigit() string method to check for number and then do int() to convert it to number\n",
      "In [1]: myList = [['a:', 'b:', '4,80', 'c:', 'b:', '5,00', ':', '4,91', 'Pass'], ['a:', 'b\n",
      "   ...: :', '1,45', 'c:', 'b:', '1,55', 'd:', '1,51', 'Pass'], ['a:', 'b:', '-1,15', 'a:',\n",
      "   ...:  'b:', '-0,95', 'c:', '-1,07', 'Pass']]\n",
      "In [2]: out = [[int(j.replace(',', '')) for j in i if j.replace(',', '').isdigit()] for i\n",
      "...:  in myList]\n",
      "\n",
      "In [3]: out \n",
      "Out[3]: [[480, 500, 491], [145, 155, 151], []]\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086454/removing-non-alphanumeric-unicode-characters-from-a-string-in-python\n",
      "Removing non-alphanumeric unicode characters from a string in Python\n",
      "\n",
      "\n",
      "How do I convert this string:\n",
      "\"\\xa0かかわらず\"\n",
      "\n",
      "to this string?:\n",
      "\"かかわらず\"\n",
      "\n",
      "i.e. How do I remove non-alphanumeric unicode characters? I've tried the solution that encodes the string as ascii, but it doesn't work for Japanese symbols.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086451/kivy-need-for-unschedule-for-event-created-using-clock-schedule-once\n",
      "Kivy - Need for unschedule for event created using Clock.schedule_once\n",
      "\n",
      "\n",
      "I am beginning to learn kivy and was just reading the documentation on events but I am unable to understand a certain part of it. \n",
      "Background\n",
      "The doc says to use Clock.schedule_once(callback,X) to execute callback after X seconds. However if X is 0, it will execute callback after the next frame.\n",
      "My Confusion\n",
      "Now the doc follows to say:\n",
      "\n",
      "Sometimes you may want to schedule a function to be called only once for the next frame, preventing duplicate calls.\n",
      "\n",
      "And advices not to do the following -\n",
      "# First, schedule once.\n",
      "event = Clock.schedule_once(my_callback, 0)\n",
      "\n",
      "# Then, in another place you will have to unschedule first\n",
      "# to avoid duplicate call. Then you can schedule again.\n",
      "Clock.unschedule(event)\n",
      "event = Clock.schedule_once(my_callback, 0)\n",
      "\n",
      "But instead use a trigger -\n",
      "trigger = Clock.create_trigger(my_callback)\n",
      "# later\n",
      "trigger()\n",
      "\n",
      "\n",
      "Each time you call trigger(), it will schedule a single call of your callback. If it was already scheduled, it will not be rescheduled.\n",
      "\n",
      "My confusion is why does the first method not work? Isn't the method schedule_once() to execute the callback exactly once? Why is there a possibility of duplicate as mentioned in the first approach?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086447/working-with-classes-and-setters-and-getters\n",
      "Working with classes and setters and getters\n",
      "\n",
      "\n",
      "I need to Create a class called Color.  \n",
      "\n",
      "Code 1 constructor\n",
      "That requires 2 parameters  \n",
      "Code 2 properties\n",
      "1 property is public\n",
      "1 property is private\n",
      "Create an accessor and setter for the 1 private property\n",
      "Instantiate the class created above\n",
      "Output the two properties\n",
      "\n",
      "\n",
      "I believe I have been able to create the class and as well the constructor but where am having my issues is the public/private properties as well as the other parts are troubling me.\n",
      "class Color:\n",
      "   def __init__(self,full_name,birthday ):\n",
      "       self.name = full_name\n",
      "       self.birthday = birthday\n",
      "\n",
      "   def age(self):\n",
      "      return self.birthday\n",
      "\n",
      "   def fname(self):\n",
      "       return _self.name\n",
      "\n",
      "object = Color()\n",
      "\n",
      "Answer\n",
      "\n",
      "Using python @property getters and setters decorators, the calls to these from an instance are undistinguishable.\n",
      "The inner workings follow the leading underscore convention for private attributes, without resorting to double underscore name mangling.\n",
      "class Homework:\n",
      "\n",
      "    def __init__(self, param1, param2):\n",
      "        self._param1 = param1    # private attribute\n",
      "        self.param2 = param2     # public attribute\n",
      "\n",
      "    @property\n",
      "    def param1(self):\n",
      "        \"\"\"accessor for private parameter\n",
      "        \"\"\"\n",
      "        return self._param1\n",
      "\n",
      "    @param1.setter\n",
      "    def param1(self, value):\n",
      "        \"\"\"setter for private parameter\n",
      "        \"\"\" \n",
      "        self._param1 = value\n",
      "\n",
      "homework = Homework('The great secret', 'The public life of Napoleon')\n",
      "\n",
      "# accessing the parameters follow the same syntax\n",
      "print(homework.param1)\n",
      "print(homework.param2)\n",
      "\n",
      "# setting the parameters also follow the dotted syntax\n",
      "homework.param1 = \"you won't believe it\"    \n",
      "homework.param2 = 'but the dog ate it'    \n",
      "\n",
      "print(homework.param1)\n",
      "print(homework.param2)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086446/stats-f-oneway-scipy-anova-returns-2-arrays-with-4-values\n",
      "stats.f_oneway Scipy Anova returns 2 arrays with 4 values\n",
      "\n",
      "\n",
      "Trying to run one way Anova on data which looks approximately like this: \n",
      "Year   | Diversity  |\n",
      "2010   |   6        |\n",
      "2010   |   8        |\n",
      "...    |   ...      |\n",
      "2011   |   10       |\n",
      "...    |   ...      |\n",
      "2019   |   7        |\n",
      "\n",
      "There are 1827 rows, diversity values for various points within the range of each year. I am comparing the variance year on year. When I do\n",
      "F, p = stats.f_oneway(df.loc[df[\"Year\"] == 2010],\n",
      "               df.loc[df[\"Year\"] == 2011],\n",
      "               df.loc[df[\"Year\"] == 2012])\n",
      "\n",
      "(Here I omitted the rest of the groups because this is very ugly but I couldn't figure out how else to pass the different groups for the Anova test). I get an array with 2 values each for F and p: \n",
      "F: type float64, size (2,),\n",
      "-2.588805281700000000e+11, 4.908743340532151223e+00\n",
      "p: type float64, size (2,),\n",
      "nan, 0.00774507\n",
      "\n",
      "From what I read, I can't find anyone getting 2 arrays, it should be just one F value and one P value, I am doing something seriously wrong? \n",
      "(There are no zeroes or NANs in the df). \n",
      "When I do: \n",
      "mod = ols('Diversity ~ (Year)', data = df).fit()\n",
      "mod.summary()\n",
      "\n",
      "I get a normal Summary table, with F = 1.462, p = 0.227 (different to my attempts above). \n",
      "Any ideas on my mess would be greatly appreciated...\n",
      "\n",
      "Answer\n",
      "\n",
      "Your DataFrame has 2 columns, even after you slice it, thus you return 2 p-values and 2 F-values, one for the comparison of each column across samples. You should change each selection to only include the 'Diversity' column, like: \n",
      "df.loc[df['Year'] == 2010, 'Diversity']\n",
      "\n",
      "If you just want to do an ANOVA for Diversity across all years in your sample, you can do this compactly with:\n",
      "stats.f_oneway(*[s for idx, s in df.groupby('Year').Diversity])\n",
      "\n",
      "\n",
      "MCVE\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "\n",
      "l = [pd.DataFrame(np.random.randint(1, 10, (50, 4))) for i in range(7)]\n",
      "                                              # |\n",
      "                                              # 4 cols, should get 4 p-vals/F-vals\n",
      "\n",
      "stats.f_oneway(*l)\n",
      "#F_onewayResult(statistic=array([0.70527759, 0.2291319 , 0.03545031, 0.02568242]), \n",
      "#                  pvalue=array([0.49563511, 0.79550711, 0.96517894, 0.97464894]))\n",
      "                               #    col1         col2        col3       col4\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086433/about-iteratively-accessing-a-function-itertools-method-in-python\n",
      "About iteratively accessing a function (“itertools” method) in python\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wrote a python code using the itertools method in python because I want to iteratively give the p_vec to the following function, \n",
      "import numpy as np\n",
      "from itertools import islice\n",
      "\n",
      "x1=np.array([1,2,3,4])\n",
      "p1=np.array([.1,.2,.3,.4])\n",
      "\n",
      "def fun1 (x_vec,p_vec):\n",
      "    x11=np.zeros(len(x_vec))\n",
      "    p11=np.zeros(len(p_vec))\n",
      "\n",
      "    for i in range (0,len(x_vec)):\n",
      "        x11[i] =x_vec[i]**2\n",
      "\n",
      "        while True:\n",
      "            p11[i]=x11[i]*p_vec[i]\n",
      "\n",
      "            yield x11 ,p11\n",
      "\n",
      "\n",
      "my_iterator = fun1(x1, p1) \n",
      "\n",
      "for values in islice(my_iterator, 0, 4):  \n",
      "    print(values)\n",
      "\n",
      "The code didnt give any errors. But the output i got appears follows,\n",
      "(array([1., 0., 0., 0.]), array([0.1, 0. , 0. , 0. ]))\n",
      "(array([1., 0., 0., 0.]), array([0.1, 0. , 0. , 0. ]))\n",
      "(array([1., 0., 0., 0.]), array([0.1, 0. , 0. , 0. ]))\n",
      "(array([1., 0., 0., 0.]), array([0.1, 0. , 0. , 0. ]))\n",
      "\n",
      "I wrote a code that do the same thing manually,\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "x1=np.array([1,2,3,4])\n",
      "p1=np.array([.1,.2,.3,.4])\n",
      "\n",
      "def fun1 (x_vec,p_vec):\n",
      "    x11=np.zeros(len(x_vec))\n",
      "    p11=np.zeros(len(p_vec))\n",
      "\n",
      "    for i in range (0,len(x_vec)):\n",
      "        x11[i] =x_vec[i]**2\n",
      "        p11[i]=x11[i]*p_vec[i]\n",
      "\n",
      "    return x11 ,p11\n",
      "\n",
      "First Iteration \n",
      " x2=np.array(len(x1))\n",
      "    p2=np.array(len(p1))\n",
      "\n",
      "    x2 ,p2 = fun1(x1,p1)\n",
      "\n",
      "Second Iteration \n",
      " x3=np.array(len(x1))\n",
      "    p3=np.array(len(p1))\n",
      "\n",
      "    x3 ,p3 = fun1(x1,p2)\n",
      "\n",
      "So in the second iteration , i used p2  which was obtained from the previous iteration. \n",
      "Third Iteration \n",
      "x4=np.array(len(x1))\n",
      "p4=np.array(len(p1))\n",
      "\n",
      "x4 ,p4 = fun1(x1,p3)\n",
      "\n",
      "print(\"p\",p2)\n",
      "print(\"x\",x2)\n",
      "\n",
      "print(\"p\",p3)\n",
      "print(\"x\",x3)\n",
      "\n",
      "print(\"p\",p3)\n",
      "print(\"x\",x4)\n",
      "\n",
      "Based on this, My desired output should be something like this (for 3 iterations)\n",
      "p [0.1 0.8 2.7 6.4]\n",
      "x [ 1.  4.  9. 16.]\n",
      "p [1.000e-01 3.200e+00 2.430e+01 1.024e+02]\n",
      "x [ 1.  4.  9. 16.]\n",
      "p [1.000e-01 3.200e+00 2.430e+01 1.024e+02]\n",
      "x [ 1.  4.  9. 16.]\n",
      "\n",
      "can anyone suggest what should I modify to get the correct result?\n",
      "Thank you.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086398/how-do-you-clear-google-colabs-output-periodically\n",
      "How do you clear Google Colab's output periodically\n",
      "\n",
      "\n",
      "I am using Google Colab to train an object detection model using the tensorflow object detection api. When I run the cell train.py, it keeps printing the loss at each step and eventually after 30 minutes or so, the browser crashes because of the number of lines printed as the cell's output.\n",
      "Is there any script which one can use to clear the output periodically(say every 30 min) instead of manually pressing I am using Google Colab to train an object detection model using the tensorflow object detection api. When I run the cell train.py, it keeps printing the loss at each step and eventually after 30 minutes or so, the browser crashes because of the number of lines printed as the cell's output.\n",
      "the clear output button?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086368/pandas-dataframe-slicing-pythonic-idiom-for-order-of-row-v-column\n",
      "pandas dataframe slicing - pythonic idiom for order of row v column?\n",
      "\n",
      "\n",
      "Given a DataFrame of this format\n",
      "                     Temperature  DewPoint  Pressure\n",
      "Date                                                \n",
      "2010-01-01 00:00:00         46.2      37.5       1.0\n",
      "2010-01-01 01:00:00         44.6      37.1       1.0\n",
      "2010-01-01 02:00:00         44.1      36.9       1.0\n",
      "2010-01-01 03:00:00         43.8      36.9       1.0\n",
      "2010-01-01 04:00:00         43.5      36.8       1.0\n",
      "2010-01-01 05:00:00         43.3      37.3       1.0\n",
      "...\n",
      "2010-01-01 21:00:00         48.1      38.5       1.0\n",
      "2010-01-01 22:00:00         47.2      38.5       1.0\n",
      "2010-01-01 23:00:00         46.4      38.4       1.0\n",
      "2010-01-02 00:00:00         46.5      38.2       1.0\n",
      "2010-01-02 01:00:00         44.9      37.8       1.0\n",
      "...                          ...       ...       ...\n",
      "2010-12-31 22:00:00         46.9      37.9       1.0\n",
      "2010-12-31 23:00:00         46.2      37.7       1.0\n",
      "\n",
      "Using partial string indexing to extract temperature data from August 1 2010 to August 15 2010, the following appear to be equivalent\n",
      "d1 = df['Temperature']['2010-Aug-01':'2010-Aug-15']\n",
      "\n",
      "d2 = df['2010-Aug-01':'2010-Aug-15']['Temperature']\n",
      "\n",
      "I assume pandas is \"smart enough\" to do the right thing, but I was surprised. I was thinking dictionary format and would have assumed the index (key) should come first with the value (column) choice second.\n",
      "Is there a recommended order?  \n",
      "[column][index]\n",
      "\n",
      "vs\n",
      "[index][column]\n",
      "\n",
      "for writing the code or does it not matter how I write it because pandas understands and so would anyone reading the code?\n",
      "\n",
      "Answer\n",
      "\n",
      "You should using .loc\n",
      "d1 = df.loc['2010-08-01':'2010-08-15','Temperature']\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086340/python-flask-how-to-run-subprocess-unset-env-variable\n",
      "Python Flask - how to run subprocess (unset ENV variable)?\n",
      "\n",
      "\n",
      "I have a running Flask app but need to unset ENV variable in the moment of startup.\n",
      "In linux - command is:\n",
      "unset http_proxy\n",
      "How to execute that in the Flask app right after import block?\n",
      "Thanks.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086301/basic-neural-network-on-mnist-using-tensorflow-2-0\n",
      "Basic neural network on MNIST using tensorflow 2.0?\n",
      "\n",
      "\n",
      "I tried to write a basic neural network with two hidden layers on MNIST dataset using tensorflow 2.0 beta but I'm not sure what went wrong here but the loss/acc I got was incorrect. \n",
      "I'll appreciate if someone could help me out. Also If there's something I could improve in the code do let me know as well.\n",
      "Here's my full code for easy reproducibility: \n",
      "import numpy as np\n",
      "import os\n",
      "import logging\n",
      "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
      "import tensorflow as tf\n",
      "import tensorflow_datasets as tfds\n",
      "\n",
      "(x_train, y_train), (x_test, y_test) = tfds.load('mnist', split=['train', 'test'], \n",
      "                                                  batch_size=-1, as_supervised=True)\n",
      "\n",
      "# reshaping\n",
      "x_train = tf.reshape(x_train, shape=(x_train.shape[0], 784))\n",
      "x_test  = tf.reshape(x_test, shape=(x_test.shape[0], 784))\n",
      "\n",
      "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
      "# rescaling\n",
      "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y))\n",
      "\n",
      "class Model(object):\n",
      "    def __init__(self, hidden1_size, hidden2_size, device=None):\n",
      "        # layer sizes along with input and output\n",
      "        self.input_size, self.output_size, self.device = 784, 10, device\n",
      "        self.hidden1_size, self.hidden2_size = hidden1_size, hidden2_size\n",
      "        self.lr_rate = 1e-03\n",
      "\n",
      "        # weights initializationg\n",
      "        self.glorot_init = tf.initializers.glorot_uniform(seed=42)\n",
      "        # weights b/w input to hidden1 --> 1\n",
      "        self.w_h1 = tf.Variable(self.glorot_init((self.input_size, self.hidden1_size)))\n",
      "        # weights b/w hidden1 to hidden2 ---> 2\n",
      "        self.w_h2 = tf.Variable(self.glorot_init((self.hidden1_size, self.hidden2_size)))\n",
      "        # weights b/w hidden2 to output ---> 3\n",
      "        self.w_out = tf.Variable(self.glorot_init((self.hidden2_size, self.output_size)))\n",
      "\n",
      "        # bias initialization\n",
      "        self.b1 = tf.Variable(self.glorot_init((self.hidden1_size,)))\n",
      "        self.b2 = tf.Variable(self.glorot_init((self.hidden2_size,)))\n",
      "        self.b_out = tf.Variable(self.glorot_init((self.output_size,)))\n",
      "\n",
      "        self.variables = [self.w_h1, self.b1, self.w_h2, self.b2, self.w_out, self.b_out]\n",
      "\n",
      "\n",
      "    def feed_forward(self, x):\n",
      "        if self.device is not None:\n",
      "            with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
      "                # layer1\n",
      "                self.layer1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.w_h1), self.b1))\n",
      "                # layer2\n",
      "                self.layer2 = tf.nn.sigmoid(tf.add(tf.matmul(self.layer1,\n",
      "                                                             self.w_h2), self.b2))\n",
      "                # output layer\n",
      "                self.output = tf.nn.softmax(tf.add(tf.matmul(self.layer2,\n",
      "                                                             self.w_out), self.b_out))\n",
      "        return self.output\n",
      "\n",
      "    def loss_fn(self, y_pred, y_true):\n",
      "        self.loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, \n",
      "                                                                  logits=y_pred)\n",
      "        return tf.reduce_mean(self.loss)\n",
      "\n",
      "    def acc_fn(self, y_pred, y_true):\n",
      "        y_pred = tf.cast(tf.argmax(y_pred, axis=1), tf.int32)\n",
      "        y_true = tf.cast(y_true, tf.int32)\n",
      "        predictions = tf.cast(tf.equal(y_true, y_pred), tf.float32)\n",
      "        return tf.reduce_mean(predictions)\n",
      "\n",
      "    def backward_prop(self, batch_xs, batch_ys):\n",
      "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr_rate)\n",
      "        with tf.GradientTape() as tape:\n",
      "            predicted = self.feed_forward(batch_xs)\n",
      "            step_loss = self.loss_fn(predicted, batch_ys)\n",
      "        grads = tape.gradient(step_loss, self.variables)\n",
      "        optimizer.apply_gradients(zip(grads, self.variables))\n",
      "\n",
      "neural_net = Model(512, 256, 'gpu')\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    no_steps = n_shape//batch_size\n",
      "    avg_loss = 0.\n",
      "    avg_acc = 0.\n",
      "    for (batch_xs, batch_ys) in ds_train.take(no_steps):\n",
      "        preds = neural_net.feed_forward(batch_xs)\n",
      "        avg_loss += neural_net.loss_fn(preds, batch_ys)\n",
      "        avg_acc += neural_net.acc_fn(preds, batch_ys)\n",
      "        neural_net.backward_prop(batch_xs, batch_ys)\n",
      "    print(f'Epoch: {epoch}, Training Loss: {avg_loss}, Training ACC: {avg_acc}')\n",
      "\n",
      "# output for 3 epochs:\n",
      "Epoch: 0, Training Loss: 796.0076293945312, Training ACC: 356.0390625\n",
      "Epoch: 1, Training Loss: 748.853515625, Training ACC: 401.9609375\n",
      "Epoch: 2, Training Loss: 742.2123413085938, Training ACC: 407.9453125\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086287/indexing-new-dataframes-into-new-columns-with-pandas\n",
      "Indexing new dataframes into new columns with pandas\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to create a new dataframe from an existing one by selecting multiple columns, and appending those column values to a new column with it's corresponding index as a new column\n",
      "So, lets say I have this as a dataframe:\n",
      "A B C D E F\n",
      "0 1 2 3 4 0\n",
      "0 7 8 9 1 0\n",
      "0 4 5 2 4 0\n",
      "\n",
      "Transform into this by selecting columns B through E:\n",
      "A index_value\n",
      "1 1\n",
      "7 1\n",
      "4 1\n",
      "2 2\n",
      "8 2\n",
      "5 2\n",
      "3 3\n",
      "9 3\n",
      "2 3\n",
      "4 4\n",
      "1 4\n",
      "4 4\n",
      "\n",
      "So, for the new dataframe, column A would be all of the values from columns B through E in the old dataframe, and column index_value would correspond to the index value [starting from zero] of the selected columns.\n",
      "I've been scratching my head for hours. Any help would be appreciated, thanks!\n",
      "Python3, Using pandas & numpy libraries.\n",
      "\n",
      "Answer\n",
      "\n",
      "This is just melt \n",
      "df.columns = range(df.shape[1])\n",
      "s = df.melt().loc[lambda x : x.value!=0]\n",
      "s\n",
      "    variable  value\n",
      "3          1      1\n",
      "4          1      7\n",
      "5          1      4\n",
      "6          2      2\n",
      "7          2      8\n",
      "8          2      5\n",
      "9          3      3\n",
      "10         3      9\n",
      "11         3      2\n",
      "12         4      4\n",
      "13         4      1\n",
      "14         4      4\n",
      "Try using:\n",
      "df = pd.melt(df[['B', 'C', 'D', 'E']])\n",
      "# Or df['variable'] = df[['B', 'C', 'D', 'E']].melt()\n",
      "df['variable'].shift().eq(df['variable'].shift(-1)).cumsum().shift(-1).ffill()\n",
      "print(df)\n",
      "\n",
      "Output:\n",
      "    variable  value\n",
      "0        1.0      1\n",
      "1        1.0      7\n",
      "2        1.0      4\n",
      "3        2.0      2\n",
      "4        2.0      8\n",
      "5        2.0      5\n",
      "6        3.0      3\n",
      "7        3.0      9\n",
      "8        3.0      2\n",
      "9        4.0      4\n",
      "10       4.0      1\n",
      "11       4.0      4\n",
      "#Another way\n",
      "\n",
      "    A   B   C   D   E   F\n",
      "0   0   1   2   3   4   0\n",
      "1   0   7   8   9   1   0\n",
      "2   0   4   5   2   4   0\n",
      "\n",
      "# Select columns to include\n",
      "\n",
      "start_colum ='B'\n",
      "end_column ='E'\n",
      "index_column_name ='A'\n",
      "\n",
      "#re-stack the dataframe\n",
      "\n",
      "df = df.loc[:,start_colum:end_column].stack().sort_index(level=1).reset_index(level=0, drop=True).to_frame()\n",
      "\n",
      "#Create the \"index_value\" column \n",
      "\n",
      "df['index_value'] =pd.Categorical(df.index).codes+1\n",
      "\n",
      "df.rename(columns={0:index_column_name}, inplace=True)\n",
      "\n",
      "df.set_index(index_column_name, inplace=True)\n",
      "\n",
      "df\n",
      "\n",
      "    index_value\n",
      "A   \n",
      "1   1\n",
      "7   1\n",
      "4   1\n",
      "2   2\n",
      "8   2\n",
      "5   2\n",
      "3   3\n",
      "9   3\n",
      "2   3\n",
      "4   4\n",
      "1   4\n",
      "4   4\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086268/is-there-a-viable-way-to-cluster-geo-spatial-data-while-considering-boundary-lin\n",
      "Is there a viable way to cluster geo-spatial data while considering boundary line segments?\n",
      "\n",
      "\n",
      "I am attempting to cluster lat/long coordinates into a specified number of densely created clusters but need to consider line segment boundaries - if the line segment between any two data points intersects a list of specified line segments (say 4 line segments --> Identified by start/end lat/long) then the points should not be clustered together. Because this is geo-spatial data I am looking to cluster around specific \"geographies\" that can not easily be interpreted from the clustering algorithms I am currently using. An initial thought was to modify the upper triangle of a distance matrix that is inputted into the clustering algorithm, looping through each entry of the triangle, checking the line segment against the \"boundaries\" and replacing the distance with a large value if intersection is found. This however is incredibly computationally hard (or at least the configuration I have set-up), and I am unable to manipulate the data in a reasonable amount of time.\n",
      "To give a representation of the scale, these data sets may consist of anywhere form 1,000-50,000 Lat/Long pairs.\n",
      "I have attempted to \"structure\" the data by utilizing the \"kneighbors_graph\" in Python to develop a connectivity matrix based on the KNN algorithm but it does not solve the issue (with varying values of k).Example followed: https://scikit-learn.org/stable/auto_examples/cluster/plot_ward_structured_vs_unstructured.html\n",
      "This ended up utilizing an Agglomerative Clustering approach which did not yield the results I was hoping (clusters still spanning across different geographies, and uneven cluster sizes - one as majority of the dataset).\n",
      "In R I have attempted the aforementioned line segment method to adjust the distance matrix being fed into the k-means algorithm, but stopped the code execution after about an hour of computation (and the upper triangle was barely processed!), which makes me think it has to do with my implementation. I will paste my method below (the line segments are read in from a csv file as a dataframe with start_lat,start_long,end_lat,end_long -hence the \"barrier[k,...]\" calls)\n",
      "Any and all help is appreciated in terms of general ideology on how to approach the problem or even specific code implementations that could speed up the processing idea I've mentioned. I also looked into the sweeping line algorithm but have not been able to wrap my head around an efficient way to implement that into the overall script.\n",
      "#Load CSV of barrier line segments\n",
      "barrier <- read.csv(\"LineSegments.csv\")\n",
      "\n",
      "#Create distance matrix from Lat/Long Dataframe\n",
      "distMatrix <- as.matrix(dist(LatLongDf))\n",
      "q <- nrow(distMatrix)\n",
      "\n",
      "#Loop through upper triangle of matrix without diagonal\n",
      "for (i in 1:(q-1)){\n",
      "    for (j in (i+1):q) {\n",
      "\n",
      "        #Grab row/column index of matrix (point IDs) and remap to original DF for point lat/longs\n",
      "        c1 <- c(LatLongDf[rownames(distMatrix)[i][1],LatLongDf[rownames(distMatrix)[i][2])\n",
      "        c2 <- c(LatLongDf[rownames(distMatrix)[j][1],LatLongDf[rownames(distMatrix)[j][2])\n",
      "\n",
      "        #Loop through inputted line segments\n",
      "        for (k in 1:nrow(barrier)) {\n",
      "             #Get point of intersection between two segments\n",
      "             dp <- line.line.intersection(c1,c2,c(barrier[k,2],barrier[k,3]),c(barrier[k,4],barrier[k,5]),interior.only = TRUE)\n",
      "             #If the lines do not intersect then set distance to max\n",
      "             if (is.na(dp[1])) {\n",
      "                  distMatrix[i,j] <- max(distMatrix)\n",
      "                  break\n",
      "             }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086256/finding-width-and-height-of-inward-curved-blob\n",
      "Finding Width and height of inward curved blob\n",
      "\n",
      "\n",
      "I have been scratching my head over this problem of calculation of width and height measurements of figure like below\n",
      "The major challenge is i cant use miBoundingrectangle and cant figure out a way for bounding from inside , either way i ll lose some pixels for height and width measurement. \n",
      "Sample Input :\n",
      "\n",
      "Sample Output:\n",
      "\n",
      "Is there any fail proof(the dimension measurement is as close to accurate) way i can get help with ?\n",
      "Below is a solution i was trying out to find inner bounding max rectangle. \n",
      "_,contour2,_=cv2.findContours(im,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)\n",
      "for c in contour2:\n",
      "    area=cv2.contourArea(c)\n",
      "    if area ==25224.0:\n",
      "        print(area)\n",
      "        n = np.squeeze(contour2[0])\n",
      "\n",
      "        x = sorted(n, key=lambda a:a[0])\n",
      "        left = x[0]\n",
      "        right = x[-1]\n",
      "        print(\"\",left,right)\n",
      "        y= sorted(n, key=lambda a:a[1])\n",
      "        top = y[0]\n",
      "        bottom = y[-1]\n",
      "        cv2.drawContours(im,[c],-1,(128,128,128),2)\n",
      "        cv2.circle(im, (left[0],left[1]), 4, (128,128,128), 8)\n",
      "        cv2.circle(im, (right[0],right[1]), 4, (128,128,128), 8)\n",
      "        cv2.circle(im, (top[0],top[1]), 4, (128,128,128), 8)\n",
      "        cv2.circle(im, (bottom[0],bottom[1]), 4, (128,128,128), 8)\n",
      "\n",
      "        roi_w = int(np.sqrt((top[0]-right[0])*(top[0]-right[0])(top[1]-right[1])*(top[1]-right[1])))\n",
      "        roi_h = int(np.sqrt((top[0]-left[0])*(top[0]-left[0])+(top[1]-left[1])*(top[1]-left[1])))\n",
      "                pts1 = np.float32([top,right,left])\n",
      "\n",
      "        new_top = top\n",
      "        new_right = [top[0] + roi_w, top[1]]\n",
      "        new_left = [top[0], top[1] + roi_h]\n",
      "        pts2 = np.float32([new_top,new_right,new_left])\n",
      "\n",
      "     cv2.imshow(\"threshed\", im)`\n",
      "\n",
      "Answer\n",
      "\n",
      "Here's an OpenCV solution. The main idea is\n",
      "\n",
      "Convert image to grayscale and invert\n",
      "Find contour and find center of the contour\n",
      "Count all row pixels and all column pixels to determine width/height\n",
      "\n",
      "\n",
      "We convert image to grayscale and invert it. This is the image we will count pixels on since the desired ROI is in white\n",
      "\n",
      "From here, we find the main contour and find the center using cv2.moments(). This gives us the centroid (i.e., the center (x, y)-coordinates of the object)\n",
      "M = cv2.moments(c)\n",
      "cX = int(M[\"m10\"] / M[\"m00\"])\n",
      "cY = int(M[\"m01\"] / M[\"m00\"])\n",
      "\n",
      "Next we use Numpy slicing to obtain all the row and column pixels. We use cv2.countNonZero() to find the width/height of the row/column like this\n",
      "row_pixels = cv2.countNonZero(gray[cY][:])\n",
      "column_pixels = cv2.countNonZero(gray[:, cX])\n",
      "\n",
      "Here's a visualization\n",
      "\n",
      "Remember we use cv2.countNonZero() on the inverted image since the desired blob is in white. Here's the result\n",
      "\n",
      "row 150\n",
      "column 354\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "image = cv2.imread('1.png')\n",
      "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "gray = 255 - gray\n",
      "\n",
      "cnts = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
      "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
      "\n",
      "for c in cnts:\n",
      "    M = cv2.moments(c)\n",
      "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
      "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
      "\n",
      "    cv2.circle(image, (cX, cY), 5, (36, 255, 12), -1)\n",
      "    image[cY][:] = (36, 255, 12)\n",
      "    image[:, cX] = (36, 255, 12)\n",
      "    row_pixels = cv2.countNonZero(gray[cY][:])\n",
      "    column_pixels = cv2.countNonZero(gray[:, cX])\n",
      "\n",
      "print('row', row_pixels)\n",
      "print('column', column_pixels)\n",
      "cv2.imshow('image', image)\n",
      "cv2.imwrite('image.png', image)\n",
      "cv2.waitKey(0)\n",
      "This is an Imagemagick solution. But the concept will give you a clue how to proceed with OpenCV. It is not quite the dimensions you want. But the closest way I could conceive. Basically, it is the maximum inside bounding box. Perhaps there is something similar in OpenCV.\n",
      "Iterate around each edge of the image from outside towards the inside until each remaining edge is fully black with no white (or reasonably close to that).\n",
      "Input:\n",
      "\n",
      "convert img.png -threshold 0 -define trim:percent-background=0% -trim +repage -format \"%wx%h\" +write info: result.png\n",
      "\n",
      "returns: widthxheight => 144x317\n",
      "\n",
      "\n",
      "\n",
      "ADDITION:\n",
      "Here is another solution that should be easy to do in OpenCV.\n",
      "Trim to get the minimum outer bounding box. Extract the center row and column, which may have some white on the ends. Then pad with white all around. Then trim all the white again so you have one black row and column remaining with no white. Then get the dimensions of the single black row and single black column.\n",
      "width=`convert img.png -threshold 0 -trim +repage -gravity center -crop x1+0+0 +repage -bordercolor white -border 1x1 -trim +repage -format \"%w\" info:`\n",
      "height=`convert img.png -threshold 0 -trim +repage -gravity center -crop 1x+0+0 +repage -bordercolor white -border 1x1 -trim +repage -format \"%h\" info:`\n",
      "echo \"width=$width; height=$height;\"\n",
      "returns: => width=145; height=352;\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086250/how-to-extract-xml-attribute-using-beautifulsoup-and-python\n",
      "How to extract xml attribute using beautifulsoup and python\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm trying to extract the 'totalvotes' value from this xml:\n",
      "<poll title=\"User Suggested Number of Players\" totalvotes=\"0\" name=\"suggested_numplayers\">\n",
      "<results numplayers=\"3+\"> </results>\n",
      "</poll>\n",
      "\n",
      "I've messed around with so many different combinations of the following code, but none of them work.\n",
      "soup.find_all('poll',{'title':'User Suggested Number of Players'})[0].find_all('totalvotes')\n",
      "\n",
      "I'm simply trying to retrieve the value of 0, in this case. How do I do this?\n",
      "Thank you.\n",
      "\n",
      "Answer\n",
      "\n",
      "To extract from first element\n",
      "soup.find('poll').get('totalvotes')\n",
      "\n",
      "To extract from all the elements\n",
      "for poll in soup.find_all('poll'):\n",
      "    print (poll.get('totalvotes'))\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086239/how-to-fix-indexing-or-reading-a-specific-value-of-a-key-were-the-occurrence-of\n",
      "How to fix indexing or reading a specific value of a key, were the occurrence of the key changes dynamically\n",
      "\n",
      "\n",
      "I have a code to capture the values associated to the below keys from a json file. were i have converted the json file into dict function and reading the value. At a point were the occurrence / line number of the key varies based on the json file i choose.\n",
      "Keys:\n",
      "In\n",
      "Name\n",
      "required\n",
      "type\n",
      "Need help to have a standard code / customizing the existing code even if the occurrence or line number changes in the json file.\n",
      "Given below the sample json content i am trying, Please have a detailed look into the below json content. as the occurrence will vary from one API endpoint to other.\n",
      "swagger: '2.0'\n",
      "info:\n",
      "  description: >-\n",
      "    This is a sample server Petstore server.  You can find out more about\n",
      "    Swagger at http://swagger.io or on irc.freenode.net,\n",
      "    #swagger.      For this sample, you can use the api\n",
      "    key special-key to test the authorization     filters.\n",
      "  version: 1.0.0\n",
      "  title: Swagger Petstore\n",
      "  termsOfService: 'http://swagger.io/terms/'\n",
      "  contact:\n",
      "    email: apiteam@swagger.io\n",
      "  license:\n",
      "    name: Apache 2.0\n",
      "    url: 'http://www.apache.org/licenses/LICENSE-2.0.html'\n",
      "host: petstore.swagger.io\n",
      "basePath: /v2\n",
      "tags:\n",
      "  - name: pet\n",
      "    description: Everything about your Pets\n",
      "    externalDocs:\n",
      "      description: Find out more\n",
      "      url: 'http://swagger.io'\n",
      "  - name: store\n",
      "    description: Access to Petstore orders\n",
      "  - name: user\n",
      "    description: Operations about user\n",
      "    externalDocs:\n",
      "      description: Find out more about our store\n",
      "      url: 'http://swagger.io'\n",
      "schemes:\n",
      "  - https\n",
      "  - http\n",
      "paths:\n",
      "  /pet:\n",
      "    post:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Add a new pet to the store\n",
      "      description: ''\n",
      "      operationId: addPet\n",
      "      consumes:\n",
      "        - application/json\n",
      "        - application/xml\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - $ref: '#/parameters/Pets'\n",
      "        - $ref: '#/parameters/petname'\n",
      "        - $ref: '#/parameters/petid'\n",
      "        - $ref: '#/parameters/petsd'\n",
      "        - $ref: '#/parameters/sampletag'\n",
      "        - $ref: '#/parameters/report-pets'\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: Pet object that needs to be added to the store\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/Pet'\n",
      "      responses:\n",
      "        '405':\n",
      "          description: Invalid input\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "    put:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Update an existing pet\n",
      "      description: ''\n",
      "      operationId: updatePet\n",
      "      consumes:\n",
      "        - application/json\n",
      "        - application/xml\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: Pet object that needs to be added to the store\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/Pet'\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Pet not found\n",
      "        '405':\n",
      "          description: Validation exception\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "  /pet/findByStatus:\n",
      "    get:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Finds Pets by status\n",
      "      description: Multiple status values can be provided with comma separated strings\n",
      "      operationId: findPetsByStatus\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - $ref: '#/parameters/dummy'\n",
      "        - $ref: '#/parameters/X-sample'\n",
      "        - $ref: '#/parameters/X-pets'\n",
      "        - $ref: '#/parameters/X-pet-id'\n",
      "        - $ref: '#/parameters/application-id'\n",
      "        - $ref: '#/parameters/report-id'\n",
      "        - $ref: \"#/parameters/limit\"\n",
      "        - $ref: \"#/parameters/offset\"\n",
      "        - name: status\n",
      "          in: query\n",
      "          description: Status values that need to be considered for filter\n",
      "          required: true\n",
      "          type: array\n",
      "          items:\n",
      "            type: string\n",
      "            enum:\n",
      "              - available\n",
      "              - pending\n",
      "              - sold\n",
      "            default: available\n",
      "          collectionFormat: multi\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            type: array\n",
      "            items:\n",
      "              $ref: '#/definitions/Pet'\n",
      "        '400':\n",
      "          description: Invalid status value\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "  /pet/findByTags:\n",
      "    get:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Finds Pets by tags\n",
      "      description: >-\n",
      "        Muliple tags can be provided with comma separated strings. Use\n",
      "        tag1, tag2, tag3 for testing.\n",
      "      operationId: findPetsByTags\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: tags\n",
      "          in: query\n",
      "          description: Tags to filter by\n",
      "          required: true\n",
      "          type: array\n",
      "          items:\n",
      "            type: string\n",
      "          collectionFormat: multi\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            type: array\n",
      "            items:\n",
      "              $ref: '#/definitions/Pet'\n",
      "        '400':\n",
      "          description: Invalid tag value\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "      deprecated: true\n",
      "  '/pet/{petId}':\n",
      "    get:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Find pet by ID\n",
      "      description: Returns a single pet\n",
      "      operationId: getPetById\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - $ref: '#/parameters/dummnies'\n",
      "        - $ref: '#/parameters/X-B3-pet'\n",
      "        - $ref: '#/parameters/X-B3-id'\n",
      "        - $ref: '#/parameters/X-B3-petname'\n",
      "        - $ref: '#/parameters/pets-id'\n",
      "        - $ref: '#/parameters/name-id'\n",
      "        - name: petId\n",
      "          in: path\n",
      "          description: ID of pet to return\n",
      "          required: true\n",
      "          type: integer\n",
      "          format: int64\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/Pet'\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Pet not found\n",
      "      security:\n",
      "        - api_key: []\n",
      "    post:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Updates a pet in the store with form data\n",
      "      description: ''\n",
      "      operationId: updatePetWithForm\n",
      "      consumes:\n",
      "        - application/x-www-form-urlencoded\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: petId\n",
      "          in: path\n",
      "          description: ID of pet that needs to be updated\n",
      "          required: true\n",
      "          type: integer\n",
      "          format: int64\n",
      "        - name: name\n",
      "          in: formData\n",
      "          description: Updated name of the pet\n",
      "          required: false\n",
      "          type: string\n",
      "        - name: status\n",
      "          in: formData\n",
      "          description: Updated status of the pet\n",
      "          required: false\n",
      "          type: string\n",
      "      responses:\n",
      "        '405':\n",
      "          description: Invalid input\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "    delete:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Deletes a pet\n",
      "      description: ''\n",
      "      operationId: deletePet\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: api_key\n",
      "          in: header\n",
      "          required: false\n",
      "          type: string\n",
      "        - name: petId\n",
      "          in: path\n",
      "          description: Pet id to delete\n",
      "          required: true\n",
      "          type: integer\n",
      "          format: int64\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Pet not found\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "  '/pet/{petId}/uploadImage':\n",
      "    post:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: uploads an image\n",
      "      description: ''\n",
      "      operationId: uploadFile\n",
      "      consumes:\n",
      "        - multipart/form-data\n",
      "      produces:\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: petId\n",
      "          in: path\n",
      "          description: ID of pet to update\n",
      "          required: true\n",
      "          type: integer\n",
      "          format: int64\n",
      "        - name: additionalMetadata\n",
      "          in: formData\n",
      "          description: Additional data to pass to server\n",
      "          required: false\n",
      "          type: string\n",
      "        - name: file\n",
      "          in: formData\n",
      "          description: file to upload\n",
      "          required: false\n",
      "          type: file\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/ApiResponse'\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "  /store/inventory:\n",
      "    get:\n",
      "      tags:\n",
      "        - store\n",
      "      summary: Returns pet inventories by status\n",
      "      description: Returns a map of status codes to quantities\n",
      "      operationId: getInventory\n",
      "      produces:\n",
      "        - application/json\n",
      "      parameters: []\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            type: object\n",
      "            additionalProperties:\n",
      "              type: integer\n",
      "              format: int32\n",
      "      security:\n",
      "        - api_key: []\n",
      "  /store/order:\n",
      "    post:\n",
      "      tags:\n",
      "        - store\n",
      "      summary: Place an order for a pet\n",
      "      description: ''\n",
      "      operationId: placeOrder\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: order placed for purchasing the pet\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/Order'\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/Order'\n",
      "        '400':\n",
      "          description: Invalid Order\n",
      "  '/store/order/{orderId}':\n",
      "    get:\n",
      "      tags:\n",
      "        - store\n",
      "      summary: Find purchase order by ID\n",
      "      description: >-\n",
      "        For valid response try integer IDs with value >= 1 and <= 10.\n",
      "        Other values will generated exceptions\n",
      "      operationId: getOrderById\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: orderId\n",
      "          in: path\n",
      "          description: ID of pet that needs to be fetched\n",
      "          required: true\n",
      "          type: integer\n",
      "          maximum: 10\n",
      "          minimum: 1\n",
      "          format: int64\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/Order'\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Order not found\n",
      "    delete:\n",
      "      tags:\n",
      "        - store\n",
      "      summary: Delete purchase order by ID\n",
      "      description: >-\n",
      "        For valid response try integer IDs with positive integer value.\n",
      "        Negative or non-integer values will generate API errors\n",
      "      operationId: deleteOrder\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: orderId\n",
      "          in: path\n",
      "          description: ID of the order that needs to be deleted\n",
      "          required: true\n",
      "          type: integer\n",
      "          minimum: 1\n",
      "          format: int64\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Order not found\n",
      "  /user:\n",
      "    post:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Create user\n",
      "      description: This can only be done by the logged in user.\n",
      "      operationId: createUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: Created user object\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/User'\n",
      "      responses:\n",
      "        default:\n",
      "          description: successful operation\n",
      "  /user/createWithArray:\n",
      "    post:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Creates list of users with given input array\n",
      "      description: ''\n",
      "      operationId: createUsersWithArrayInput\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: List of user object\n",
      "          required: true\n",
      "          schema:\n",
      "            type: array\n",
      "            items:\n",
      "              $ref: '#/definitions/User'\n",
      "      responses:\n",
      "        default:\n",
      "          description: successful operation\n",
      "  /user/createWithList:\n",
      "    post:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Creates list of users with given input array\n",
      "      description: ''\n",
      "      operationId: createUsersWithListInput\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: List of user object\n",
      "          required: true\n",
      "          schema:\n",
      "            type: array\n",
      "            items:\n",
      "              $ref: '#/definitions/User'\n",
      "      responses:\n",
      "        default:\n",
      "          description: successful operation\n",
      "  /user/login:\n",
      "    get:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Logs user into the system\n",
      "      description: ''\n",
      "      operationId: loginUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: username\n",
      "          in: query\n",
      "          description: The user name for login\n",
      "          required: true\n",
      "          type: string\n",
      "        - name: password\n",
      "          in: query\n",
      "          description: The password for login in clear text\n",
      "          required: true\n",
      "          type: string\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            type: string\n",
      "          headers:\n",
      "            X-Rate-Limit:\n",
      "              type: integer\n",
      "              format: int32\n",
      "              description: calls per hour allowed by the user\n",
      "            X-Expires-After:\n",
      "              type: string\n",
      "              format: date-time\n",
      "              description: date in UTC when token expires\n",
      "        '400':\n",
      "          description: Invalid username/password supplied\n",
      "  /user/logout:\n",
      "    get:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Logs out current logged in user session\n",
      "      description: ''\n",
      "      operationId: logoutUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters: []\n",
      "      responses:\n",
      "        default:\n",
      "          description: successful operation\n",
      "  '/user/{username}':\n",
      "    get:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Get user by user name\n",
      "      description: ''\n",
      "      operationId: getUserByName\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: username\n",
      "          in: path\n",
      "          description: 'The name that needs to be fetched. Use user1 for testing. '\n",
      "          required: true\n",
      "          type: string\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/User'\n",
      "        '400':\n",
      "          description: Invalid username supplied\n",
      "        '404':\n",
      "          description: User not found\n",
      "    put:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Updated user\n",
      "      description: This can only be done by the logged in user.\n",
      "      operationId: updateUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: username\n",
      "          in: path\n",
      "          description: name that need to be updated\n",
      "          required: true\n",
      "          type: string\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: Updated user object\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/User'\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid user supplied\n",
      "        '404':\n",
      "          description: User not found\n",
      "    delete:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Delete user\n",
      "      description: This can only be done by the logged in user.\n",
      "      operationId: deleteUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: username\n",
      "          in: path\n",
      "          description: The name that needs to be deleted\n",
      "          required: true\n",
      "          type: string\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid username supplied\n",
      "        '404':\n",
      "          description: User not found\n",
      "securityDefinitions:\n",
      "  petstore_auth:\n",
      "    type: oauth2\n",
      "    authorizationUrl: 'http://petstore.swagger.io/oauth/dialog'\n",
      "    flow: implicit\n",
      "    scopes:\n",
      "      'write:pets': modify pets in your account\n",
      "      'read:pets': read your pets\n",
      "  api_key:\n",
      "    type: apiKey\n",
      "    name: api_key\n",
      "    in: header\n",
      "definitions:\n",
      "  Order:\n",
      "    type: object\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      petId:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      quantity:\n",
      "        type: integer\n",
      "        format: int32\n",
      "      shipDate:\n",
      "        type: string\n",
      "        format: date-time\n",
      "      status:\n",
      "        type: string\n",
      "        description: Order Status\n",
      "        enum:\n",
      "          - placed\n",
      "          - approved\n",
      "          - delivered\n",
      "      complete:\n",
      "        type: boolean\n",
      "        default: false\n",
      "    xml:\n",
      "      name: Order\n",
      "  Category:\n",
      "    type: object\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      name:\n",
      "        type: string\n",
      "    xml:\n",
      "      name: Category\n",
      "  User:\n",
      "    type: object\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      username:\n",
      "        type: string\n",
      "      firstName:\n",
      "        type: string\n",
      "      lastName:\n",
      "        type: string\n",
      "      email:\n",
      "        type: string\n",
      "      password:\n",
      "        type: string\n",
      "      phone:\n",
      "        type: string\n",
      "      userStatus:\n",
      "        type: integer\n",
      "        format: int32\n",
      "        description: User Status\n",
      "    xml:\n",
      "      name: User\n",
      "  Tag:\n",
      "    type: object\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      name:\n",
      "        type: string\n",
      "    xml:\n",
      "      name: Tag\n",
      "  Pet:\n",
      "    type: object\n",
      "    required:\n",
      "      - name\n",
      "      - photoUrls\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      category:\n",
      "        $ref: '#/definitions/Category'\n",
      "      name:\n",
      "        type: string\n",
      "        example: doggie\n",
      "      photoUrls:\n",
      "        type: array\n",
      "        xml:\n",
      "          name: photoUrl\n",
      "          wrapped: true\n",
      "        items:\n",
      "          type: string\n",
      "      tags:\n",
      "        type: array\n",
      "        xml:\n",
      "          name: tag\n",
      "          wrapped: true\n",
      "        items:\n",
      "          $ref: '#/definitions/Tag'\n",
      "      status:\n",
      "        type: string\n",
      "        description: pet status in the store\n",
      "        enum:\n",
      "          - available\n",
      "          - pending\n",
      "          - sold\n",
      "    xml:\n",
      "      name: Pet\n",
      "  ApiResponse:\n",
      "    type: object\n",
      "    properties:\n",
      "      code:\n",
      "        type: integer\n",
      "        format: int32\n",
      "      type:\n",
      "        type: string\n",
      "      message:\n",
      "        type: string\n",
      "externalDocs:\n",
      "  description: Find out more about Swagger\n",
      "  url: 'http://swagger.io'\n",
      "i have written the below code to capture the values based on the index [0], but the index value are dynamic. Example at 0 In key word present, for next content it might occur in 5.\n",
      "import yaml\n",
      "import json\n",
      "with open(\"pets.yaml\", 'r') as yaml_in, open(\"yml_test.json\", \"w\") as json_out:\n",
      "    data = json.loads(json.dumps(yaml.load(yaml_in, Loader=yaml.FullLoader)))\n",
      "    output_dict = {}\n",
      "    for url in data[\"paths\"]:\n",
      "        for method in data[\"paths\"][url]:\n",
      "            output_dict[url + \"/\" + method] = {}\n",
      "            output_dict[url + \"/\" + method][\"parameters\"] = {}\n",
      "            if \"consumes\" in data[\"paths\"][url][method]:\n",
      "                output_dict[url+\"/\"+method][\"consumes\"] = data[\"paths\"][url][method][\"consumes\"]\n",
      "                print(\"Consumes Parameter: \", data[\"paths\"][url][method][\"consumes\"])\n",
      "            if \"produces\" in data[\"paths\"][url][method]:\n",
      "                output_dict[url+\"/\"+method][\"produces\"] = data[\"paths\"][url][method][\"produces\"]\n",
      "                print(\"Produces parameter: \", data[\"paths\"][url][method][\"produces\"])\n",
      "            if data[\"paths\"][url][method][\"parameters\"]:\n",
      "                if \"in\" in data[\"paths\"][url][method][\"parameters\"][0]:\n",
      "                    output_dict[url+\"/\"+method][\"parameters\"][\"in\"] = data[\"paths\"][url][method][\"parameters\"][0][\"in\"]\n",
      "                    print(\"In Parameter: \", data[\"paths\"][url][method][\"parameters\"][0][\"in\"])\n",
      "                if \"name\" in data[\"paths\"][url][method][\"parameters\"][0]:\n",
      "                    output_dict[url+\"/\"+method][\"parameters\"][\"name\"] = data[\"paths\"][url][method][\"parameters\"][0][\"name\"]\n",
      "                    print(\"Name parameter: \", data[\"paths\"][url][method][\"parameters\"][0][\"name\"])\n",
      "                if \"required\" in data[\"paths\"][url][method][\"parameters\"][0]:\n",
      "                    output_dict[url+\"/\"+method][\"parameters\"][\"required\"] = data[\"paths\"][url][method][\"parameters\"][0][\"required\"]\n",
      "                    print(\"Required Parameter: \", data[\"paths\"][url][method][\"parameters\"][0][\"required\"])\n",
      "                if \"type\" in  data[\"paths\"][url][method][\"parameters\"][0]:\n",
      "                    output_dict[url+\"/\"+method][\"parameters\"][\"type\"] = data[\"paths\"][url][method][\"parameters\"][0][\"type\"]\n",
      "                    print(\"Type Parameter: \", data[\"paths\"][url][method][\"parameters\"][0][\"type\"])\n",
      "\n",
      "    json.dump(output_dict, json_out)\n",
      "\n",
      "Below is the sample output, but were i need to capture required, Name, Type.\n",
      "\n",
      "The below output occurred when i changed the index 0 to 5.But for next occurrence it might be within 6 or 7 or 3,...\n",
      "Produces parameter:  ['application/json']\n",
      "In Parameter:  query\n",
      "Produces parameter:  ['application/octet-stream']\n",
      "In Parameter:  path\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086230/how-to-make-a-bar-plot-in-python\n",
      "How to make a bar plot in Python?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am trying to build graphs in Python, using this dataset:   \n",
      "    df  = pd.read_csv(\"Sales.csv\")\n",
      "    df\n",
      "\n",
      "\n",
      "Then I try to build a bar chart using this code:\n",
      "df_product_group = df.groupby('Product').sum()\n",
      "product_group = df_product_group.groupby(['Total Amount'])\n",
      "product_group.plot(kind='barh', stacked=True, figsize=[16,6], colormap='winter') \n",
      "\n",
      "It produces a lot of error codes, including this at the end of the line:\n",
      "~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py in _get_grouper(obj, key, axis, level, sort, observed, mutated, validate)\n",
      "   3289                 in_axis, name, level, gpr = False, None, gpr, None\n",
      "   3290             else:\n",
      "-> 3291                 raise KeyError(gpr)\n",
      "   3292         elif isinstance(gpr, Grouper) and gpr.key is not None:\n",
      "   3293             # Add key to exclusions\n",
      "\n",
      "KeyError: 'Total Amount'\n",
      "\n",
      "What did I do wrong here? And how do I make a bar plot the right way here?\n",
      "Thank you beforehand.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086194/how-to-manage-a-multilayered-dictionary-customize-the-columns-subtract-column\n",
      "How to manage a multilayered dictionary, customize the columns, subtract column data, and add a new column?\n",
      "\n",
      "\n",
      "Thanks so much for the help!\n",
      "I'm doing a json pull from Alphavantage. I'm trying to:\n",
      "\n",
      "Convert the json data to a Pandas dataframe\n",
      "Get the correct data to display correctly\n",
      "Customize the column labels ('Open', 'High', 'Low', 'Close', 'Volume')\n",
      "Subtract data in column 'Close' from data in column 'Open'\n",
      "Create a new column called 'Net' with data from number 4 above\n",
      "\n",
      "I'm a total noob. This is actually my first real project and first time posting here. I'm still learning and experimenting. I'm sure there is a much easier way to do what I'm doing. I've spent countless hours researching and trying to figure this out. Here is what I have so far:\n",
      "import pandas as pd\n",
      "import requests as rq\n",
      "\n",
      "pull_type = 'TIME_SERIES_DAILY'\n",
      "symbol = 'GOOG'\n",
      "size = 'compact'\n",
      "data_type = 'json'\n",
      "api_key = 'XXX_MY_KEY_XXX'\n",
      "url = 'https://www.alphavantage.co/query?'\n",
      "pull_parameters = {\n",
      "    'function': pull_type,\n",
      "    'symbol': symbol,\n",
      "    'outputsize': size,\n",
      "    'datatype': data_type,\n",
      "    'apikey': api_key\n",
      "}\n",
      "\n",
      "pull = rq.get(url, params=pull_parameters)\n",
      "\n",
      "data = pull.json()\n",
      "\n",
      "df = pd.DataFrame.from_dict(data['Time Series (Daily)'], orient='index')\n",
      "\n",
      "df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "\n",
      "df.index = pd.to_datetime(df.index)\n",
      "\n",
      "day_net = df['Open'] - df['Close']\n",
      "\n",
      "print(day_net)\n",
      "\n",
      "I'm getting so many exception errors. Too many to list. Still learning what they all mean. Any input and direction would be welcomed and much appreciated. Thanks!\n",
      "\n",
      "Answer\n",
      "\n",
      "Try changing this line:\n",
      "df = pd.DataFrame.from_dict(data['Time Series (Daily)'], orient='index')\n",
      "\n",
      "To:\n",
      "df = pd.DataFrame.from_dict(data['Time Series (Daily)'], orient='index').astype(float)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086154/beautifulsoup-cannot-bring-bodys-contents\n",
      "BeautifulSoup cannot bring <body>'s contents\n",
      "\n",
      "\n",
      "http://bus.asan.go.kr/web/bus_arrInfo_pop?busStopId=288000863\n",
      "The link is the bus information system page provided by a Korean local government.\n",
      "I want to crawl the information on the page. but I couldn't.\n",
      "When I tried using BeautifulSoup, Some codes were read but other parts weren't.\n",
      "My code is as below.\n",
      "from urllib.request import urlopen\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "html = urlopen(\"http://bus.asan.go.kr/web/bus_arrInfo_pop?busStopId=288000863\")\n",
      "\n",
      "bsObj = BeautifulSoup(html.read(), \"html.parser\")\n",
      "print(bsObj)\n",
      "\n",
      "and the result is below.\n",
      "There are no any body-contents in the result.\n",
      "What should I do to get contents from the page?\n",
      "Thank you in advance.\n",
      "\n",
      "\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
      "\n",
      "<html lang=\"ko\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\">\n",
      "<title>아산시 버스정보시스템</title>\n",
      "<link href=\"../resources/css/common.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"../resources/css/w/scrollbar.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"../resources/css/w/bus_arrInfo_pop.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<script src=\"../resources/js/jquery-1.9.1.js\" type=\"text/javascript\"></script>\n",
      "<script src=\"../resources/js/hashMap.js\" type=\"text/javascript\"></script>\n",
      "<script src=\"../resources/js/w/commonTraffic.js\" type=\"text/javascript\"></script>\n",
      "<script type=\"text/javascript\">\n",
      "\n",
      "        $(document).ready(function(){\n",
      "                var paramStop_id = '288000863';\n",
      "                if(paramStop_id != \"\" && paramStop_id != null){\n",
      "                        var form_data = {\n",
      "                                        busStopId: paramStop_id\n",
      "            };\n",
      "\n",
      "                ajaxCall(\"../mobile/traffic/searchBusStopRoute\", form_data, ajaxBeforeSendMapRouteInfo, ajaxSuccessMapRouteInfo);\n",
      "                }\n",
      "\n",
      "                $('.btn_print').click(function(){\n",
      "                        $('.stationInfo_wrap .cont').css('max-height','inherit');\n",
      "                        $('.stationInfo_wrap .cont').css('overflow-y','auto');\n",
      "                        window.print();\n",
      "                        $('.stationInfo_wrap .cont').css('max-height','670px');\n",
      "                        $('.stationInfo_wrap .cont').css('overflow-y','scroll');\n",
      "                });\n",
      "        });\n",
      "\n",
      "        function ajaxBeforeSendMapRouteInfo(xhr){\n",
      "                var strTemp = \"\";\n",
      "                strTemp += \"<div style='height: 144px;width: 573px;border-left: 1px solid #d0d0d0;'><img style='width: 20px; height: 20px; margin-top:60px;' alt='로딩중' src='../resources/images/w/loader.gif'></div>\";\n",
      "                $(\"#map_route_data\").empty().append(strTemp);\n",
      "        }\n",
      "\n",
      "        function ajaxSuccessMapRouteInfo(data){\n",
      "                var strTemp = \"\";\n",
      "                var stopInfo = data.stopInfo;\n",
      "                if(data.busStopRouteList.length == 0){\n",
      "                        var id = stopInfo.service_id;\n",
      "                        if(id==\"\"||id==null||id==\" \"){\n",
      "                                id = \"ID 없음\";\n",
      "                        }\n",
      "\n",
      "                        $(\"#map_service_id\").text(\"[\" + id + \"]\");\n",
      "                        $(\"#map_stop_name\").text(stopInfo.stop_name);\n",
      "\n",
      "                        strTemp += \"<div style='height: 152px;width: 573px;border-left: 1px solid #d0d0d0;line-height: 144px;'>검색결과가 없습니다.</div>\";\n",
      "                } else {\n",
      "                        var id = data.busStopRouteList[0].service_id;\n",
      "                        if(id==\"\"||id==null||id==\" \"){\n",
      "                                id = \"ID 없음\";\n",
      "                        }\n",
      "                        $(\"#map_service_id\").text(\"[\" + id + \"]\");\n",
      "                        $(\"#map_stop_name\").text(data.busStopRouteList[0].stop_name);\n",
      "\n",
      "                        $.each( data.busStopRouteList, function( index, value ) {\n",
      "                                var routeName = value.route_name;\n",
      "                                if(value.relay_areacode==285){\n",
      "                                        routeName = routeName + \" (천안)\";\n",
      "                                }\n",
      "                                if(index==0){\n",
      "                                        if(value.eb_flag==0){\n",
      "                                                strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                        }else{\n",
      "                                                if(value.route_type == 11) {\n",
      "                                                        strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                }else {\n",
      "                                                        strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                }\n",
      "                                        }\n",
      "                                        strTemp += \"<div class='st_waitTime'>\"+value.provide_type+\"</div><div class='st_where'>\"+value.rstop+\"</div><div class='st_XXX'>\"+value.last_stop_name+\"</div>\";\n",
      "\n",
      "                                        if(index!=(data.busStopRouteList.length-1)){\n",
      "                                                line=1;\n",
      "                                        }else{\n",
      "                                                //strTemp += \"<div class='st_waitTime'></div><div class='st_where'></div><div class='st_XXX' style='margin-bottom:6px;'></div>\";\n",
      "                                                line=2;\n",
      "                                        }\n",
      "                                        temp_route_id=value.route_id;\n",
      "                                }else{\n",
      "                                        if(temp_route_id==value.route_id){\n",
      "                                                //strTemp += \"<div class='st_waitTime line2'>\"+value.provide_type+\"</div><div class='st_where line2'>\"+value.rstop+\"</div><div class='st_XXX line2'>\"+value.last_stop_name+\"</div>\";\n",
      "                                                line=2;\n",
      "                                                temp_route_id=\"-1\";\n",
      "                                        }else{\n",
      "                                                if(line==1){\n",
      "                                                        //strTemp += \"<div class='st_waitTime\n",
      "line2'></div><div class='st_where line2'></div><div class='st_XXX line2'></div>\";\n",
      "                                                        temp_route_id=\"-1\";\n",
      "                                                        line=2;\n",
      "                                                }\n",
      "                                                if(value.eb_flag==0){\n",
      "                                                        strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                }else{\n",
      "                                                        if(value.route_type == 11) {\n",
      "                                                                strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                        }else {\n",
      "                                                                strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                        }\n",
      "                                                }\n",
      "\n",
      "                                                if(index!=(data.busStopRouteList.length-1)){\n",
      "                                                        strTemp += \"<div class='st_waitTime'>\"+value.provide_type+\"</div><div class='st_where'>\"+value.rstop+\"</div><div class='st_XXX'>\"+value.last_stop_name+\"</div>\";\n",
      "                                                        line=1;\n",
      "                                                }else{\n",
      "                                                        strTemp += \"<div class='st_waitTime'>\"+value.provide_type+\"</div><div class='st_where'>\"+value.rstop+\"</div><div class='st_XXX' style='margin-bottom:10px;'>\"+value.last_stop_name+\"</div>\";\n",
      "                                                        //strTemp += \"<div class='st_waitTime'></div><div class='st_where'></div><div class='st_XXX' style='margin-bottom:10px;'></div>\";\n",
      "                                                        line=2;\n",
      "                                                }\n",
      "\n",
      "                                                temp_route_id=value.route_id;\n",
      "                                        }\n",
      "                                }\n",
      "                        });\n",
      "\n",
      "                }\n",
      "                $(\"#map_route_data\").empty().append(strTemp);\n",
      "        }\n",
      "\n",
      "        </script>\n",
      "</meta></head>\n",
      "<body style=\"width:100%;min-width:615px;\">\n",
      "<div class=\"wrap\" style=\"width:615px;\">\n",
      "<div class=\"stationInfo_wrap\">\n",
      "<div class=\"st_header\">\n",
      "<div class=\"st_info\">\n",
      "<p>\n",
      "<span id=\"map_service_id\"></span>\n",
      "<span id=\"map_stop_name\" style=\"padding-left: 5px;\"></span>\n",
      "<a class=\"btn_print extraBtnBg\" href=\"#\" style=\"  margin-top: 13px; font-size: 12px; line-height: 19px; width:90px;\">도착정보 출력</a></p>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cont\">\n",
      "<div class=\"st_title\">\n",
      "<div class=\"st_busNum\">노선번호</div>\n",
      "<div class=\"st_waitTime\">도착예정</div>\n",
      "<div class=\"st_where\">현재위치</div>\n",
      "<div class=\"st_XXX\">현재정류장</div>\n",
      "</div>\n",
      "<div class=\"st_list\">\n",
      "<div class=\"map_route_data\" id=\"map_route_data\">\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Answer\n",
      "\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = 'http://bus.asan.go.kr/web/bus_arrInfo_pop?busStopId=288000863'\n",
      "res = requests.get(url)\n",
      "html_page = res.content\n",
      "soup = BeautifulSoup(html_page, 'html.parser')\n",
      "text = soup.find_all(text=True)\n",
      "\n",
      "output = ''\n",
      "blacklist = [\n",
      "    '[document]',\n",
      "    'noscript',\n",
      "    'header',\n",
      "    'html',\n",
      "    'meta',\n",
      "    'head', \n",
      "    'input',\n",
      "    'script',\n",
      "    # there may be more elements you don't want, such as \"style\", etc.\n",
      "]\n",
      "\n",
      "for t in text:\n",
      "    if t.parent.name not in blacklist:\n",
      "        output += '{} '.format(t)\n",
      "\n",
      "print(output)\n",
      "\n",
      "\n",
      "result:\n",
      "'아산시 버스정보시스템\\n\\n\\n\\n\\n\\n\\n\\n도착정보 출력\\n\\n\\n\\n\\n\\n노선번호\\n도착예정\\n현재위치\\n현재정류장\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "you can also replace \\n if you want.\n",
      "sourcecode from:https://matix.io/extract-text-from-webpage-using-beautifulsoup-and-python/\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086150/web-scraping-python-using-my-subscriptions\n",
      "Web scraping python - using my subscriptions\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am scraping multiple news sites, some of which require a subscription to access. Is there a way to proxy python web requests through my browser which has all of these subscriptions logged in?\n",
      "Or is there a better way to use my subscription log in details through python web requests?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "page= urlopen(\"https://stackoverflow.com/questions/tagged/python\")\n",
    "document=page.read()\n",
    "soup=BeautifulSoup(document, 'html.parser')\n",
    "questions=soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "# questions=[]\n",
    "for questions in questions_list:\n",
    "    print(\"Question\\n\")\n",
    "    print('http://stackoverflow.com'+questions.get('href'))\n",
    "    print(questions.get_text())\n",
    "    print(\"\\n\")\n",
    "    url='https://stackoverflow.com'+questions.get('href')\n",
    "    response = req.urlopen(url)\n",
    "    soup= BeautifulSoup(response,'html.parser')\n",
    "    for question in soup.select(\"div.postcell div.post-text\"):\n",
    "        print(question.get_text().strip())\n",
    "    print(\"\\nAnswer\\n\")\n",
    "    if len(soup.select(\"div.answercell div.post-text\"))==0:\n",
    "        print('no answer')\n",
    "    else:\n",
    "        for answer in soup.select(\"div.answercell div.post-text\"):\n",
    "            print(answer.get_text().strip())\n",
    "\n",
    "    print('='*40,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "site = \"https://kin.naver.com/search/list.nhn?\"\n",
    "tag = input(\"검색어를 입력해주십시오-->\")\n",
    "num = input(\"검색할 페이지 번호를 입력하십시오-->\")\n",
    "temp_url = site + \"sort=none&query=\" + tag \n",
    "temp_url_encode=parse.urlparse(temp_url)\n",
    "query = parse.parse_qs(temp_url_encode.query)\n",
    "query_encode = parse.urlencode(query, doseq=True)\n",
    "\n",
    "url = site+query_encode+\"&section=kin&page=\"+ num\n",
    "\n",
    "#\n",
    "\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "soup = BeautifulSoup(document.decode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "temp_qna = soup.find(class_=\"basic1\")\n",
    "qna_list = temp_qna.select(\"li > dl > dt > a\")\n",
    "\n",
    "for qna in qna_list:\n",
    "    \n",
    "    # 링크 생성\n",
    "    qna_url = qna.attrs[\"href\"]\n",
    "    print(\"=\"*30+\"링크\"+\"=\"*30)\n",
    "    print(qna_url)\n",
    "    \n",
    "    # 링크 읽기\n",
    "    qna_page = urlopen(qna_url.encode(\"ascii\",\"ignore\").decode(\"ascii\",\"ignore\")) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성\n",
    "    soup_qna = BeautifulSoup(qna_document.decode(\"utf-8\"), \"html.parser\")\n",
    "    \n",
    "    # 질문\n",
    "    print(\"*\"*10 + \"질문 제목\")\n",
    "    qna_questions = soup_ qna.find(class_=\"question-content__inner\")\n",
    "    \n",
    "    if qna_questions == None:\n",
    "        pass\n",
    "    else:\n",
    "        title_q = qna_questions.select_one(\"div.c-heading > div.c-heading__title > div.c-heading__title-inner > div.title\").text\n",
    "        print(title_q.strip())\n",
    "    \n",
    "    content_q = qna_questions.select_one(\"div.c-heading > div.c-heading__content\")\n",
    "    if content_q == None:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*10 + \"질문 내용\")\n",
    "        print(content_q.text.strip())\n",
    "        \n",
    "    # 답변\n",
    "    qna_answers = soup_qna.find(class_=\"answer-content__inner\")\n",
    "    \n",
    "    title_q_list = qna_answers.select(\"div.c-heading-answer__title > p\")\n",
    "    content_q_list = qna_answers.select(\"div._endContentsText\")\n",
    "    \n",
    "    if title_q == None:\n",
    "        print(\"답변이 없습니다\")\n",
    "    else:\n",
    "        for title_q in title_q_list:\n",
    "            for content_q in content_q_list:\n",
    "                print(\"\\n\")\n",
    "                print(\"+\"*10 + \"답변자\" + \"+\"*10)\n",
    "                print(title_q.text.strip())\n",
    "                print(\"+\"*26)\n",
    "                print(\"\\n\")\n",
    "                print(\"-\"*10 + \"답변 내용\" + \"-\"*10)\n",
    "                print(content_q.text.strip())\n",
    "                print(\"-\"*29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# 검색어 설정\n",
    "tag = input(\"검색어를 입력하십시오-->\")\n",
    "\n",
    "# url 설정 및 url 읽기\n",
    "url = \"https://stackoverflow.com/questions/tagged/\" + tag\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "\n",
    "# 객체 생성 및 파일 읽기\n",
    "soup = BeautifulSoup(document, \"html.parser\")\n",
    "questions = soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "\n",
    "# 메인 알고리즘\n",
    "# for questions in questions_list:\n",
    "    \n",
    "    print(\"@\"*50, \"제목\", \"@\"*50)\n",
    "    \n",
    "    # Q&A 질문 요약\n",
    "    print(\"질문\",questions.get_text()) # 조금 더 가벼움!\n",
    "    \n",
    "    # Q&A 링크 생성\n",
    "    print(\"=\"*100)\n",
    "    print(\"링크:\",\"https://stackoverflow.com\"+questions.get(\"href\"))\n",
    "          \n",
    "    \n",
    "    # Q&A 링크 읽기\n",
    "    qna_url=\"https://stackoverflow.com\"+questions.get(\"href\")\n",
    "    qna_page = urlopen(qna_url) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성 및 파일 읽기\n",
    "    soup_qna = BeautifulSoup(qna_document, \"html.parser\")\n",
    "    qna_questions = soup_qna.find(class_=\"question\")\n",
    "    \n",
    "    # 질문 내용 출력\n",
    "    print(\"*\"*50 ,\"질문 내용\", \"*\"*50)\n",
    "    print(qna_questions.select(\"div.post-text\")[0].text)\n",
    "    \n",
    "    # 답변 내용 출력\n",
    "    print(\"*\"*50 ,\"답변 내용\", \"*\"*50)\n",
    "    qna_answers = soup_qna.find(id=\"answers\")\n",
    "    if qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\") == None:\n",
    "        print(\"#\"*50,\"답변이 없습니다\",\"#\"*50)\n",
    "    else:\n",
    "        print(qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\").text)\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# 검색어 설정\n",
    "tag = input(\"검색어를 입력하십시오-->\")\n",
    "\n",
    "# url 설정 및 url 읽기\n",
    "url = \"https://stackoverflow.com/questions/tagged/\" + tag\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "\n",
    "# 객체 생성 및 파일 읽기\n",
    "soup = BeautifulSoup(document, \"html.parser\")\n",
    "questions = soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "\n",
    "# 메인 알고리즘\n",
    "for questions in questions_list:\n",
    "    \n",
    "    print(\"@\"*50, \"제목\", \"@\"*50)\n",
    "    \n",
    "    # Q&A 질문 요약\n",
    "    print(\"질문\",questions.get_text()) # 조금 더 가벼움!\n",
    "    \n",
    "    # Q&A 링크 생성\n",
    "    print(\"=\"*100)\n",
    "    print(\"링크:\",\"https://stackoverflow.com\"+questions.get(\"href\"))\n",
    "          \n",
    "    \n",
    "    # Q&A 링크 읽기\n",
    "    qna_url=\"https://stackoverflow.com\"+questions.get(\"href\")\n",
    "    qna_page = urlopen(qna_url) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성 및 파일 읽기\n",
    "    soup_qna = BeautifulSoup(qna_document, \"html.parser\")\n",
    "    qna_questions = soup_qna.find(class_=\"question\")\n",
    "    \n",
    "    # 질문 내용 출력\n",
    "    print(\"*\"*50 ,\"질문 내용\", \"*\"*50)\n",
    "    print(qna_questions.select(\"div.post-text\")[0].text)\n",
    "    \n",
    "    # 답변 내용 출력\n",
    "    print(\"*\"*50 ,\"답변 내용\", \"*\"*50)\n",
    "    qna_answers = soup_qna.find(id=\"answers\")\n",
    "    if qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\") == None:\n",
    "        print(\"#\"*50,\"답변이 없습니다\",\"#\"*50)\n",
    "    else:\n",
    "        print(qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\").text)\n",
    "    print(\"=\"*100)\n",
    "\n",
    "\n",
    "# In[223]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지식인 검색\n",
    "site = \"https://kin.naver.com/search/list.nhn?\"\n",
    "tag = input(\"검색어를 입력해주십시오-->\")\n",
    "num = input(\"검색할 페이지 번호를 입력하십시오-->\")\n",
    "temp_url = site + \"sort=none&query=\" + tag \n",
    "temp_url_encode=parse.urlparse(temp_url)\n",
    "query = parse.parse_qs(temp_url_encode.query)\n",
    "query_encode = parse.urlencode(query, doseq=True)\n",
    "\n",
    "url = site+query_encode+\"&section=kin&page=\"+ num\n",
    "\n",
    "#\n",
    "\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "soup = BeautifulSoup(document.decode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "temp_qna = soup.find(class_=\"basic1\")\n",
    "qna_list = temp_qna.select(\"li > dl > dt > a\")\n",
    "\n",
    "for qna in qna_list:\n",
    "    \n",
    "    # 링크 생성\n",
    "    qna_url = qna.attrs[\"href\"]\n",
    "    print(\"=\"*30+\"링크\"+\"=\"*30)\n",
    "    print(qna_url)\n",
    "    \n",
    "    # 링크 읽기\n",
    "    qna_page = urlopen(qna_url.encode(\"ascii\",\"ignore\").decode(\"ascii\",\"ignore\")) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성\n",
    "    soup_qna = BeautifulSoup(qna_document.decode(\"utf-8\"), \"html.parser\")\n",
    "    \n",
    "    # 질문\n",
    "    print(\"*\"*10 + \"질문 제목\")\n",
    "    qna_questions = soup_qna.find(class_=\"question-content__inner\")\n",
    "    \n",
    "    if qna_questions == None:\n",
    "        pass\n",
    "    else:\n",
    "        title_q = qna_questions.select_one(\"div.c-heading > div.c-heading__title > div.c-heading__title-inner > div.title\").text\n",
    "        print(title_q.strip())\n",
    "    \n",
    "    content_q = qna_questions.select_one(\"div.c-heading > div.c-heading__content\")\n",
    "    if content_q == None:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*10 + \"질문 내용\")\n",
    "        print(content_q.text.strip())\n",
    "        \n",
    "    # 답변\n",
    "    qna_answers = soup_qna.find(class_=\"answer-content__inner\")\n",
    "    \n",
    "    title_q_list = qna_answers.select(\"div.c-heading-answer__title > p\")\n",
    "    content_q_list = qna_answers.select(\"div._endContentsText\")\n",
    "    \n",
    "    if title_q == None:\n",
    "        print(\"답변이 없습니다\")\n",
    "    else:\n",
    "        for title_q in title_q_list:\n",
    "            for content_q in content_q_list:\n",
    "                print(\"\\n\")\n",
    "                print(\"+\"*10 + \"답변자\" + \"+\"*10)\n",
    "                print(title_q.text.strip())\n",
    "                print(\"+\"*26)\n",
    "                print(\"\\n\")\n",
    "                print(\"-\"*10 + \"답변 내용\" + \"-\"*10)\n",
    "                print(content_q.text.strip())\n",
    "                print(\"-\"*29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 -> 수치화(DTM, Word2Vec 등)\n",
    "#문서간 단어들의 차이를 계산? 유클리드, 코사인 유사도 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서1     1         1         0         1\n",
    "# 문서2     1         0         1         1\n",
    "# 문서3     2         0         2         2\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(x,y):\n",
    "     return np.dot(x,y)/(norm(x)*norm(y))\n",
    "    \n",
    "doc1=np.array([1,1,0,1])\n",
    "doc2=np.array([1,0,1,1])\n",
    "doc3=np.array([2,0,2,2])\n",
    "\n",
    "print(cos_sim(doc1, doc2))\n",
    "print(cos_sim(doc1, doc3))\n",
    "print(cos_sim(doc3, doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"movies_metadata.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()['overview']\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#단순 코사인 유사도 기반 계산(연습)\n",
    "tfidf=TfidfVectorizer(stop_words='english')\n",
    "tfidf\n",
    "#data['overview'].isnull().value_counts()\n",
    "data['overview']=data['overview'].fillna('') \n",
    "#NaN의 경우는 ''로 (tfidf 작업시 NaN있으면 에러가 발생)\n",
    "data['overview'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat=tfidf.fit_transform(data['overview'])\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cos_sim=cos_sim):\n",
    "    idx_title=idx[title] # 12356 = idx['Rambo']\n",
    "    sim_score=list(enumerate(cos_sim[idx_title]))\n",
    "    sim_score=sorted(sim_score, key=lambda x:x[1] ,reverse=True)\n",
    "    mi=(sim_score[1:11])\n",
    "    res=[i[0]for i in mi]\n",
    "    print(data['title'].iloc[res])\n",
    "#     print(sim_score[1:11])\n",
    "#     mi=[i[0]for i in sim_score]\n",
    "#     print(mi)\n",
    "#     print(sim_score)\n",
    "#     idx_title #12356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('Rambo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_info={'m_id':\"aporlo21\",\n",
    "           'm_passwd':\"1234!@#$\"}\n",
    "url_login= \"http://www.hanbit.co.kr/member/login_proc.php\"\n",
    "# post방식으로 서버 연결\n",
    "session=requests.session()\n",
    "res=session.post(url_login, data=login_info)\n",
    "res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_mypage= \"http://www.hanbit.co.kr/myhanbit/myhanbit.html\"\n",
    "res=session.get(url_mypage)\n",
    "# res.text\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "mi=soup.select_one(\".mileage_section1 > dd > span\").text\n",
    "ec=soup.select_one(\".mileage_section2 > dd > span\").text #get.text : method 형 도출\n",
    "ec\n",
    "print(\"마일리지:\"+mi,\"이코인:\"+ec)\n",
    "#container > div > div.sm_mymileage > dl.mileage_section1 > dd > span\n",
    "# 4로 시작하는 error\n",
    "# 5로 시작하는 ser측 문제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
