# day26

ansanble : 동일한 학습 알고리즘 사용 

stacking : 서로 다른 모델 결합시킴 

begging : 여러가지 모델 학습시켜 집계하여 모델링하는 기법

- history

2000 random forest 기법 

2004 gradient boosting 기법 - begging

약한 예측 모델 을  다수를 앙상블 시킨다 (다수결)

bootstrap : 복원추출 . 여러번 반복 실행 추출 ( aggregatiog)

각각에서 decision tree해서 나온 결과 집계하여 결론 도출 



boosting : 맞추기 어려운 문제를 해결하는데 주안점으로 둔 알고리즘

(계속 틀리는) 7번 문제에 대해 가중치를 구한다 

가중치를 두는것,


Convolutional : 합성곱
pulling = subsampling 

NN 완전연결계층의 문제점 - 데이터 형상 무시된다 
ex) image 가로 세로 색상 = 3차원 => 1차원객체로 평탄화 진행
-> 형상이 무시된다

mnist ( 28*28 * (색상차원 )) ...무시되어짐

합성곱계층 을통해 형상유지 가능케함 
3차원데이터 전달.

Convolutional  : element 들끼리 곱하고 더하는것 
입력특징맵
출력특징맵

이미지에 대한 특성을 추출하자 



##  LeNet

![img](https://t1.daumcdn.net/cfile/tistory/99170D4C5C7E21250E)

1 개 input Layer

3 개 Conv Layer ( c1, c3, c5 )

2 개 Subsampling Layer ( s2, s4 )

1 층의 full connected Layer ( f6 )  

1 개 output Layer



- Process Explanation

c1 Layer ) 입력 영상 ( 32 * 32 ) 이미지를 6개의 5 * 5 필터와 conv 연산을 (합성곱) 해준다 

=> 6장의 28 * 28 특성맵을 얻는다  

```
훈련해야할 파라미터 개수 : ( 가중치 * 입력맵개수 + 바이어스 ) * 특성맵개수
= ( 5 * 5 * 1 + 1) * 6 = 156
```

s2  Layer ) 6장의 28 * 28 특성맵에 대해 subsampling 

28 * 28 특성맵이 14 * 14 특성맵으로 축소된다 

2 * 2 필터를 stride 2 로 설정해서 subsampling 해줌

사용하는 subsampling method is average pooling

```
훈련해야할 파라미터 개수 : ( w + b ) * 특성맵개수 = ( 1 + 1 ) * 6 = 12

```

c3 Layer ) 6장의 14 * 14 특성맵에 합성곱연산을 수행해서 16장의 10 * 10 특성맵산출

cf ) 6장의 14 14 특성 맵에서 연속된 3장을 모아 5 5 3 사이즈 필터와 합성곱 

 6장의 14 14 특성 맵에서 연속된 4장을 모아 5 5 4 사이즈 필터와 합성곱 

 6장의 14 14 특성 맵에서 불연속된 4장을 모아 5 5 4 사이즈 필터와 합성곱 

 6장의 14 14 특성 맵에서 모두 모아 5 5 6 필터와 합성곱 => 1장의 10 * 10 특성맵산출

결과적으로 ( 6 + 6 + 3 + 1 )

```
훈련해야할 파라미터 개수: 

첫번째그룹=> (가중치*입력맵개수+바이어스)*특성맵 개수 = (5*5*3 + 1)*6 = 456

두번째그룹=> (가중치*입력맵개수+바이어스)*특성맵 개수 = (5*5*4 + 1)*6 = 606

세번째그룹=> (가중치*입력맵개수+바이어스)*특성맵 개수 = (5*5*4 + 1)*3 = 303

네번째그룹=> (가중치*입력맵개수+바이어스)*특성맵 개수 = (5*5*6 + 1)*1 = 151

456 + 606 + 303 + 151 = 1516
```



4) S4 레이어:

16장의 10 x 10 특성 맵에 대해서 서브샘플링을 진행해 16장의 5 x 5 특성 맵으로 축소시킨다. 



훈련해야할 파라미터 개수: (가중치 + 바이어스)*특성맵개수 = (1 + 1)*16 = 32


  

5) C5 레이어 : 16장의 5 x 5 특성맵을 120개 5 x 5 x 16 사이즈의 필터와 컨볼루션 해준다. 결과적으로 120개 1 x 1 특성맵이 산출된다. 



훈련해야할 파라미터 개수: (가중치*입력맵개수 + 바이어스)*특성맵 개수 = (5*5*16 + 1)*120 = 48120

 

6) F6 레이어 : 84개의 유닛을 가진 피드포워드 신경망이다. C5의 결과를 84개의 유닛에 연결시킨다. 



훈련해야할 파라미터 개수: 연결개수 = (입력개수 + 바이어스)*출력개수 = (120 + 1)*84 = 10164



7) 아웃풋 레이어 : 10개의 Euclidean radial basis function(RBF) 유닛들로 구성되어있다. 각각 F6의 84개 유닛으로부터 인풋을 받는다. 최종적으로 이미지가 속한 클래스를 알려준다. 



LeNet-5를 제대로 가동하기 위해 훈련해야할 파라미터는 총 156 + 12 + 1516 + 32 + 48120 + 10164 = **60000개**다. 


  