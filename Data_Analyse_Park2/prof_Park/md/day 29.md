# day 29



베이즈 이론 : 사전확률 로부터 사후확률을 예측하는 이론 

빈도표가 있으면, 우도표를 구할수 있다

- 베이지안 필터기 - > 감정평가 (긍정, 부정 )

- 베이지안 확률 

A 라는 도시에서 철수라는 애가 나타냈는데 아이가 노벨상 확률은?

빈도확률로 얘기할시 동일한 아이가 몇번 노벨상받을지를 평가해야하는데 동일 환경에서 자란 아이 있을수 없으므로 불가능하다

불확실성의 개념으로 이야기하는 베이지안 확률론으로 얘기해야하는데, 즉, 이사건과 관련있는 여러가지 확률을 이용하여 새롭게 일어 ㅏㄴㄹ수 있는 사건에 대한 추정을 하는것



- 베이지안 이론 

''사전 확률 P(A) 와 우도확률 P(B|A)를 안다면 사후확률 P(A|B)를 알수 있다''

EX) 청바지 적재 창고. 불량인 청바지(사건) 가 어떤 공장(사전확률 : 구미, 청주, 대구 공장 불량률) 생산품일까(사후확률)

- 정리 

사후확률 분포 : 사건발생후 원이 발생할수 있는 사건이 무엇인지 추청, 그 가능성을 나타내는 변수의 분포

사전확률 분포 : 사건발생 전 사건의 원이 될 수 있는 사건들에 대한 분포 



=> P(A1 | B) = P(A1 and B) / P(B)

결과 B(창고에서 불량 청바지가 발견) 을 발생시키는 원인들이 A1(구미 불량),  A2(청주 불량), A3(대구 불량) [ 사전확률 ]

: 결과 B가 발생했다 조건 아래 원인 A이 발생했을 확률 



P(B|A) : 우도(LIKELIHOOD)

=> 해당사건이 일어난 상황에서 (B), 주어진 데이터가 관찰될 확률 P(B|A)가 높을 수록 더 높은 posterior 사후확률 로 업데이트 된다  



- TF - TDF : Term Frequency - Inverse Document Frequency

정보검색과 텍스트 마이닝에서 이용하는 가중치, 여러문서로 이루어진 문서군이 있을 때 어떤 단어가 특정 문서내에서 얼마나 중요한지 나타내는 통계적 수치 

문서의 핵심어 추출, 검색엔진 결과 순위결정, 유사도 조사등의 용도로 사용

TF 단어빈도는 특정 단어가 문서내 얼마나 자주 등장하는지 나타내여 값이 높을수록, 문서에서 중요하다 생각, (단순 해당단어 총빈도수)

ref ) 불린빈도 , 로그 스케일 빈도, 증가빈도

하지만 단어자체가 문서내에서 자주사용될시, DF(문서빈도) 인데, 이값의 역수를 IDF라하고 

ref) 

TF - IDF는 두 값을 곲한 수치이다. IDF 값은 무서군 성격에 따라 결정된다

EX) '원자' 는 흔치않은 단어로 IDF값이 높아지고 핵심어 될수 있지, 원자에 대한 문서를 모은 문서군의 경우 이 말은 상투어로 작용해 각 문서들을 세분화 하여 구분할수 있는 다른 말이 높은 가중치를 얻게된다 



- **문제** 

**\1. 스팸필터**

-홍길동 받은 메일의 80% 스팸메일.

-스팸메일의 95%에서 '대출'이라는 단어

-정상메일의 2%에서 '대출' 단어

---------주어진 데이터--------

문제)방금 메일을 받음.

'대출'이라는 단어가 제목에서 발견됨.

스팸일 확률?

P(스팸|대출)=P(대출|스팸)P(스팸) / P(대출)

​                = 0.95*0.8 / P(대출)



P(대출)=P(대출|스팸)P(스팸)+P(대출|정상)P(정상)

=             0.95 * 0.8 + 0.02 * 0.2 = 0.764



P(스팸|대출)= 0.95*0.8 / 0.764 =???





**\2. 문장간 유사도 조사**



(1, target) 

오늘 역삼에서 맛있는 돈가스를 먹었다.

(2, source) 

역삼에서 먹었던 오늘의 돈가스는 맛있었다.





(2)번 원문장에 대해 (1)번 대상문장이 어느정도 유사한지 출력?

(1)번 문장에 대해 n=2로 하여 문장 분리하면

=> '오늘','늘 ',' 역','역삼', ... '다.'

=>만약 길이가 20이라 가정하고, 

(2)번 원문장에 대해서도 n=2로 하여 문장 분리했을때,

공통으로 존재하는 단어가 5개 존재한다면,

5/20 = 25%의 유사도를 갖는다.



두 문장의 유사도?(using n-gram)

ex) n=2

(1) '오늘','늘 ',' 역','역삼', ... '다.'  

=> 20개 중 5개가 (2)과 일치

(2) '역삼', '삼에', '에서', ...'다.'

