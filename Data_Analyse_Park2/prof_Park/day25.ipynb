{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural Network\n",
    "## CNN \n",
    "## Recurrent Neural Network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 가변수 dummy 변수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_id</th>\n",
       "      <th>m_gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>disco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_id  m_gen\n",
       "0     1   rock\n",
       "1     2   rock\n",
       "2     3    pop\n",
       "3     4  disco\n",
       "4     5    pop"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# 여러개의 범주형자료 => 가변수 생성( dummy 변수 )\n",
    "df=pd.DataFrame({'m_id':[1,2,3,4,5],\n",
    "            'm_gen':['rock','rock','pop','disco','pop']},\n",
    "            columns=['m_id', 'm_gen'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disco</th>\n",
       "      <th>pop</th>\n",
       "      <th>rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disco  pop  rock\n",
       "0      0    0     1\n",
       "1      0    0     1\n",
       "2      0    1     0\n",
       "3      1    0     0\n",
       "4      0    1     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm=pd.get_dummies(df['m_gen']) # 가변수화 # 이산형화\n",
    "mm\n",
    "# disco, pop, rock 몇개 있는지 도식화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_id</th>\n",
       "      <th>m_gen</th>\n",
       "      <th>genre_disco</th>\n",
       "      <th>genre_pop</th>\n",
       "      <th>genre_rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pop</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>disco</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pop</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m_id  m_gen  genre_disco  genre_pop  genre_rock\n",
       "0     1   rock            0          0           1\n",
       "1     2   rock            0          0           1\n",
       "2     3    pop            0          1           0\n",
       "3     4  disco            1          0           0\n",
       "4     5    pop            0          1           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm=df.join(mm.add_prefix('genre_')) # 각각의 컬럼앞에  df 조인\n",
    "mm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mnist 숫자 이미지 모델화진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Process\n",
    "# Perceptron\n",
    "\n",
    "# 입력신호,,,각각의 신호마다 가중치를 다르게 주어 곱하고 합한값이 임계치를 넘냐마냐에 따라 \n",
    "# 활성화 유무를 결정한다 [activation func]\n",
    "# ====> hidden layer 생성\n",
    "# 출력 y가 연속형으로 도출\n",
    "# logistic regression => 선형회귀가 아닌 '분류' 를하겠다\n",
    "# 분류하고자하는 최종결과가 몇개이느냐에 따라 분류기 갯수를 정한다 \n",
    "# a,b,c 대상 목표 각각의 분류기 생성,,, 후 이를 분류하는 \n",
    "# sigmoid함수통해 0-1사이 결과값으로 변환 시킴 \n",
    "# 퍼셉트론 : 1950년대 하드웨어 기기..당시 연산 사람이 수동으로 직접함 \n",
    "# 단순 퍼셉트로,,, 선형적 계산(분류기 1개...50% 뿐....) 으로는 xor 연산이 불가능하다\n",
    "# sol) multi-perceptron 등장(Multi-Layer-Perceptron)\n",
    "# vanising gradient ( 경사도 손실,, 삭제  현상) \n",
    "# sigmoid의 과연속으로 인해 backpropagation 결과값이 가중치 0 이되버림\n",
    "# 합성함수의 x(정의역)이 전체함수(치역)에 주는 영향도(력) 알아보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Networks\n",
    "# 이미지 인식, 음성인식 분야에서 주로활용되는 분야\n",
    "# deep 한 NN 모델설계가 가능했을때 가능하다 \n",
    "\n",
    "# Hinton 교수 CIFAR 제자진 Imagenet 대회 우승자 \n",
    "# 실무 > 학력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN 이용, ^y 구하기 수식 구현 \n",
    "## +) MNIST db 구현 \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data # 함수 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 10:17:49.732504 13324 deprecation.py:323] From <ipython-input-13-a29ddbfcd8f5>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0805 10:17:49.747881 13324 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0805 10:17:49.763523 13324 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "W0805 10:17:50.559570 13324 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 10:17:51.116803 13324 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0805 10:17:51.119767 13324 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 10:17:51.853076 13324 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x0000027398B33438>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002739B4F65F8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002739B4F6BE0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True) # ohe해주는 속성..결과값 0,1\n",
    "mnist # ( cell - 28 * 28 = 784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data 5만개 image ( 입력, 레이블 구성 ) => model\\\n",
    "# test data 1 만개 image => 모델, 출력결과 정확도 ? \n",
    "# 10 가지 분류기 종류 개수를 포함한 변숙 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10 # 분류결과으 종류 갯수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28*28])\n",
    "y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([28*28, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "hf = tf.nn.softmax(tf.matmul(x,w)+b) ## nn aj\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hf), axis=1))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "\n",
    "# 최댓값에 해당하는 숫자 출력 도출(argmax) \n",
    "is_correct = tf.equal(tf.arg_max(hf,1), tf.arg_max(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "# 1차원으로 쭉 나열 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에폭 (전체 ㅔ이터를 1번 트레이니 -> 1 에폭)\n",
    "training_epochs=15\n",
    "batch_size= 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1 cost: 2.782846367\n",
      "Epoch:    2 cost: 1.092277401\n",
      "Epoch:    3 cost: 0.857700571\n",
      "Epoch:    4 cost: 0.748232932\n",
      "Epoch:    5 cost: 0.680729940\n",
      "Epoch:    6 cost: 0.634933211\n",
      "Epoch:    7 cost: 0.597597148\n",
      "Epoch:    8 cost: 0.570820752\n",
      "Epoch:    9 cost: 0.548042165\n",
      "Epoch:   10 cost: 0.527811778\n",
      "Epoch:   11 cost: 0.513575451\n",
      "Epoch:   12 cost: 0.496172927\n",
      "Epoch:   13 cost: 0.484546270\n",
      "Epoch:   14 cost: 0.473408157\n",
      "Epoch:   15 cost: 0.462278179\n",
      "learning finished\n",
      "accuracy : 0.8902\n",
      "Label: [1]\n",
      "prediction: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 세션만들고\n",
    "# training 하기 \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in  range(training_epochs):#5만개 이미지 * 15번 트레이닝\n",
    "        avg_cost=0\n",
    "        total_batch=int(mnist.train.num_examples / batch_size) #5만/100\n",
    "        for i in range(total_batch): #500번(1번에 100개씩 이미지를 읽겠다)\n",
    "            batch_xs, batch_ys=mnist.train.next_batch(batch_size)\n",
    "            cv, _=sess.run([cost, train], feed_dict={x:batch_xs, y:batch_ys})\n",
    "            avg_cost+=cv/total_batch #  100데이터코스트/500\n",
    "        print(\"Epoch:\", '%4d' % (epoch+1),'cost:', '{:.9f}'.format(avg_cost))    \n",
    "    print(\"learning finished\")# 1, 3, 7, 10, 14   35/5=7\n",
    "    print(\"accuracy :\", sess.run(accuracy, feed_dict={x:mnist.test.images, \n",
    "                                                      y:mnist.test.labels}))\n",
    "    \n",
    "    r=random.randint(0, mnist.test.num_examples-1)\n",
    "    print(\"Label:\",sess.run(tf.argmax(mnist.test.labels[r:r+1],1)))\n",
    "    print(\"prediction:\",sess.run(tf.argmax(hf,1),feed_dict={x:mnist.test.images[r:r+1]}))    \n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28))\n",
    "    plt.show()\n",
    "    \n",
    "            # label 도 따로 읽어준다 \n",
    "            # batch_xs ( 100 * 784 )\n",
    "            # batch_ys ( 100에 해당하는 y image )\n",
    "            # cost. train node 객체 생성, 실행 \n",
    "            # 100개의 데이터 가져와서 500 번 반복 ( 50,000 )\n",
    "            # 정리\n",
    "            \n",
    "            # 1번 for 문 # 50000개 이미지를 15번 반복 (50000, 784)\n",
    "            # # 이미지를 총 500 번 읽어들이겟다 ( 100 개씩 이미지 읽겠다 )\n",
    "            # 그때의 x, y data 가 차례로 들어간다 \n",
    "            # batch_xs : 100개 이미지 (100*784) // batch_ys : 숫자 이미지 (100, 10)\n",
    "            # cost fun 내에서 어떻게 쓰이느냐 (cost 변수선언부)\n",
    "            # y*tf.log(hf), axis=1 연산의 결과 : 10 개 ... 10개 합친 하나의 결과값 \n",
    "            # cost 구할때 실제값 예측값 의 곱의 합 : 10 * 100개 이미지 \n",
    "            # 이에 대한 평균 reduce_mean(reduce_sum ...) \n",
    "            # reason _ # 메모리 부담이크다 \n",
    "            # 50,000 / 500 = 100개 씩 읽어온다 \n",
    "            # x = [none, 784] w = [784,10] # w = 784개 있고 결과가 10개가 도출되어나옴\n",
    "            # 이 cost 10 개 값에 대하여 softmax [ 0 -1 사이값 결과로 도출 ] : y^ (예측값)\n",
    "            # log 취한값 hf\n",
    "            # 실제값 y : [ 0 0 0 .... 1 ]해당이미지 실제값 \n",
    "            # cost 읽어드린 전체 100개에 대한 reduce mean 값  \n",
    "            # 100 data.. cv(cost value) / 500 누적 = > cost의 평균들어간다\n",
    "    # ref) 1, 3, 7, 10, 14 35/5 7 \n",
    "    #      0.2, 3, 7, 10, 14 35/5 7  #1에폭 수행완료 500번반복완료\n",
    "            \n",
    "            \n",
    "    \n",
    "    # session(close)\n",
    "    \n",
    "    # tf.interactive(). eval 함수사용 ====> session(close) 함수 필요 표현 (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## depth 를 더 크게 준다! \n",
    "# 진짜 딥러닝 !! \n",
    "\n",
    "# 여러가지 기법을 활용하여 정확도를 극대화시켜보자!! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = [[0,0],[0,1],[1,0],[1,1]]\n",
    "ydata = [[0],[1],[1],[0]]\n",
    "x = tf.placeholder(tf.float32, [None,2])\n",
    "y = tf.placeholder(tf.float32, [None,1])\n",
    "w = tf.Variable(tf.random_normal([2,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "hf = tf.sigmoid(tf.matmul(x,w) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9048706 [[ 0.3059115]\n",
      " [-0.6636957]]\n",
      "100 0.70034987 [[ 0.4571167 ]\n",
      " [-0.08230113]]\n",
      "200 0.69563234 [[ 0.27730483]\n",
      " [-0.01155346]]\n",
      "300 0.69405925 [[0.16707025]\n",
      " [0.01265127]]\n",
      "400 0.69349957 [[0.10192736]\n",
      " [0.01941748]]\n",
      "500 0.69328964 [[0.06299709]\n",
      " [0.01891637]]\n",
      "600 0.6932069 [[0.03942024]\n",
      " [0.01587127]]\n",
      "700 0.69317293 [[0.02495045]\n",
      " [0.01237018]]\n",
      "800 0.6931585 [[0.01595545]\n",
      " [0.00923489]]\n",
      "900 0.6931522 [[0.01029643]\n",
      " [0.00670621]]\n",
      "1000 0.69314945 [[0.00669707]\n",
      " [0.00477914]]\n",
      "1100 0.69314826 [[0.00438531]\n",
      " [0.00336073]]\n",
      "1200 0.69314766 [[0.00288783]\n",
      " [0.00234046]]\n",
      "1300 0.6931473 [[0.00191067]\n",
      " [0.00161827]]\n",
      "1400 0.69314724 [[0.00126906]\n",
      " [0.00111285]]\n",
      "1500 0.6931472 [[0.00084557]\n",
      " [0.00076213]]\n",
      "1600 0.6931472 [[0.00056486]\n",
      " [0.00052029]]\n",
      "1700 0.6931472 [[0.00037814]\n",
      " [0.00035434]]\n",
      "1800 0.6931472 [[0.00025356]\n",
      " [0.00024084]]\n",
      "1900 0.6931472 [[0.00017023]\n",
      " [0.00016344]]\n",
      "2000 0.6931472 [[0.00011441]\n",
      " [0.00011079]]\n",
      "2100 0.6931472 [[7.696149e-05]\n",
      " [7.502637e-05]]\n",
      "2200 0.6931472 [[5.1802373e-05]\n",
      " [5.0771749e-05]]\n",
      "2300 0.6931472 [[3.4886576e-05]\n",
      " [3.4335775e-05]]\n",
      "2400 0.6931472 [[2.3505074e-05]\n",
      " [2.3215036e-05]]\n",
      "2500 0.6931472 [[1.5833957e-05]\n",
      " [1.5683985e-05]]\n",
      "2600 0.6931472 [[1.0666236e-05]\n",
      " [1.0590769e-05]]\n",
      "2700 0.6931472 [[7.1927789e-06]\n",
      " [7.1456225e-06]]\n",
      "2800 0.6931472 [[4.8413795e-06]\n",
      " [4.8195539e-06]]\n",
      "2900 0.6931472 [[3.2543999e-06]\n",
      " [3.2519470e-06]]\n",
      "3000 0.6931472 [[2.2008858e-06]\n",
      " [2.1984329e-06]]\n",
      "3100 0.6931472 [[1.4871194e-06]\n",
      " [1.4876467e-06]]\n",
      "3200 0.6931472 [[9.968674e-07]\n",
      " [9.973946e-07]]\n",
      "3300 0.6931471 [[6.601006e-07]\n",
      " [6.606279e-07]]\n",
      "3400 0.6931472 [[4.4105346e-07]\n",
      " [4.4158077e-07]]\n",
      "3500 0.6931472 [[2.9204128e-07]\n",
      " [2.9256859e-07]]\n",
      "3600 0.6931472 [[1.8624263e-07]\n",
      " [1.8676994e-07]]\n",
      "3700 0.6931472 [[1.3706861e-07]\n",
      " [1.3759592e-07]]\n",
      "3800 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "3900 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4000 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4100 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4200 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4300 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4400 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4500 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4600 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4700 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4800 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "4900 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5000 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5100 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5200 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5300 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5400 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5500 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5600 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5700 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5800 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "5900 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6000 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6100 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6200 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6300 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6400 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6500 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6600 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6700 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6800 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "6900 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7000 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7100 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7200 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7300 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7400 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7500 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7600 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7700 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7800 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "7900 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8000 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8100 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8200 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8300 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8400 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8500 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8600 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8700 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8800 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "8900 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9000 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9100 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9200 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9300 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9400 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9500 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9600 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9700 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9800 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "9900 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "10000 0.6931472 [[1.3259825e-07]\n",
      " [1.3312555e-07]]\n",
      "hv: [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] pre: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] acc: 0.5\n",
      "bias [-1.7798104e-07]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata, y:ydata})# x,y data 필요 \n",
    "        if step % 100 == 0 :\n",
    "            print(step, sess.run(cost, feed_dict={x:xdata, y:ydata}), sess.run(w)) \n",
    "    hv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})        \n",
    "    print('hv:', hv, 'pre:', pv, 'acc:', av)\n",
    "    print('bias', sess.run(b))\n",
    "            # w가 두개 필요하다 \n",
    "# result \n",
    "# step number, w1, w2\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = [[0,0],[0,1],[1,0],[1,1]]\n",
    "ydata = [[0],[1],[1],[0]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,2])\n",
    "y = tf.placeholder(tf.float32, [None,1])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,2]))\n",
    "b1 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "L1 = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([2,2]))\n",
    "b2 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "hf = tf.sigmoid(tf.matmul(L1, w2) + b2) # 최종가설함수 \n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1185924 [[-1.0720356   0.44674316]\n",
      " [-0.0502847   1.716932  ]] [[ 1.5520248  -0.20845415]\n",
      " [ 1.9702677   0.8978331 ]]\n",
      "100 0.7166582 [[-1.2391652   0.16828017]\n",
      " [-0.24205667  1.4249262 ]] [[ 0.89138424 -0.20222582]\n",
      " [ 1.2933211   0.84998155]]\n",
      "200 0.6973474 [[-1.2423301   0.02643958]\n",
      " [-0.25382292  1.3383446 ]] [[ 0.75502086 -0.18625082]\n",
      " [ 1.1585029   0.8342385 ]]\n",
      "300 0.6951462 [[-1.2268194  -0.09386773]\n",
      " [-0.24204972  1.2989982 ]] [[ 0.7186717  -0.17826967]\n",
      " [ 1.1272943   0.82497084]]\n",
      "400 0.69341016 [[-1.2086887  -0.21511541]\n",
      " [-0.22767851  1.2745305 ]] [[ 0.6990106  -0.17443028]\n",
      " [ 1.1194048   0.8232831 ]]\n",
      "500 0.69162285 [[-1.1903985  -0.3396781 ]\n",
      " [-0.21404809  1.2617732 ]] [[ 0.68135804 -0.17308067]\n",
      " [ 1.121803    0.83020645]]\n",
      "600 0.6897497 [[-1.1724542  -0.4671033 ]\n",
      " [-0.20183332  1.261651  ]] [[ 0.66288286 -0.17380331]\n",
      " [ 1.1320897   0.8459128 ]]\n",
      "700 0.68774927 [[-1.1550117  -0.5969579 ]\n",
      " [-0.19121546  1.2752388 ]] [[ 0.64297163 -0.17653833]\n",
      " [ 1.1497056   0.87029105]]\n",
      "800 0.68555593 [[-1.1381468  -0.7293044 ]\n",
      " [-0.18225722  1.3031964 ]] [[ 0.62145966 -0.18131189]\n",
      " [ 1.1745139   0.9032358 ]]\n",
      "900 0.6830831 [[-1.1219136  -0.8646731 ]\n",
      " [-0.17497122  1.3458004 ]] [[ 0.5982728  -0.18818402]\n",
      " [ 1.2065805   0.9447592 ]]\n",
      "1000 0.6802292 [[-1.106359  -1.0039107]\n",
      " [-0.1693333  1.4030417]] [[ 0.5733347  -0.19725092]\n",
      " [ 1.2461206   0.9950102 ]]\n",
      "1100 0.6768838 [[-1.0915424  -1.1480097 ]\n",
      " [-0.16528216  1.4746686 ]] [[ 0.5465436  -0.20864832]\n",
      " [ 1.2934492   1.05424   ]]\n",
      "1200 0.6729351 [[-1.0775496 -1.2979418]\n",
      " [-0.1627125  1.560174 ]] [[ 0.51776713 -0.22254503]\n",
      " [ 1.3489109   1.1227291 ]]\n",
      "1300 0.6682816 [[-1.0645139  -1.4544888 ]\n",
      " [-0.16146167  1.6587334 ]] [[ 0.48686048 -0.23912495]\n",
      " [ 1.4127915   1.2006919 ]]\n",
      "1400 0.6628455 [[-1.0526369  -1.6180751 ]\n",
      " [-0.16129427  1.7691681 ]] [[ 0.45368814 -0.2585607 ]\n",
      " [ 1.485232    1.2881584 ]]\n",
      "1500 0.65658826 [[-1.0422076  -1.7886187 ]\n",
      " [-0.16188702  1.8899506 ]] [[ 0.4181459  -0.28098556]\n",
      " [ 1.566138    1.3848944 ]]\n",
      "1600 0.6495238 [[-1.0336138  -1.9654405 ]\n",
      " [-0.16281946  2.0192761 ]] [[ 0.38017297 -0.30647576]\n",
      " [ 1.6551179   1.4903215 ]]\n",
      "1700 0.64172304 [[-1.0273503  -2.1472688 ]\n",
      " [-0.16357386  2.1551855 ]] [[ 0.3397501 -0.3350445]\n",
      " [ 1.7514604  1.6035006]]\n",
      "1800 0.6333107 [[-1.0240067  -2.3323545 ]\n",
      " [-0.16354394  2.2956812 ]] [[ 0.2968816  -0.36665672]\n",
      " [ 1.8541534   1.7231716 ]]\n",
      "1900 0.6244508 [[-1.0242445  -2.5186777 ]\n",
      " [-0.16205192  2.438849  ]] [[ 0.25156808 -0.40125597]\n",
      " [ 1.9619517   1.8478447 ]]\n",
      "2000 0.6153258 [[-1.0287601  -2.7041786 ]\n",
      " [-0.15836832  2.582925  ]] [[ 0.20377676 -0.43879724]\n",
      " [ 2.073474    1.9759195 ]]\n",
      "2100 0.60611326 [[-1.0382446 -2.8869681]\n",
      " [-0.1517321  2.7263484]] [[ 0.15341498 -0.47928   ]\n",
      " [ 2.1873183   2.1058214 ]]\n",
      "2200 0.59696543 [[-1.0533341  -3.0654767 ]\n",
      " [-0.14136532  2.867811  ]] [[ 0.10030989 -0.52277327]\n",
      " [ 2.3021655   2.2361166 ]]\n",
      "2300 0.58799595 [[-1.0745666  -3.2385154 ]\n",
      " [-0.12647963  3.0062745 ]] [[ 0.04419937 -0.5694302 ]\n",
      " [ 2.4168613   2.3655992 ]]\n",
      "2400 0.5792737 [[-1.1023327  -3.40529   ]\n",
      " [-0.10626969  3.1409757 ]] [[-0.01526621 -0.61948824]\n",
      " [ 2.5304706   2.4933314 ]]\n",
      "2500 0.57082313 [[-1.1368338  -3.56536   ]\n",
      " [-0.07989056  3.271419  ]] [[-0.07851017 -0.67325675]\n",
      " [ 2.6423      2.6186683 ]]\n",
      "2600 0.56262916 [[-1.1780374  -3.718576  ]\n",
      " [-0.04641433  3.3973484 ]] [[-0.14600727 -0.73109466]\n",
      " [ 2.751896    2.7412338 ]]\n",
      "2700 0.554643 [[-1.2256389  -3.865015  ]\n",
      " [-0.00476116  3.518716  ]] [[-0.21825728 -0.7933835 ]\n",
      " [ 2.8590248   2.8609    ]]\n",
      "2800 0.5467859 [[-1.2790315  -4.0049176 ]\n",
      " [ 0.04640442  3.6356528 ]] [[-0.29576483 -0.86050844]\n",
      " [ 2.9636583   2.977753  ]]\n",
      "2900 0.53894913 [[-1.3372895 -4.138629 ]\n",
      " [ 0.108821   3.7484398]] [[-0.37903467 -0.93285257]\n",
      " [ 3.0659509   3.0920622 ]]\n",
      "3000 0.5309857 [[-1.3991845  -4.26655   ]\n",
      " [ 0.18482818  3.85749   ]] [[-0.46859512 -1.0108213 ]\n",
      " [ 3.1662118   3.204258  ]]\n",
      "3100 0.5226892 [[-1.4632679 -4.3890944]\n",
      " [ 0.277603   3.9633317]] [[-0.56506395 -1.0949107 ]\n",
      " [ 3.2649012   3.3149004 ]]\n",
      "3200 0.51375705 [[-1.5280848  -4.50663   ]\n",
      " [ 0.39135888  4.066597  ]] [[-0.6692651 -1.1858276]\n",
      " [ 3.362612   3.4246597]]\n",
      "3300 0.503742 [[-1.5926946  -4.619429  ]\n",
      " [ 0.53126454  4.167982  ]] [[-0.7823868 -1.284658 ]\n",
      " [ 3.4600446  3.5342557]]\n",
      "3400 0.49202865 [[-1.6577536  -4.727603  ]\n",
      " [ 0.70254403  4.268154  ]] [[-0.9061183 -1.3930295]\n",
      " [ 3.5579402  3.6443338]]\n",
      "3500 0.47792944 [[-1.7270985  -4.831045  ]\n",
      " [ 0.90812737  4.3675494 ]] [[-1.0425818 -1.5131162]\n",
      " [ 3.6569228  3.7552593]]\n",
      "3600 0.46095946 [[-1.8084366 -4.9295516]\n",
      " [ 1.1455259  4.466144 ]] [[-1.193878  -1.647269 ]\n",
      " [ 3.7573133  3.866917 ]]\n",
      "3700 0.44108492 [[-1.9105421 -5.022962 ]\n",
      " [ 1.4061675  4.56346  ]] [[-1.361355  -1.7972648]\n",
      " [ 3.859065   3.978784 ]]\n",
      "3800 0.41867006 [[-2.0379312 -5.1113214]\n",
      " [ 1.6790142  4.6589575]] [[-1.5449926 -1.9634571]\n",
      " [ 3.9619768  4.0903587]]\n",
      "3900 0.3943103 [[-2.1885319 -5.1948147]\n",
      " [ 1.9545395  4.7523565]] [[-1.7430738 -2.1442146]\n",
      " [ 4.065921   4.201454 ]]\n",
      "4000 0.36876237 [[-2.355973  -5.2736783]\n",
      " [ 2.2257357  4.843543 ]] [[-1.9522855 -2.3360915]\n",
      " [ 4.1708455  4.312108 ]]\n",
      "4100 0.3428696 [[-2.5328963 -5.348148 ]\n",
      " [ 2.4875183  4.9323273]] [[-2.1683466 -2.5346875]\n",
      " [ 4.276627   4.4223223]]\n",
      "4200 0.31743592 [[-2.7128713 -5.4184694]\n",
      " [ 2.7362766  5.018368 ]] [[-2.386839  -2.7356114]\n",
      " [ 4.3829875  4.5319314]]\n",
      "4300 0.2931133 [[-2.8909874 -5.484903 ]\n",
      " [ 2.9697363  5.101257 ]] [[-2.6038535 -2.935126 ]\n",
      " [ 4.489498   4.6406207]]\n",
      "4400 0.27034944 [[-3.063809 -5.547714]\n",
      " [ 3.18683   5.18063 ]] [[-2.8163052 -3.1303847]\n",
      " [ 4.595681   4.748006 ]]\n",
      "4500 0.24939173 [[-3.2291358 -5.607166 ]\n",
      " [ 3.3874557  5.256241 ]] [[-3.0219967 -3.3194294]\n",
      " [ 4.7010384  4.853711 ]]\n",
      "4600 0.23032367 [[-3.3857324 -5.663509 ]\n",
      " [ 3.572187   5.3279767]] [[-3.219527  -3.5010543]\n",
      " [ 4.8051267  4.95741  ]]\n",
      "4700 0.21311218 [[-3.5330694 -5.716979 ]\n",
      " [ 3.7420087  5.395844 ]] [[-3.4081333 -3.6746304]\n",
      " [ 4.9075727  5.0588503]]\n",
      "4800 0.19765148 [[-3.6711063 -5.767791 ]\n",
      " [ 3.8981037  5.45994  ]] [[-3.5875347 -3.8399515]\n",
      " [ 5.0080805  5.157845 ]]\n",
      "4900 0.18379721 [[-3.8001199 -5.8161454]\n",
      " [ 4.041719   5.520424 ]] [[-3.7577887 -3.9970984]\n",
      " [ 5.10643    5.25428  ]]\n",
      "5000 0.17139035 [[-3.9205747 -5.8622193]\n",
      " [ 4.174074   5.5774956]] [[-3.9191692 -4.146333 ]\n",
      " [ 5.202465   5.3480935]]\n",
      "5100 0.1602722 [[-4.0330343 -5.9061794]\n",
      " [ 4.296317   5.6313705]] [[-4.0720873 -4.288029 ]\n",
      " [ 5.296096   5.439266 ]]\n",
      "5200 0.15029302 [[-4.1381    -5.948176 ]\n",
      " [ 4.4094887  5.6822696]] [[-4.2170286 -4.4226155]\n",
      " [ 5.387267   5.527814 ]]\n",
      "5300 0.1413165 [[-4.236367  -5.988345 ]\n",
      " [ 4.5145354  5.730408 ]] [[-4.354504  -4.550543 ]\n",
      " [ 5.475967   5.6137776]]\n",
      "5400 0.13322082 [[-4.328414  -6.026814 ]\n",
      " [ 4.6122947  5.775994 ]] [[-4.4850297 -4.6722627]\n",
      " [ 5.5622053  5.6972165]]\n",
      "5500 0.12589881 [[-4.4147763 -6.0636945]\n",
      " [ 4.703511   5.8192263]] [[-4.6091022 -4.788211 ]\n",
      " [ 5.6460195  5.7781982]]\n",
      "5600 0.119256824 [[-4.4959555 -6.099088 ]\n",
      " [ 4.788841   5.8602853]] [[-4.7271967 -4.898798 ]\n",
      " [ 5.727465   5.8568068]]\n",
      "5700 0.113213666 [[-4.5723996 -6.1330924]\n",
      " [ 4.8688626  5.899337 ]] [[-4.8397565 -5.0044093]\n",
      " [ 5.806599   5.933126 ]]\n",
      "5800 0.10769892 [[-4.6445208 -6.1657953]\n",
      " [ 4.944086   5.936536 ]] [[-4.947194 -5.105408]\n",
      " [ 5.883494  6.00724 ]]\n",
      "5900 0.10265175 [[-4.712689  -6.1972795]\n",
      " [ 5.014955   5.972022 ]] [[-5.0498843 -5.2021213]\n",
      " [ 5.958223   6.079238 ]]\n",
      "6000 0.098019354 [[-4.7772384 -6.227615 ]\n",
      " [ 5.0818686  6.0059223]] [[-5.1481695 -5.2948513]\n",
      " [ 6.0308633  6.149205 ]]\n",
      "6100 0.093756035 [[-4.838469  -6.2568717]\n",
      " [ 5.145177   6.0383525]] [[-5.24237   -5.383876 ]\n",
      " [ 6.1014934  6.2172256]]\n",
      "6200 0.08982203 [[-4.8966465 -6.2851133]\n",
      " [ 5.205192   6.069418 ]] [[-5.332775  -5.4694495]\n",
      " [ 6.17019    6.2833834]]\n",
      "6300 0.086182706 [[-4.952017  -6.3123984]\n",
      " [ 5.2621913  6.099216 ]] [[-5.4196463 -5.551803 ]\n",
      " [ 6.2370315  6.3477573]]\n",
      "6400 0.08280791 [[-5.004794  -6.338779 ]\n",
      " [ 5.3164206  6.1278324]] [[-5.503225  -5.63115  ]\n",
      " [ 6.3020926  6.4104233]]\n",
      "6500 0.07967133 [[-5.055177  -6.3643064]\n",
      " [ 5.3681006  6.155348 ]] [[-5.5837274 -5.707682 ]\n",
      " [ 6.3654447  6.4714537]]\n",
      "6600 0.07674967 [[-5.1033444 -6.3890257]\n",
      " [ 5.417426   6.1818333]] [[-5.6613555 -5.781579 ]\n",
      " [ 6.427159   6.5309224]]\n",
      "6700 0.07402257 [[-5.149453  -6.412982 ]\n",
      " [ 5.4645762  6.207356 ]] [[-5.736291 -5.853001]\n",
      " [ 6.487302  6.588893]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800 0.07147202 [[-5.193649 -6.436214]\n",
      " [ 5.509711  6.231976]] [[-5.8087    -5.922099 ]\n",
      " [ 6.5459404  6.6454296]]\n",
      "6900 0.06908211 [[-5.2360644 -6.4587593]\n",
      " [ 5.552971   6.255749 ]] [[-5.87874   -5.9890094]\n",
      " [ 6.6031346  6.700592 ]]\n",
      "7000 0.06683867 [[-5.276817 -6.480651]\n",
      " [ 5.594488  6.278727]] [[-5.9465485 -6.053859 ]\n",
      " [ 6.6589456  6.754438 ]]\n",
      "7100 0.064729095 [[-5.3160195 -6.5019207]\n",
      " [ 5.63438    6.3009562]] [[-6.0122557 -6.1167636]\n",
      " [ 6.7134266  6.807022 ]]\n",
      "7200 0.06274228 [[-5.353768  -6.5226007]\n",
      " [ 5.6727552  6.3224792]] [[-6.075979  -6.1778307]\n",
      " [ 6.766633   6.858394 ]]\n",
      "7300 0.060868032 [[-5.390155  -6.5427184]\n",
      " [ 5.70971    6.343334 ]] [[-6.1378307 -6.237159 ]\n",
      " [ 6.8186183  6.908606 ]]\n",
      "7400 0.05909746 [[-5.4252634 -6.5623   ]\n",
      " [ 5.745334   6.363559 ]] [[-6.1979113 -6.294837 ]\n",
      " [ 6.869427   6.957702 ]]\n",
      "7500 0.05742235 [[-5.4591703 -6.581372 ]\n",
      " [ 5.779708   6.383187 ]] [[-6.2563133 -6.3509555]\n",
      " [ 6.919107   7.005727 ]]\n",
      "7600 0.055835534 [[-5.4919424 -6.599954 ]\n",
      " [ 5.8129086  6.4022493]] [[-6.313124 -6.40559 ]\n",
      " [ 6.967703  7.052722]]\n",
      "7700 0.054330304 [[-5.523647  -6.6180706]\n",
      " [ 5.8450027  6.4207764]] [[-6.368426  -6.458815 ]\n",
      " [ 7.015255   7.0987267]]\n",
      "7800 0.05290077 [[-5.5543427 -6.6357417]\n",
      " [ 5.876055   6.4387946]] [[-6.4222918 -6.5106974]\n",
      " [ 7.061803   7.1437783]]\n",
      "7900 0.051541526 [[-5.584085 -6.652985]\n",
      " [ 5.906121  6.456329]] [[-6.474792  -6.5613003]\n",
      " [ 7.107385   7.1879125]]\n",
      "8000 0.050247602 [[-5.6129255 -6.6698184]\n",
      " [ 5.9352574  6.473403 ]] [[-6.525991  -6.6106863]\n",
      " [ 7.1520386  7.231163 ]]\n",
      "8100 0.04901454 [[-5.640911  -6.6862607]\n",
      " [ 5.9635124  6.4900384]] [[-6.5759478 -6.6589065]\n",
      " [ 7.1957955  7.2735624]]\n",
      "8200 0.047838263 [[-5.668084  -6.702328 ]\n",
      " [ 5.990934   6.5062537]] [[-6.624723  -6.7060146]\n",
      " [ 7.2386885  7.315141 ]]\n",
      "8300 0.04671502 [[-5.694487  -6.7180343]\n",
      " [ 6.0175624  6.5220704]] [[-6.672366  -6.7520585]\n",
      " [ 7.2807493  7.355929 ]]\n",
      "8400 0.045641407 [[-5.720157  -6.733393 ]\n",
      " [ 6.043438   6.5375047]] [[-6.718928  -6.7970843]\n",
      " [ 7.3220053  7.3959527]]\n",
      "8500 0.04461427 [[-5.7451296 -6.748419 ]\n",
      " [ 6.0685983  6.5525737]] [[-6.764455  -6.8411345]\n",
      " [ 7.3624873  7.4352384]]\n",
      "8600 0.043630708 [[-5.7694373 -6.763124 ]\n",
      " [ 6.093077   6.567293 ]] [[-6.80899   -6.88425  ]\n",
      " [ 7.4022202  7.473811 ]]\n",
      "8700 0.042688124 [[-5.793112  -6.777522 ]\n",
      " [ 6.1169066  6.581678 ]] [[-6.852575  -6.9264674]\n",
      " [ 7.44123    7.5116963]]\n",
      "8800 0.041783962 [[-5.816181  -6.791623 ]\n",
      " [ 6.1401186  6.5957413]] [[-6.895247 -6.967824]\n",
      " [ 7.479539  7.548915]]\n",
      "8900 0.04091607 [[-5.8386726 -6.805438 ]\n",
      " [ 6.1627393  6.609497 ]] [[-6.9370437 -7.008352 ]\n",
      " [ 7.5171733  7.585489 ]]\n",
      "9000 0.04008233 [[-5.860613 -6.818977]\n",
      " [ 6.184796  6.622957]] [[-6.977999 -7.048083]\n",
      " [ 7.554153  7.62144 ]]\n",
      "9100 0.039280787 [[-5.8820233 -6.8322506]\n",
      " [ 6.206313   6.636134 ]] [[-7.0181446 -7.0870476]\n",
      " [ 7.5904994  7.656786 ]]\n",
      "9200 0.038509652 [[-5.9029274 -6.8452673]\n",
      " [ 6.2273135  6.649036 ]] [[-7.0575113 -7.125273 ]\n",
      " [ 7.6262336  7.691549 ]]\n",
      "9300 0.037767254 [[-5.923346  -6.8580356]\n",
      " [ 6.247819   6.6616764]] [[-7.0961285 -7.1627884]\n",
      " [ 7.6613736  7.7257447]]\n",
      "9400 0.037052065 [[-5.943299  -6.8705654]\n",
      " [ 6.2678504  6.6740627]] [[-7.134024  -7.199618 ]\n",
      " [ 7.6959376  7.7593913]]\n",
      "9500 0.036362685 [[-5.9628053 -6.882865 ]\n",
      " [ 6.2874274  6.6862054]] [[-7.1712217 -7.2357845]\n",
      " [ 7.729944   7.792505 ]]\n",
      "9600 0.0356977 [[-5.9818816 -6.894939 ]\n",
      " [ 6.3065686  6.698114 ]] [[-7.2077484 -7.2713118]\n",
      " [ 7.76341    7.8251023]]\n",
      "9700 0.035055865 [[-6.000546  -6.906799 ]\n",
      " [ 6.3252892  6.7097955]] [[-7.243626  -7.3062215]\n",
      " [ 7.7963505  7.8571978]]\n",
      "9800 0.03443605 [[-6.018814  -6.9184465]\n",
      " [ 6.3436074  6.721257 ]] [[-7.2788773 -7.340535 ]\n",
      " [ 7.8287807  7.8888063]]\n",
      "9900 0.033837117 [[-6.0367    -6.9298925]\n",
      " [ 6.3615375  6.732508 ]] [[-7.313523  -7.374272 ]\n",
      " [ 7.8607173  7.9199414]]\n",
      "10000 0.03325812 [[-6.0542183 -6.9411426]\n",
      " [ 6.3790946  6.743556 ]] [[-7.3475823 -7.4074497]\n",
      " [ 7.8921723  7.9506164]]\n",
      "hv: [[0.03142816 0.03065205]\n",
      " [0.9724565  0.97313666]\n",
      " [0.95423    0.9553958 ]\n",
      " [0.02765685 0.0269438 ]] pre: [[0. 0.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]] acc: 1.0\n",
      "\n",
      "bias: [ 2.9661844 -3.6386876] [3.3574553 3.3870862]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata, y:ydata})# x,y data 필요 \n",
    "        if step % 100 == 0 :\n",
    "            print(step, sess.run(cost, feed_dict={x:xdata, y:ydata}), \n",
    "                  sess.run(w1), sess.run(w2)) \n",
    "    hv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})        \n",
    "    print('hv:', hv, 'pre:', pv, 'acc:', av)\n",
    "    print('\\nbias:', sess.run(b1), sess.run(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None,2])\n",
    "y = tf.placeholder(tf.float32, [None,1])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "L1 = tf.sigmoid(tf.matmul(x, w1) + b1) # 출력이자 입력 층\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([10,1]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "# 2,1 로 빠져나온다\n",
    "hf = tf.sigmoid(tf.matmul(L1, w2) + b2) # 최종가설함수 \n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 2.3926592\n",
      "100 cost: 0.6829141\n",
      "200 cost: 0.6608696\n",
      "300 cost: 0.6384851\n",
      "400 cost: 0.6128551\n",
      "500 cost: 0.58255494\n",
      "600 cost: 0.5471357\n",
      "700 cost: 0.5069373\n",
      "800 cost: 0.46297786\n",
      "900 cost: 0.4168315\n",
      "1000 cost: 0.3704297\n",
      "1100 cost: 0.32574448\n",
      "1200 cost: 0.2844191\n",
      "1300 cost: 0.24750161\n",
      "1400 cost: 0.21539298\n",
      "1500 cost: 0.1879781\n",
      "1600 cost: 0.16482699\n",
      "1700 cost: 0.14537464\n",
      "1800 cost: 0.12904033\n",
      "1900 cost: 0.115291096\n",
      "2000 cost: 0.10366739\n",
      "2100 cost: 0.09378648\n",
      "2200 cost: 0.08533544\n",
      "2300 cost: 0.07806119\n",
      "2400 cost: 0.07176003\n",
      "2500 cost: 0.0662677\n",
      "2600 cost: 0.061451778\n",
      "2700 cost: 0.05720483\n",
      "2800 cost: 0.05343947\n",
      "2900 cost: 0.050084166\n",
      "3000 cost: 0.047079965\n",
      "3100 cost: 0.04437809\n",
      "3200 cost: 0.04193799\n",
      "3300 cost: 0.039725557\n",
      "3400 cost: 0.037712336\n",
      "3500 cost: 0.03587391\n",
      "3600 cost: 0.034189727\n",
      "3700 cost: 0.032642115\n",
      "3800 cost: 0.031216018\n",
      "3900 cost: 0.02989837\n",
      "4000 cost: 0.028677713\n",
      "4100 cost: 0.02754436\n",
      "4200 cost: 0.026489604\n",
      "4300 cost: 0.02550588\n",
      "4400 cost: 0.024586642\n",
      "4500 cost: 0.023725977\n",
      "4600 cost: 0.022918679\n",
      "4700 cost: 0.022160115\n",
      "4800 cost: 0.02144621\n",
      "4900 cost: 0.02077331\n",
      "5000 cost: 0.020138051\n",
      "5100 cost: 0.019537557\n",
      "5200 cost: 0.018969115\n",
      "5300 cost: 0.018430289\n",
      "5400 cost: 0.017918942\n",
      "5500 cost: 0.01743314\n",
      "5600 cost: 0.016971052\n",
      "5700 cost: 0.016531006\n",
      "5800 cost: 0.016111532\n",
      "5900 cost: 0.015711345\n",
      "6000 cost: 0.015329089\n",
      "6100 cost: 0.014963714\n",
      "6200 cost: 0.014614081\n",
      "6300 cost: 0.014279294\n",
      "6400 cost: 0.013958385\n",
      "6500 cost: 0.013650615\n",
      "6600 cost: 0.013355186\n",
      "6700 cost: 0.013071392\n",
      "6800 cost: 0.012798557\n",
      "6900 cost: 0.012536127\n",
      "7000 cost: 0.012283538\n",
      "7100 cost: 0.01204019\n",
      "7200 cost: 0.011805687\n",
      "7300 cost: 0.011579508\n",
      "7400 cost: 0.01136127\n",
      "7500 cost: 0.011150606\n",
      "7600 cost: 0.010947013\n",
      "7700 cost: 0.010750292\n",
      "7800 cost: 0.01056006\n",
      "7900 cost: 0.010375968\n",
      "8000 cost: 0.010197816\n",
      "8100 cost: 0.010025255\n",
      "8200 cost: 0.009858056\n",
      "8300 cost: 0.00969602\n",
      "8400 cost: 0.009538842\n",
      "8500 cost: 0.009386373\n",
      "8600 cost: 0.009238397\n",
      "8700 cost: 0.009094731\n",
      "8800 cost: 0.008955179\n",
      "8900 cost: 0.008819559\n",
      "9000 cost: 0.008687747\n",
      "9100 cost: 0.008559578\n",
      "9200 cost: 0.008434868\n",
      "9300 cost: 0.008313544\n",
      "9400 cost: 0.0081954505\n",
      "9500 cost: 0.008080454\n",
      "9600 cost: 0.007968445\n",
      "9700 cost: 0.0078592915\n",
      "9800 cost: 0.007752913\n",
      "9900 cost: 0.0076492066\n",
      "10000 cost: 0.00754808\n",
      "hv: [[0.00520767]\n",
      " [0.99341387]\n",
      " [0.99195564]\n",
      " [0.01023354]] pre: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 순수하게 cost만 출력\n",
    "# cost를 줄이기위해 layer를 10개로 늘려랏! \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata, y:ydata})# x,y data 필요 \n",
    "        if step % 100 == 0 :\n",
    "            print(step, 'cost:',sess.run(cost, feed_dict={x:xdata, y:ydata})) \n",
    "    hv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})        \n",
    "    print('hv:', hv, 'pre:', pv, 'acc:', av)\n",
    "#     print('\\nbias:', sess.run(b1), sess.run(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide nn : 0.007\n",
    "# wide 한 step  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 1.0532382\n",
      "100 cost: 0.7422164\n",
      "200 cost: 0.6930148\n",
      "300 cost: 0.68731594\n",
      "400 cost: 0.68566024\n",
      "500 cost: 0.6842843\n",
      "600 cost: 0.6828438\n",
      "700 cost: 0.68127805\n",
      "800 cost: 0.67954904\n",
      "900 cost: 0.6776179\n",
      "1000 cost: 0.6754438\n",
      "1100 cost: 0.6729829\n",
      "1200 cost: 0.6701891\n",
      "1300 cost: 0.6670152\n",
      "1400 cost: 0.6634151\n",
      "1500 cost: 0.6593467\n",
      "1600 cost: 0.65477675\n",
      "1700 cost: 0.64968526\n",
      "1800 cost: 0.6440705\n",
      "1900 cost: 0.6379516\n",
      "2000 cost: 0.63137025\n",
      "2100 cost: 0.62438726\n",
      "2200 cost: 0.61707675\n",
      "2300 cost: 0.60951763\n",
      "2400 cost: 0.60178405\n",
      "2500 cost: 0.59393734\n",
      "2600 cost: 0.58602077\n",
      "2700 cost: 0.5780565\n",
      "2800 cost: 0.57004637\n",
      "2900 cost: 0.5619729\n",
      "3000 cost: 0.5538022\n",
      "3100 cost: 0.545485\n",
      "3200 cost: 0.53695744\n",
      "3300 cost: 0.52813977\n",
      "3400 cost: 0.5189355\n",
      "3500 cost: 0.50922894\n",
      "3600 cost: 0.49888355\n",
      "3700 cost: 0.4877395\n",
      "3800 cost: 0.47561437\n",
      "3900 cost: 0.46230698\n",
      "4000 cost: 0.44760936\n",
      "4100 cost: 0.43133003\n",
      "4200 cost: 0.41332847\n",
      "4300 cost: 0.3935599\n",
      "4400 cost: 0.37211806\n",
      "4500 cost: 0.34925932\n",
      "4600 cost: 0.32539055\n",
      "4700 cost: 0.3010135\n",
      "4800 cost: 0.27663797\n",
      "4900 cost: 0.25268263\n",
      "5000 cost: 0.22937436\n",
      "5100 cost: 0.20663841\n",
      "5200 cost: 0.18402696\n",
      "5300 cost: 0.1611888\n",
      "5400 cost: 0.13941346\n",
      "5500 cost: 0.12090168\n",
      "5600 cost: 0.10609337\n",
      "5700 cost: 0.094317354\n",
      "5800 cost: 0.0848346\n",
      "5900 cost: 0.07707073\n",
      "6000 cost: 0.07060937\n",
      "6100 cost: 0.06515191\n",
      "6200 cost: 0.060482003\n",
      "6300 cost: 0.05644057\n",
      "6400 cost: 0.052908175\n",
      "6500 cost: 0.04979388\n",
      "6600 cost: 0.04702709\n",
      "6700 cost: 0.044552293\n",
      "6800 cost: 0.04232518\n",
      "6900 cost: 0.040310036\n",
      "7000 cost: 0.03847775\n",
      "7100 cost: 0.036804236\n",
      "7200 cost: 0.035269577\n",
      "7300 cost: 0.033856995\n",
      "7400 cost: 0.032552365\n",
      "7500 cost: 0.03134366\n",
      "7600 cost: 0.030220574\n",
      "7700 cost: 0.02917428\n",
      "7800 cost: 0.028197061\n",
      "7900 cost: 0.027282264\n",
      "8000 cost: 0.026424056\n",
      "8100 cost: 0.02561731\n",
      "8200 cost: 0.024857514\n",
      "8300 cost: 0.024140622\n",
      "8400 cost: 0.023463134\n",
      "8500 cost: 0.022821844\n",
      "8600 cost: 0.022213917\n",
      "8700 cost: 0.021636814\n",
      "8800 cost: 0.021088243\n",
      "8900 cost: 0.020566119\n",
      "9000 cost: 0.020068591\n",
      "9100 cost: 0.019593958\n",
      "9200 cost: 0.019140657\n",
      "9300 cost: 0.018707301\n",
      "9400 cost: 0.018292585\n",
      "9500 cost: 0.01789533\n",
      "9600 cost: 0.017514478\n",
      "9700 cost: 0.01714903\n",
      "9800 cost: 0.016798053\n",
      "9900 cost: 0.016460733\n",
      "10000 cost: 0.016136268\n",
      "hv: [[0.01704082 0.01701334 0.01234114 0.01357856 0.01513803 0.01970497\n",
      "  0.00710025 0.01897886 0.0101738  0.01295269]\n",
      " [0.9806329  0.9883625  0.98530686 0.985706   0.9844898  0.98638034\n",
      "  0.9880991  0.9874222  0.98422694 0.986565  ]\n",
      " [0.9796238  0.9848758  0.98196584 0.9832022  0.97904795 0.9846426\n",
      "  0.9869604  0.98585737 0.97936654 0.9830433 ]\n",
      " [0.02456573 0.01099128 0.02118555 0.01828811 0.02308089 0.01064798\n",
      "  0.01753148 0.00911859 0.02772021 0.01852483]] pre: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# deep & wide\n",
    "# wide - 층을 구성하는 노드의수 가 많다 \n",
    "# deep - layer 수가 많다 \n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,2])\n",
    "y = tf.placeholder(tf.float32, [None,1])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "L1 = tf.sigmoid(tf.matmul(x, w1) + b1) # 출력이자 입력 층\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([10,10]))\n",
    "b2 = tf.Variable(tf.random_normal([10]))\n",
    "L2 = tf.sigmoid(tf.matmul(L1, w2) + b2) # 최종가설함수 \n",
    "# -> layer 층\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([10,10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "# deep & wide\n",
    "L3 = tf.sigmoid(tf.matmul(L2, w3) + b3) # 최종가설함수 \n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([10,10]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "# deep & wide\n",
    "hf = tf.sigmoid(tf.matmul(L3, w4) + b4) # 최종가설함수 \n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata, y:ydata})# x,y data 필요 \n",
    "        if step % 100 == 0 :\n",
    "            print(step, 'cost:',sess.run(cost, feed_dict={x:xdata, y:ydata})) \n",
    "    hv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})        \n",
    "    print('hv:', hv, 'pre:', pv, 'acc:', av)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 0.6961013\n",
      "100 cost: 0.6931454\n",
      "200 cost: 0.6931454\n",
      "300 cost: 0.6931454\n",
      "400 cost: 0.69314533\n",
      "500 cost: 0.6931453\n",
      "600 cost: 0.6931453\n",
      "700 cost: 0.6931452\n",
      "800 cost: 0.69314533\n",
      "900 cost: 0.69314516\n",
      "1000 cost: 0.6931453\n",
      "1100 cost: 0.69314516\n",
      "1200 cost: 0.69314516\n",
      "1300 cost: 0.69314516\n",
      "1400 cost: 0.69314516\n",
      "1500 cost: 0.69314504\n",
      "1600 cost: 0.6931451\n",
      "1700 cost: 0.69314504\n",
      "1800 cost: 0.69314504\n",
      "1900 cost: 0.69314504\n",
      "2000 cost: 0.6931451\n",
      "2100 cost: 0.69314504\n",
      "2200 cost: 0.6931449\n",
      "2300 cost: 0.6931449\n",
      "2400 cost: 0.6931449\n",
      "2500 cost: 0.6931449\n",
      "2600 cost: 0.6931449\n",
      "2700 cost: 0.6931449\n",
      "2800 cost: 0.69314486\n",
      "2900 cost: 0.6931448\n",
      "3000 cost: 0.69314474\n",
      "3100 cost: 0.6931448\n",
      "3200 cost: 0.69314474\n",
      "3300 cost: 0.69314474\n",
      "3400 cost: 0.6931447\n",
      "3500 cost: 0.6931447\n",
      "3600 cost: 0.6931447\n",
      "3700 cost: 0.69314456\n",
      "3800 cost: 0.6931447\n",
      "3900 cost: 0.6931447\n",
      "4000 cost: 0.69314456\n",
      "4100 cost: 0.69314456\n",
      "4200 cost: 0.69314456\n",
      "4300 cost: 0.69314456\n",
      "4400 cost: 0.6931445\n",
      "4500 cost: 0.69314456\n",
      "4600 cost: 0.6931445\n",
      "4700 cost: 0.69314444\n",
      "4800 cost: 0.69314444\n",
      "4900 cost: 0.69314444\n",
      "5000 cost: 0.69314444\n",
      "5100 cost: 0.69314444\n",
      "5200 cost: 0.6931444\n",
      "5300 cost: 0.6931443\n",
      "5400 cost: 0.6931443\n",
      "5500 cost: 0.6931443\n",
      "5600 cost: 0.6931443\n",
      "5700 cost: 0.6931443\n",
      "5800 cost: 0.6931443\n",
      "5900 cost: 0.6931442\n",
      "6000 cost: 0.6931442\n",
      "6100 cost: 0.6931442\n",
      "6200 cost: 0.69314414\n",
      "6300 cost: 0.6931441\n",
      "6400 cost: 0.6931441\n",
      "6500 cost: 0.6931442\n",
      "6600 cost: 0.6931442\n",
      "6700 cost: 0.693144\n",
      "6800 cost: 0.6931441\n",
      "6900 cost: 0.693144\n",
      "7000 cost: 0.693144\n",
      "7100 cost: 0.69314396\n",
      "7200 cost: 0.693144\n",
      "7300 cost: 0.69314396\n",
      "7400 cost: 0.69314396\n",
      "7500 cost: 0.6931439\n",
      "7600 cost: 0.6931438\n",
      "7700 cost: 0.69314384\n",
      "7800 cost: 0.69314384\n",
      "7900 cost: 0.6931439\n",
      "8000 cost: 0.69314384\n",
      "8100 cost: 0.69314384\n",
      "8200 cost: 0.6931437\n",
      "8300 cost: 0.6931438\n",
      "8400 cost: 0.6931438\n",
      "8500 cost: 0.6931437\n",
      "8600 cost: 0.6931437\n",
      "8700 cost: 0.6931437\n",
      "8800 cost: 0.69314367\n",
      "8900 cost: 0.6931436\n",
      "9000 cost: 0.6931437\n",
      "9100 cost: 0.6931436\n",
      "9200 cost: 0.6931436\n",
      "9300 cost: 0.6931435\n",
      "9400 cost: 0.6931435\n",
      "9500 cost: 0.6931435\n",
      "9600 cost: 0.6931435\n",
      "9700 cost: 0.6931435\n",
      "9800 cost: 0.6931435\n",
      "9900 cost: 0.69314337\n",
      "10000 cost: 0.6931435\n",
      "hv: [[0.49994153]\n",
      " [0.49994934]\n",
      " [0.5000464 ]\n",
      " [0.50004673]] pre: [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]] acc: 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vanishing Gradiant \n",
    "x = tf.placeholder(tf.float32, [None,2])\n",
    "y = tf.placeholder(tf.float32, [None,1])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "L1 = tf.sigmoid(tf.matmul(x, w1) + b1) # 출력이자 입력 층\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([10,10]))\n",
    "b2 = tf.Variable(tf.random_normal([10]))\n",
    "L2 = tf.sigmoid(tf.matmul(L1, w2) + b2) # 최종가설함수 \n",
    "# -> layer 층\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([10,10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "# deep & wide\n",
    "L3 = tf.sigmoid(tf.matmul(L2, w3) + b3) # 최종가설함수 \n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([10,10]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "# deep & wide\n",
    "L4 = tf.sigmoid(tf.matmul(L3, w4) + b4) # 최종가설함수 \n",
    "\n",
    "w5 = tf.Variable(tf.random_normal([10,10]))\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "L5 = tf.sigmoid(tf.matmul(L4, w5) + b5) # 출력이자 입력 층\n",
    "\n",
    "w6 = tf.Variable(tf.random_normal([10,10]))\n",
    "b6 = tf.Variable(tf.random_normal([10]))\n",
    "L6 = tf.sigmoid(tf.matmul(L5, w6) + b6) # 최종가설함수 \n",
    "# -> layer 층\n",
    "\n",
    "w7 = tf.Variable(tf.random_normal([10,10]))\n",
    "b7 = tf.Variable(tf.random_normal([10]))\n",
    "# deep & wide\n",
    "L7 = tf.sigmoid(tf.matmul(L6, w7) + b7) # 최종가설함수 \n",
    "\n",
    "w8 = tf.Variable(tf.random_normal([10,10]))\n",
    "b8 = tf.Variable(tf.random_normal([10]))\n",
    "# deep & wide\n",
    "L8 = tf.sigmoid(tf.matmul(L7, w8) + b8) # 최종가설함수 \n",
    "\n",
    "w9 = tf.Variable(tf.random_normal([10,10]))\n",
    "b9 = tf.Variable(tf.random_normal([10]))\n",
    "# deep & wide\n",
    "L9 = tf.sigmoid(tf.matmul(L8, w9) + b9) # 최종가설함수 \n",
    "\n",
    "w10 = tf.Variable(tf.random_normal([10,1]))\n",
    "b10 = tf.Variable(tf.random_normal([1]))\n",
    "# deep & wide\n",
    "hf = tf.sigmoid(tf.matmul(L9, w10) + b10) # 최종가설함수 \n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x:xdata, y:ydata})# x,y data 필요 \n",
    "        if step % 100 == 0 :\n",
    "            print(step, 'cost:',sess.run(cost, feed_dict={x:xdata, y:ydata})) \n",
    "    hv, pv, av = sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})        \n",
    "    print('hv:', hv, 'pre:', pv, 'acc:', av)\n",
    "#     print('\\nbias:', sess.run(b1), sess.run(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
