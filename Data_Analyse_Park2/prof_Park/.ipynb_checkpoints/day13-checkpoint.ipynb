{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090326/remove-numbers-from-string-that-are-not-inside-quotes\n",
      "Remove numbers from string that are not inside quotes?\n",
      "\n",
      "\n",
      "How to remove numbers from string that are not inside quotes using python re module?\n",
      "For example, string '2 persons goes to watch \"Adam 2\".' should become  'persons goes to watch \"Adam 2\".'\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090309/how-do-i-get-all-the-edges-associated-vertices-and-the-respective-id-label-an\n",
      "How do I get all the edges, associated vertices, and the respective id, label and properties via gremlin-python?\n",
      "\n",
      "\n",
      "I want to fetch all the edges and associated vertices from my AWS Neptune DB. In addition, I want the id, labels and properties for the nodes as well as edges.\n",
      "My data is a stored as a property graph and I'm using gremlin-python to query it.\n",
      "Below is a query which provides the required data when executed in the gremlin shell. However, trying to execute the same using gremlin-python throws an error. \n",
      "g.V().bothE().otherV().limit(2).path().by(__.valueMap(true))\n",
      "Python variant\n",
      "from gremlin_python import statics\n",
      "from gremlin_python.structure.graph import Graph\n",
      "from gremlin_python.process.traversal import T\n",
      "from gremlin_python.process.graph_traversal import __\n",
      "from gremlin_python.process.strategies import *\n",
      "from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection\n",
      "\n",
      "# Define a graph instance\n",
      "graph = Graph()\n",
      "\n",
      "# Connect to the neptune instance\n",
      "try:\n",
      "    remoteConn = DriverRemoteConnection('wss://<YOUR_NEPTUNE_IP>:8182/gremlin', 'g')\n",
      "    g = graph.traversal().withRemote(remoteConn)\n",
      "except:\n",
      "    print(\"Couldn't connect successfully with Neptune instance\")\n",
      "    exit()\n",
      "\n",
      "g.V().bothE().otherV().limit(2).path().by(__.valueMap(True))\n",
      "\n",
      "Error\n",
      "GremlinServerError: 498: {\"requestId\":\"...\",\"code\":\"UnsupportedOperationException\",\"detailedMessage\":\"org.apache.tinkerpop.gremlin.process.traversal.step.util.ImmutablePath cannot be cast to org.apache.tinkerpop.gremlin.structure.Element\"}\n",
      "\n",
      "Can someone provide me a way to get the required information? Be it by successfully converting the above query to Python or via some other query.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090273/python-eof-bof-exception-when-using-getrows-function-from-mdx-query\n",
      "Python - EOF/BOF exception when using GetRows() function (from MDX query)\n",
      "\n",
      "\n",
      "I wrote this code to retrieve data from a cube:\n",
      "rs = win32com.client.Dispatch('ADODB.RecordSet')\n",
      "rs.__init__\n",
      "conn = win32com.client.Dispatch('ADODB.Connection')\n",
      "conn.__init__\n",
      "conn.CommandTimeout=3000\n",
      "conn.Open(connString)\n",
      "\n",
      "\n",
      "#Retrieving data\n",
      "try:\n",
      "    rs.Open(mdxQuery, conn, 1, 3)\n",
      "except Exception as e:\n",
      "    print(\"An error occured while trying to retrieve data:\")\n",
      "    print(str(e))\n",
      "    sys.exit(1)\n",
      "\n",
      "try:\n",
      "    t=rs.GetRows()\n",
      "except Exception as ex:\n",
      "    print(str(ex))\n",
      "\n",
      "it seems the mdx query is ok, and retrieve some result (I can see it from debug mode)\n",
      "but when I try to assign the result of GetRows() function to a variable, it fails, with the following message:\n",
      "\n",
      "ADODB.Field : Either BOF or EOF is True, or the current record has been deleted. Requested operation requires a current record.\n",
      "\n",
      "It seems to me GetRows() function is not able to handle NULL values. Is there a way to tell that method to skip NULL values or just fill it with blanks, and avoid this error?\n",
      "Thanks\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090272/geoalchemy-one-column-for-all-shapely-types\n",
      "GeoAlchemy : one column for all shapely types\n",
      "\n",
      "\n",
      "By now I have this code:\n",
      "\n",
      "value_literal = Column(String())\n",
      "value_point = Column(Geometry('POINT'))\n",
      "value_multipoint = Column(Geometry('MULTIPOINT'))\n",
      "value_line = Column(Geometry('LINESTRING'))\n",
      "value_multiline = Column(Geometry('MULTILINESTRING'))\n",
      "value_polygon = Column(Geometry('POLYGON'))\n",
      "value_multipolygon = Column(Geometry('MULTIPOLYGON'))\n",
      "\n",
      "\n",
      "but I must consider all cases when dealing with an object : indeed, its geometric value can be a point, a line, and so on.\n",
      "It could be great if I would have only one field that would contain either a point, or a line, or a multipoint, et caetera...\n",
      "is it possible?\n",
      "thank you\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090258/random-selenium-errors-egl-driver-message-error\n",
      "Random Selenium errors EGL Driver message (error)\n",
      "\n",
      "\n",
      "I'm getting random error messages from selenium, even though none of them are related to the exact web driver commands I'm running (not that I know of).\n",
      "This error isn't interrupting the program, it's just adding unwanted alerts (making my prints harder to read). \n",
      "Chrome vers: 75.0.3770.100 (Official Build) (64-bit)\n",
      "Python vers: 3.6.1\n",
      "ChromeDriver vers: 75.0.3770.140\n",
      "I've added the following code already but I'm still getting the error.\n",
      "options.add_argument(\"--log-level=3\")\n",
      "\n",
      "gl_surface_egl.cc(544) - EGL Driver message (Error) eglQueryDeviceAttribEXT: Bad attribute.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090238/pycharm-does-not-recognize-pyx-files\n",
      "Pycharm does not recognize .pyx files\n",
      "\n",
      "\n",
      "Pycharm does not recognize few Cython files \n",
      "as can be shown in the picture (with Pycharm red mark under the file name),\n",
      "could you please advice what can i do ?\n",
      "\n",
      "Answer\n",
      "\n",
      "The PyCharm Community Edition does not support Cython. You should get PyCharm Professional Edition to get that feature.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090234/pad-pytorch-tensor-in-text-processing\n",
      "Pad PyTorch tensor in text processing\n",
      "\n",
      "\n",
      "Sorry for my question but I am new in NN and pytorch. I am interested in classify text with a CNN and the code I am using is given below. However when I am running it in another dataset returns the error below in line conved = [F.relu(conv(embedded)) for conv in self.convs] \n",
      "\n",
      "RuntimeError: Calculated padded input size per channel: (1 x 2). Kernel size: (1 x 3). Kernel size can't be greater than actual input size\n",
      "\n",
      "I think that this problem is because the input sentence length is smaller than the kernel size. Could you please suggest an efficient-clever way to avoid this problem?\n",
      "class CNN1d(nn.Module):\n",
      "\n",
      "def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
      "             dropout, pad_idx):\n",
      "\n",
      "    super().__init__()\n",
      "\n",
      "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
      "\n",
      "    self.convs = nn.ModuleList([\n",
      "                                nn.Conv1d(in_channels = embedding_dim, \n",
      "                                          out_channels = n_filters, \n",
      "                                          kernel_size = fs)\n",
      "                                for fs in filter_sizes\n",
      "                                ])\n",
      "\n",
      "    self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
      "\n",
      "    self.dropout = nn.Dropout(dropout)\n",
      "\n",
      "def forward(self, text):\n",
      "\n",
      "    #text = [sent len, batch size]\n",
      "\n",
      "    text = text.permute(1, 0)\n",
      "\n",
      "    #text = [batch size, sent len]\n",
      "\n",
      "    embedded = self.embedding(text)\n",
      "\n",
      "    #embedded = [batch size, sent len, emb dim]\n",
      "\n",
      "    embedded = embedded.permute(0, 2, 1)\n",
      "\n",
      "    #embedded = [batch size, emb dim, sent len]\n",
      "\n",
      "    conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
      "\n",
      "    #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
      "\n",
      "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
      "\n",
      "    #pooled_n = [batch size, n_filters]\n",
      "\n",
      "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
      "\n",
      "    #cat = [batch size, n_filters * len(filter_sizes)]\n",
      "\n",
      "    return self.fc(cat)\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090227/syntaxerror-when-using-exec-in-sage\n",
      "SyntaxError when using exec() in sage\n",
      "\n",
      "\n",
      "I'm in need of creating a BooleanPolynomialRing in sage with variables generated dynamically. I generate list of variables into string vector then generate one big string with all of them (ex. 'z_0, z_1, z_2, ..'). Then I want to use exec to generate the ring itself.\n",
      "variables =\"B.\\<\"\n",
      "for i in [0..len(varlist)-2]:\n",
      "    variables+=varlist[i]\n",
      "    variables+=\", \"\n",
      "variables +=varlist[len(varlist)-1]    \n",
      "variables +=\">=BooleanPolynomialRing()\"\n",
      "\n",
      "exec(variables)\n",
      "\n",
      "#to effectively execute B.<variables_from_list>=BooleanPolynomialRing()\n",
      "\n",
      "Unfortunately all I get is:\n",
      "SyntaxError: unexpected character after line continuation character\n",
      "Also, can anyone explain why '\\' has to be used before '<' ? It doesn't work otherwise with: \n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090219/how-to-convert-the-number-of-matrix-to-fraction-not-decimal\n",
      "How to convert the number of matrix to fraction not decimal? [duplicate]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This question already has an answer here:\n",
      "\n",
      "\n",
      "How to use numpy arrays with fractions?\n",
      "\n",
      "                    2 answers\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "I have one matrix in python:\n",
      "aa = np.array([[1, -2], [1, 1]])\n",
      "\n",
      "Then, I want to compute the inverse of this matrix aa:\n",
      "bb = inv(aa)\n",
      "Finally, I got the result:\n",
      "print(\"bb: \", bb)\n",
      "array([[ 0.33333333,  0.66666667], [-0.33333333,  0.33333333]]))\n",
      "\n",
      "But I want to print the results in fraction format, not decimal/float:\n",
      "array([[ 1/3,  2/3], [-1/3,  1/3]]))\n",
      "\n",
      "How can I get this print result by python?\n",
      "array([[ 1/3,  2/3], [-1/3,  1/3]]))\n",
      "\n",
      "Answer\n",
      "\n",
      "you could use sympy:\n",
      "from sympy import Matrix\n",
      "\n",
      "aa = Matrix([[1, -2], [1, 1]])\n",
      "bb = aa.inv()\n",
      "print(bb)  # Matrix([[1/3, 2/3], [-1/3, 1/3]])\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090203/how-to-make-sublimes-python-interpreter-work-when-sublimes-on-windows-and-pyth\n",
      "How to make Sublime's python interpreter work when Sublime's on Windows and Python is on Ubuntu\n",
      "\n",
      "\n",
      "I am running Ubuntu on Windows (I can't change it). I use Sublime Test 3 as my code editor. I have Python installed on Ubuntu and I know the path to it from within Windows. Sublime's Python interpreter is not working when I run it. I would like to be able to do both of the following:\n",
      "a) Run basic Python commands in Sublime Text 3 on Windows using Python installed in Ubuntu folders\n",
      "b) Run Python modules in Sublime Text 3 on Windows using modules installed in Ubuntu folders\n",
      "I have already tried adding the path to Python's Ubuntu folders to the PATH environment variable (for user, not for system). I didn't work. \n",
      "Then I installed Anaconda Python distribution on Windows, and added its path to the PATH variable (for user again). It did work. However, it means having to maintain two Pythons - one on Windows and one on Ubuntu, which defeats the purpose of my search. Also, I only managed to make it work for basic Python, and not for libraries. Adding PYTHONPATH variable with the path to Anaconda's modules on Windows broke the import of numpy and other libraries.\n",
      "Just to clarify, I do not use Anaconda distribution, I was just trying all I could.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090194/downsampling-an-audio-file-python\n",
      "Downsampling an audio file python\n",
      "\n",
      "\n",
      "I want to create a model which can detect if there is a glitch in an audio file. I read about audio pre processing and found that downsampling can help in reducing the size and its a necessary step for pre processing.\n",
      "I have used librosa.load and changed the sample rate to 8Khz from 44.1Khz of the original audio file. I have also read that downsampling can cause issues as we might tend to lose the data. Is there a way to keep the actual data (interpolation, aliasing ) without any issues and feel that as input to my model. Since I am training this model the data needs to be as close to perfection. I have already tried librosa.resample() but not sure if my data is being handled or not.\n",
      "I am looking for some python code for the same. Or if I am missing something here let me know. Basically I want my model to run faster as it takes too much time to just load the data. And if there are any otehr pre processing techniques let me know.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090189/use-runas-to-connect-to-odbc\n",
      "Use RUNAS to connect to odbc?\n",
      "\n",
      "\n",
      "I am trying to connect to a database using pyodbc. I can connect using ODBC Data Source using the runas command but I cannot seem to execute a python script the same.\n",
      "Examples:\n",
      "# this works\n",
      "runas /netonly /user:domain\\username \"C:\\Windows\\System32\\odbcad32.exe\"\n",
      "\n",
      "# this does not\n",
      "runas /netonly /user:domain\\username \"C:\\path\\to\\python.exe C:\\path\\to\\script.py\"\n",
      "\n",
      "Trying to execute python script a window opens and closes very quickly.\n",
      "inside the script is an infinite print to sure script is being execute.\n",
      "#script.py\n",
      "import time\n",
      "\n",
      "while True:\n",
      "   print(\"running\")\n",
      "   time.sleep(5)\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090174/the-qlabel-can-not-trigger-the-mouse-release-event\n",
      "the qlabel can not trigger the mouse release event\n",
      "\n",
      "\n",
      "I have a parent QLabel, and create a child QLabel to show some text. When I click on the child QLabel, the mousePressEvent on parent QLabel is OK but the mouseReleaseEvent can not be trigger. \n",
      "The code is:\n",
      "import sys\n",
      "from PyQt5.QtWidgets import *\n",
      "from PyQt5.QtGui import *\n",
      "from PyQt5.QtCore import *\n",
      "\n",
      "class MyLabel(QLabel):\n",
      "\n",
      "    def __init__(self):\n",
      "        super(MyLabel, self).__init__()\n",
      "        self.label = QLabel('hello<br/> world', self)\n",
      "        self.label.adjustSize()\n",
      "        self.label.setStyleSheet(\n",
      "            \"background-color: {};\".format(QColor(255, 0, 0).name())\n",
      "        )\n",
      "        self.label.move(QPoint(50, 50))\n",
      "        self.label.setFrameShape(QFrame.NoFrame)\n",
      "\n",
      "    def mousePressEvent(self, QMouseEvent):\n",
      "        super(MyLabel, self).mousePressEvent(QMouseEvent)\n",
      "        print('press')\n",
      "\n",
      "    def mouseReleaseEvent(self, QMouseEvent):\n",
      "        super(MyLabel, self).mouseReleaseEvent(QMouseEvent)\n",
      "        print('release')\n",
      "\n",
      "class Window(QLabel):\n",
      "    def __init__(self):\n",
      "        super(Window, self).__init__()\n",
      "        self.layout = QVBoxLayout()\n",
      "        self.setLayout(self.layout)\n",
      "        self.label = MyLabel()\n",
      "        self.label.setFrameShape(QFrame.Box)\n",
      "        self.label.setStyleSheet(\"border-width: 2px;border-style: solid;border-color: rgb(0, 255, 0);\")\n",
      "        self.layout.addWidget(self.label)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    app = QApplication(sys.argv)\n",
      "    window = Window()\n",
      "    window.resize(640, 480)\n",
      "    window.show()\n",
      "    sys.exit(app.exec_())\n",
      "\n",
      "I find the reason is the text in the child QLabel. If I show the text as 'hello world' rather than 'hello<.br/> world', the mouse release signal is OK when I click on the 'hello world' QLabel. So, if I need to show 'hello <.br/> world', how to fixed this bug?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090158/python-dictionary-to-numpy-conversion\n",
      "Python dictionary to NumPy conversion\n",
      "\n",
      "\n",
      "I am converting a Python dictionary to NumPy array.\n",
      "import numpy as np\n",
      "\n",
      "myDict = {\n",
      "        1: \"AAA\",\n",
      "        2: \"BBB\",\n",
      "        3: \"CCC\",\n",
      "        4: \"AAA\",\n",
      "        5: \"BBB\"\n",
      "        }\n",
      "\n",
      "myNumPyArray = np.asarray(myDict, dtype=dict, order=\"C\")\n",
      "\n",
      "print(myNumPyArray) \n",
      "\n",
      "Output\n",
      "{1: 'AAA', 2: 'BBB', 3: 'CCC', 4: 'AAA', 5: 'BBB'}\n",
      "\n",
      "Why is it showing the dictionary in the output?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090134/get-data-from-model-in-view\n",
      "get data from model in view\n",
      "\n",
      "\n",
      "I have two tables\n",
      "  Category and book\n",
      "My Category table with the book table has one-to- many links,that's mean  one category can have several books\n",
      "Now I want to display 6 books from each category on my homepage\n",
      "How should I get the information?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090108/convert-python-dictionary-keys-following-a-key-to-key-mapping\n",
      "Convert Python dictionary keys following a key-to-key mapping\n",
      "\n",
      "\n",
      "I am in need of a function used to convert the keys of a Python dict to something else, according to a keys mapping. So for example let's say I have the mapping:\n",
      "{\n",
      "    \"olk_key_1\": \"new_key_1\",\n",
      "    \"olk_key_2\": \"new_key_2\",\n",
      "    \"olk_key_3\": \"new_key_3\",\n",
      "}\n",
      "\n",
      "And the dict:\n",
      "{\n",
      "    \"old_key_1\": 1,\n",
      "    \"old_key_2\": 2,\n",
      "    \"old_key_3\": 3,\n",
      "}\n",
      "\n",
      "What I want is:\n",
      "{\n",
      "    \"new_key_1\": 1,\n",
      "    \"new_key_2\": 2,\n",
      "    \"new_key_3\": 3,\n",
      "}\n",
      "\n",
      "The tricky part about this is that the functions MUST SUPPORT ANY SORT OF NESTED STRUCTURE.  \n",
      "That includes:\n",
      "\n",
      "dicts of dicts\n",
      "dicts of lists\n",
      "lists of dicts\n",
      "\n",
      "I currently have an ugly working function. Anything better looking (feel free to just refactor my code) will be considered as an answer.\n",
      "def map_keys(self, data, mapping):\n",
      "    \"\"\"\n",
      "    This function converts the data dictionary into another one with different keys, as specified by the mapping\n",
      "    parameter\n",
      "    :param data: The dictionary to be modified\n",
      "    :param mapping: The key mapping\n",
      "    :return: A new dictionary with different keys\n",
      "    \"\"\"\n",
      "    new_data = data.copy()\n",
      "    if isinstance(new_data, list):\n",
      "        new_data = {\"tmp_key\": new_data}\n",
      "        mapping.update({\"tmp_key\": \"key_tmp\"})\n",
      "    iterate = list(new_data.items())\n",
      "    for key, value in iterate:\n",
      "        if isinstance(value, list) and isinstance(value[0], dict):\n",
      "            new_list = []\n",
      "            for item in new_data[key]:\n",
      "                new_list.append(self.map_keys(item, mapping))\n",
      "            new_data[mapping[key]] = new_list\n",
      "        else:\n",
      "            new_data[mapping[key]] = value\n",
      "        new_data.pop(key)\n",
      "    if \"key_tmp\" in new_data:\n",
      "        new_data = new_data[\"key_tmp\"]\n",
      "    return new_data\n",
      "\n",
      "Answer\n",
      "\n",
      "Am not sure if this helps with other type of nested structure, but i'll provide what i can think of\n",
      "dict1= {\n",
      "    \"olk_key_1\": \"new_key_1\",\n",
      "    \"olk_key_2\": \"new_key_2\",\n",
      "    \"olk_key_3\": \"new_key_3\",\n",
      "}\n",
      "dict2 = {\n",
      "    \"old_key_1\": 1,\n",
      "    \"old_key_2\": 2,\n",
      "    \"old_key_3\": 3,\n",
      "}\n",
      "newDict = {}\n",
      "dict1Keys = []\n",
      "for i in dict1:\n",
      "    dict1Keys.append(dict1[i])\n",
      "\n",
      "dict2Values = []\n",
      "for i in dict2:\n",
      "    dict2Values.append(dict2[i])\n",
      "\n",
      "for i in range(len(dict1Keys)):\n",
      "    newDict[dict1Keys[i]] = dict2Values[i]\n",
      "print(newDict)\n",
      "Output:\n",
      ">>>{'new_key_1': 1, 'new_key_2': 2, 'new_key_3': 3}\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090080/attributeerror-runcmd-object-has-no-attribute-p-python-subprocess\n",
      "AttributeError: 'RunCmd' object has no attribute 'p', Python subprocess\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python program produces this error\n",
      "File \".\\check_test.py\", line 57, in Run\n",
      "    self.p.terminate()\n",
      "AttributeError: 'RunCmd' object has no attribute 'p'\n",
      "\n",
      "Python Code:\n",
      "First, I call the subprocess\n",
      "subprocess.call([\"g++\", \"test.cpp\"])\n",
      "problem = RunCmd([\"./a.exe\"], TimeLimit).Run()\n",
      "\n",
      "RunCmd:\n",
      "class RunCmd(Thread):\n",
      "    def __init__(self, cmd, timeout):\n",
      "        Thread.__init__(self)\n",
      "        self.cmd = cmd\n",
      "        self.timeout = timeout\n",
      "\n",
      "    def run(self):\n",
      "        #self.p is set to None, why does the subprocess fail? (self.cmd is executed and i obtain the result expected by subprocess)\n",
      "        self.p = subprocess.Popen(self.cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True)\n",
      "\n",
      "        if self.p.stderr is None:\n",
      "            self.p.stdout = (self.p.stdout.read()).decode(\"utf-8\")\n",
      "            self.p.return_code = self.p.returncode\n",
      "        else:\n",
      "            self.p.stdout = None\n",
      "            self.p.stderr = self.p.stderr.decode(\"utf-8\")\n",
      "\n",
      "        print(self.p.poll())   #return None\n",
      "        self.p.wait()\n",
      "\n",
      "    def Run(self):\n",
      "        self.start()\n",
      "        self.join(self.timeout)\n",
      "\n",
      "        if self.is_alive():\n",
      "            self.p.terminate() #self here has no attribute 'p'\n",
      "            self.join()\n",
      "            return True\n",
      "\n",
      "\n",
      "Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \".\\check_test.py\", line 134, in <module>\n",
      "    problem = RunCmd([\"./a.exe\"], TimeLimit).Run()\n",
      "  File \".\\check_test.py\", line 57, in Run\n",
      "    self.p.terminate()\n",
      "AttributeError: 'RunCmd' object has no attribute 'p'\n",
      "None\n",
      "\n",
      "What is wrong exactly?\n",
      "\n",
      "Answer\n",
      "\n",
      "I think you're mixing .run() and .Run(). You're running the latter, while the former is the one setting p - and I don't see where you're calling .run().\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090078/tkinter-centre-all-widgets-in-window\n",
      "Tkinter centre all widgets in window\n",
      "\n",
      "\n",
      "I am building a GUI with tkinter using grid. I need to centre all my objects in the centre of the window. All questions and buttons are different lengths so for the shorter ones that don't take up the whole window I want them to be central on the x axis.\n",
      "I've looked into the issue and found a somewhat solution using place however I would have to rewrite the whole app as it is currently using grid.\n",
      "def createWidgets(self):\n",
      "\n",
      "        self.question = tk.Label(self, text=\"What is Prague the capital of?\\n\")\n",
      "        self.question.grid(row=1, column=1, columnspan=2)\n",
      "\n",
      "        self.option1 = tk.Button(self, width=12)\n",
      "        self.option1[\"text\"] = \"Romania\"\n",
      "        self.option1[\"command\"] = self.wrong1\n",
      "        self.option1.grid(column=1, row=2, padx=1, pady=1)\n",
      "\n",
      "        self.option2 = tk.Button(self, width=12)\n",
      "        self.option2[\"text\"] = \"Slovakia\"\n",
      "        self.option2[\"command\"] = self.wrong1\n",
      "        self.option2.grid(column=2, row=2, padx=1, pady=1)\n",
      "\n",
      "        self.option3 = tk.Button(self, width=12)\n",
      "        self.option3[\"text\"] = \"Czech Republic\"\n",
      "        self.option3[\"command\"] = self.correct1\n",
      "        self.option3.grid(column=1, row=3, padx=1, pady=1)\n",
      "\n",
      "        self.option4 = tk.Button(self, width=12)\n",
      "        self.option4[\"text\"] = \"Ukraine\"\n",
      "        self.option4[\"command\"] = self.wrong1\n",
      "        self.option4.grid(column=2, row=3, padx=1, pady=1)\n",
      "\n",
      "I want to centre everything inside of createWidgets so that it always starts at the top of the y axis but in the middle of the x axis.\n",
      "I use root.geometry(\"250x160\") to size the window right now and\n",
      "root.resizable(0, 0) to stop variables resizing it.\n",
      "\n",
      "Answer\n",
      "\n",
      "the pack geometry manager will center all your widgets in a column that will look like this:\n",
      "\n",
      "import tkinter as tk\n",
      "\n",
      "\n",
      "class MVCE(tk.Tk):\n",
      "\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.create_widgets()\n",
      "        self.mainloop()\n",
      "\n",
      "    def create_widgets(self):\n",
      "\n",
      "        self.question = tk.Label(self, text=\"What is Prague the capital of?\\n\")\n",
      "        self.question.pack()\n",
      "\n",
      "        self.option1 = tk.Button(self, width=12)\n",
      "        self.option1[\"text\"] = \"Romania\"\n",
      "        self.option1[\"command\"] = self.wrong1\n",
      "        self.option1.pack()\n",
      "\n",
      "        self.option2 = tk.Button(self, width=12)\n",
      "        self.option2[\"text\"] = \"Slovakia\"\n",
      "        self.option2[\"command\"] = self.wrong1\n",
      "        self.option2.pack()\n",
      "\n",
      "        self.option3 = tk.Button(self, width=12)\n",
      "        self.option3[\"text\"] = \"Czech Republic\"\n",
      "        self.option3[\"command\"] = self.correct1\n",
      "        self.option3.pack()\n",
      "\n",
      "        self.option4 = tk.Button(self, width=12)\n",
      "        self.option4[\"text\"] = \"Ukraine\"\n",
      "        self.option4[\"command\"] = self.wrong1\n",
      "        self.option4.pack()\n",
      "\n",
      "    def wrong1(self):\n",
      "        print('wrong1')\n",
      "\n",
      "    def correct1(self):\n",
      "        print('correct1')\n",
      "\n",
      "MVCE()\n",
      "I assume your class inherits from tk.Frame. You don't have to modify anything inside the class - rather, change how you pack your frame by passing fill and expand. \n",
      "import tkinter as tk\n",
      "\n",
      "class MainFrame(tk.Frame):\n",
      "    def __init__(self,master=None,**kwargs):\n",
      "        tk.Frame.__init__(self,master,**kwargs)\n",
      "        self.question = tk.Label(self, text=\"What is Prague the capital of?\\n\")\n",
      "        self.question.grid(row=1, column=1, columnspan=2)\n",
      "\n",
      "        self.option1 = tk.Button(self, width=12)\n",
      "        self.option1[\"text\"] = \"Romania\"\n",
      "        #self.option1[\"command\"] = self.wrong1\n",
      "        self.option1.grid(column=1, row=2, padx=1, pady=1)\n",
      "\n",
      "        self.option2 = tk.Button(self, width=12)\n",
      "        self.option2[\"text\"] = \"Slovakia\"\n",
      "        #self.option2[\"command\"] = self.wrong1\n",
      "        self.option2.grid(column=2, row=2, padx=1, pady=1)\n",
      "\n",
      "        self.option3 = tk.Button(self, width=12)\n",
      "        self.option3[\"text\"] = \"Czech Republic\"\n",
      "        #self.option3[\"command\"] = self.correct1\n",
      "        self.option3.grid(column=1, row=3, padx=1, pady=1)\n",
      "\n",
      "        self.option4 = tk.Button(self, width=12)\n",
      "        self.option4[\"text\"] = \"Ukraine\"\n",
      "        #self.option4[\"command\"] = self.wrong1\n",
      "        self.option4.grid(column=2, row=3, padx=1, pady=1)\n",
      "\n",
      "root = tk.Tk()\n",
      "frame = MainFrame(root)\n",
      "frame.pack(fill=tk.Y,expand=True)\n",
      "root.mainloop()\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090076/cumulative-product-for-a-python-list\n",
      "Cumulative product for a python list\n",
      "\n",
      "\n",
      "I have the following list:\n",
      "l = [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "I want to multiply the first element by 9, (1*9)=9 and then all successive items by the result of the previous multiplication. See the following output:\n",
      "[9, 18, 54, 216, 1080, 6480]\n",
      "\n",
      "Could you help on how to code this please?\n",
      "\n",
      "Answer\n",
      "\n",
      "You could update the first item in the list, and use  itertools.accumulate with operator.mul to take the cumulative product of its values:\n",
      "from operator import mul\n",
      "from itertools import accumulate\n",
      "\n",
      "l = [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "l[0]*=9\n",
      "list(accumulate(l, mul))\n",
      "# [9, 18, 54, 216, 1080, 6480]\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090046/how-to-convert-doy-day-of-year-to-months-as-text-in-a-plot\n",
      "How to convert DOY (Day of year) to months (as text) in a plot?\n",
      "\n",
      "\n",
      "I have plots of climate time series for daily mean temperature, precipitation and global radiation.\n",
      "I generated plots like this:\n",
      "https://i.ibb.co/w4x2FMN/temp-mean-1999-2018.png\n",
      "On x-axis I just generated list of the numbers 1 - 365 which represent the day of year (DOY).\n",
      "What I actually want is, that the x-axis is devided in month names (as strings) like this:\n",
      "https://i.ibb.co/cL2zc87/rplot.jpg\n",
      "I tried already a lot of different things but nothing worked.\n",
      "fig = plt.figure(figsize=(10,10))\n",
      "ax = plt.axes()\n",
      "\n",
      "x = np.arange(1,366) # here I define the List with DOY\n",
      "ax.fill_between(x, temp_cum['min'], temp_cum['max'], color='lightgray', label='1999-2017')\n",
      "#ax.plot(x, merge_table_99_17_without, color='grey', linewidth=0.3)\n",
      "ax.plot(x, temp_cum['2018'], color='black', label='2018');\n",
      "ax.legend(loc='upper left')\n",
      "\n",
      "ax.set_ylabel('daily mean temperature [°C]')\n",
      "#ax.set_xlabel('DOY')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090036/how-to-create-a-dynamic-dropdownlist-from-a-model-field-that-is-declared-as-char\n",
      "How to create a dynamic dropdownlist from a model field that is declared as CharField not a Foriegn key in django\n",
      "\n",
      "\n",
      "I want to create a dynamic SelectBox from model(for eg: list of Author details, that is neither a foriegn key nor manytomany field)\n",
      "Author = models.CharField('Author', max_length=100, blank=True, null=True, help_text='Enter Author')\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090028/recursive-transpose-of-dataframe\n",
      "Recursive Transpose of Dataframe\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  \n",
      "|Name|L1|L1 Desc|L2|L2 Desc|L3|L3 Desc|L4|L4 Desc|\n",
      "|Name1|L1|L1 Desc|L2|L2 Desc|L3|L3 Desc|L4|L4 Desc|\n",
      "|Name2|L1|L1 Desc|L2|L2 Desc|L3|L3 Desc|L4|L4 Desc|\n",
      "\n",
      "I want to get:\n",
      "|Name|Levels|Level Desc|\n",
      "|Name1|L1|L1 Desc|\n",
      "|Name1|L2|L2 Desc|\n",
      "|Name1|L3|L3 Desc|\n",
      "|Name1|L4|L4 Desc|\n",
      "|Name2|L1|L1 Desc|\n",
      "|Name2|L2|L2 Desc|\n",
      "|Name2|L3|L3 Desc|\n",
      "|Name2|L4|L4 Desc|    \n",
      "\n",
      "etc\n",
      "However, it should also expand to fit multiple Descs as per some manual input criteria (like a function parameter), for example:\n",
      "|Name|L1|L1 Desc|L1 Kid|L2|L2 Desc|L2 Kid|L3|L3 Desc|L3 Kid|L4|L4 Desc|L4 Kid|\n",
      "|Name1|L1|L1 Desc|L1 Kid|L2|L2 Desc|L2 Kid|L3|L3 Desc|L3 Kid|L4|L4 Desc|L4 Kid|\n",
      "|Name2|L1|L1 Desc|L1 Kid|L2|L2 Desc|L2 Kid|L3|L3 Desc|L3 Kid|L4|L4 Desc|L4 Kid|\n",
      "\n",
      "so that it becomes\n",
      "|Name|Levels|Level Desc|Level Kid|\n",
      "|Name1|L1|L1 Desc|L1 Kid|\n",
      "|Name1|L2|L2 Desc|L2 Kid|\n",
      "|Name1|L3|L3 Desc|L3 Kid|\n",
      "|Name1|L4|L4 Desc|L4 Kid|\n",
      "|Name2|L1|L1 Desc|L1 Kid|\n",
      "|Name2|L2|L2 Desc|L2 Kid|\n",
      "|Name2|L3|L3 Desc|L3 Kid|\n",
      "|Name2|L4|L4 Desc|L4 Kid|\n",
      "\n",
      "etc\n",
      "Typically I would use pd.melt to do this, but in this case, it does not fulfill what I require.\n",
      "Is there a pandas function for me to do this, where I can state the level of cuts I wish to take (Modulo 2 or Modulo 3 for example or outline the fields I want to keep and the column fields to fall into them)\n",
      "Or I will have to do this via recursively modified pd.melt in a custom function?\n",
      "Note: I do not know the column names in advance. I will only know by how many (every 2/3/4/5/6/etc Levels) I have to split by\n",
      "Thanks\n",
      "\n",
      "Answer\n",
      "\n",
      "First convert first columns to index for only repeating columns, then grouping by modulo, set default columns names by range and concat together, last set columns names by first group for general solution:\n",
      "n = 3\n",
      "df = df.set_index('Name')\n",
      "df1 = pd.concat([g.set_axis(range(len(g.columns)), axis=1, inplace=False) \n",
      "        for i, g in df.groupby(np.arange(len(df.columns)) // n , axis=1)], ignore_index=False)\n",
      "df1.columns = df.columns[:n]\n",
      "df1 = df1.reset_index()\n",
      "print (df1)\n",
      "    Name  L1  L1 Desc  L1 Kid\n",
      "0  Name1  L1  L1 Desc  L1 Kid\n",
      "1  Name2  L1  L1 Desc  L1 Kid\n",
      "2  Name1  L2  L2 Desc  L2 Kid\n",
      "3  Name2  L2  L2 Desc  L2 Kid\n",
      "4  Name1  L3  L3 Desc  L3 Kid\n",
      "5  Name2  L3  L3 Desc  L3 Kid\n",
      "6  Name1  L4  L4 Desc  L4 Kid\n",
      "7  Name2  L4  L4 Desc  L4 Kid\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090027/regex-findall-output-not-as-expected\n",
      "Regex findall output not as expected\n",
      "\n",
      "\n",
      "Tried Regex to extract parts of text which is read from a .txt file. However my method seems to fail some specific lines.\n",
      "Below are 3 lines from input text\n",
      "[2019/07/11 18:52:25.391] Receive : <- AI (Req No. 711185105702666 ) Message from : cop10\n",
      "\n",
      "[2019/07/11 18:52:25.391] Note    : Response that is not being sent ... cop10\n",
      "\n",
      "[2019/07/11 18:52:25.393] ★Err    : subargs[0] : IBSDK_7776\n",
      "\n",
      "below is code to extract some portion of text after the time stamp.\n",
      "regex = r\"\\[.{23}] ?(.{1,8}:.{1,12}).*\\n\"\n",
      "pattern = re.compile(regex)\n",
      "for line in input_text: \n",
      "    matches = pattern.findall(line)\n",
      "    print('matches is {}'.format(matches))\n",
      "\n",
      "\"For lines 1 and 2 in the input text, the output is as expected i.e a list of extracted text.\"\n",
      "Shown below is the output for line 1\n",
      "\"matches is ['Receive : <- AI (Req ']\"\n",
      "\"For the last line the list is empty i.e [ ]\"\n",
      "\"My expectation was ['★Err    : subargs[0]'] or list of some text.\"\n",
      "I suspect it could be due to the black star in the text as those are places where the code snippet fails,but am not fully sure why it happens.\n",
      "Would be great if I can get some input on this and if I need to make changes to my Regex.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090026/how-to-draw-rectangle-in-detection-part-using-opencv-in-python\n",
      "how to draw rectangle in detection part using openCv in python?\n",
      "\n",
      "\n",
      "hello folks ,\n",
      "I created a model which is classifying normal_car Vs cop_car\n",
      "If i pass images to model it gives a proper output \n",
      "but when image is having lots of objects , how to draw rectangle on\n",
      "  both of these (label -: normal_Car , police_Car)\n",
      "I can draw rectangle in image on every objects (but without using a model) \n",
      "how to do that??\n",
      "thanks in advanced\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57090020/how-do-i-efficiently-convert-pandas-dataframe-to-image-array\n",
      "How do I efficiently convert pandas dataframe to image array?\n",
      "\n",
      "\n",
      "I have a big pandas dataframe with columns X,Y, and I. X and Y are pixel coordinates, I is, let's say, an intensity value between 0 and 255 which I want to be shown at the corresponding X and Y position.\n",
      "There is not an entry for each pixel of the image, so all pixels' I values that are not listed in the dataframe are set to 0.\n",
      "Therefore, I initialized an two-dimensional array img with the image dimensions. Then, I already tried something like\n",
      "img.at[df.X,df.Y] = df.I\n",
      "\n",
      "which does not work. I think a simple for-loop can solve this problem, but I wonder if there is a more efficient way to do this (e.g. call a fancy numpy/opencv/whatever function I don't know...).\n",
      "\n",
      "Answer\n",
      "\n",
      "You should use the pivot function of Pandas like this:\n",
      "df.pivot('Y', 'X', 'I').values\n",
      "\n",
      "which will result in something like this:\n",
      "# array([[ 255,  34],\n",
      "#       [  56,  nan]])\n",
      "\n",
      "Then you simply need to replace the nan value with 0.\n",
      "Easiest way is probably to use scipy.sparse arrays, as coo_matrix is built identically to your inputs.\n",
      "from scipy.sparse import coo_matrix\n",
      "\n",
      "sparse_image = coo_matrix((df.I, (df.X, df.Y)), shape = image.shape)\n",
      "image = sparse_image.todense()\n",
      "\n",
      "coo_matrix also has some nice functionalities if your I values are being accumulated before this step.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089993/python-filter-by-results-pagination\n",
      "Python Filter by results pagination\n",
      "\n",
      "\n",
      "I filter my results from db by username phrase. For this I am using this get request:\n",
      "class UserFilter(Resource):\n",
      "def get(self):\n",
      "    parser = reqparse.RequestParser()\n",
      "    parser.add_argument('username', help='This field cannot be blank', required=True)\n",
      "    data = parser.parse_args()\n",
      "    current_users = UserModel.serialize_list(UserModel.query.filter(UserModel.username.like('%' + data['username'] + '%')).all())\n",
      "\n",
      "    return current_users\n",
      "\n",
      "This get returns me all users with phrase in username.\n",
      "{\n",
      "    \"id\": 1,\n",
      "    \"username\": \"test\",\n",
      "},\n",
      "{\n",
      "    \"id\": 2,\n",
      "    \"username\": \"test1\",\n",
      "},\n",
      "{\n",
      "    \"id\": 8,\n",
      "    \"username\": \"Testowe\",\n",
      "},\n",
      "\n",
      "My problem is to get this list paginated. I mean, to get results, url to next results, and url to previous results. How I can make it?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089928/the-view-didnt-return-an-httpresponse-object-it-returned-none-instead\n",
      "“The view didn't return an HttpResponse object. It returned None instead.”\n",
      "\n",
      "\n",
      "\"The view didn't return an HttpResponse object. It returned None instead.\"\n",
      "\"i am working on exam-app using python django ,but getting error in loginview function while running on localhost,how do i solve this?\"\n",
      "in views.py this the following loginview class where it's showingerror\n",
      "class LoginView(FormView):\n",
      "    form_class = AuthenticationForm\n",
      "    template_name = 'exam/login.html'\n",
      "    def form_valid(self, form):\n",
      "    username = form.cleaned_data['username']\n",
      "    password = form.cleaned_data['password']\n",
      "    user = authenticate(username  = username, password = password)\n",
      "    if user is not None and user.is_active:\n",
      "        login(self.request, user)\n",
      "        if user.role == 2:\n",
      "            return redirect(\"student\")\n",
      "        elif user.role == 3:\n",
      "            return redirect(\"index\")\n",
      "    else:\n",
      "        return self.form_invalid(form)`\n",
      "\n",
      "error showing is:\n",
      "    ValueError at /login/\n",
      "The view exam.views.LoginView didn't return an HttpResponse \n",
      "object. It returned None instead.\n",
      "\n",
      "user role is set ,please refer to attached file\n",
      "class User(AbstractBaseUser, PermissionsMixin):\n",
      "SUPER_ADMIN = 1\n",
      "STUDENT = 2\n",
      "TEACHER = 3\n",
      "ROLE_CHOICES = (\n",
      "    (STUDENT, 'Student'),\n",
      "    (SUPER_ADMIN, 'Super Admin'),\n",
      "    (TEACHER , 'Teacher'),\n",
      ")\n",
      "first_name = models.CharField(max_length = 100, null = False)\n",
      "last_name = models.CharField(max_length = 100, null = False)\n",
      "email = models.EmailField(null=False, unique=True)\n",
      "is_active = models.BooleanField(default=True)\n",
      "created_on = models.DateTimeField(auto_now_add=True)\n",
      "updated_on = models.DateTimeField(auto_now=True)\n",
      "is_staff = models.BooleanField(default=False)\n",
      "role = models.SmallIntegerField(choices = ROLE_CHOICES, null = True)\n",
      "objects = UserManager()\n",
      "USERNAME_FIELD = 'email'\n",
      "def get_full_name(self):\n",
      "    return self.first_name + \" \" + self.last_name\n",
      "def get_short_name(self):\n",
      "    return self.first_name\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089926/python-file-upload-takes-date-as-none-when-opening-a-csv-file-with-excel\n",
      "Python file upload takes date as 'None' when opening a .csv file with excel\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I made a function to upload .csv files which has the following headers,\n",
      "\n",
      "name,pid,quantity,length,width,height,volume,weight,ETA,truck_type,origin,destination\n",
      "\n",
      "I have created a custom file upload 'reader' function for it:\n",
      "def upload_batch (request):\n",
      "    template_name = 'classroom/teachers/upload.html'\n",
      "    prompt = {\n",
      "        'order': 'Order should be as follows: name,pid,quantity,length,width,height,volume,weight,truck_type,origin,destination'}\n",
      "    if request.method == \"GET\":\n",
      "        return render(request, template_name, prompt)\n",
      "\n",
      "    csv_file = request.FILES['file']\n",
      "    data_set = csv_file.read().decode('UTF-8')\n",
      "    io_string = io.StringIO(data_set)\n",
      "    next(io_string)\n",
      "\n",
      "    uploaded_by = request.user\n",
      "\n",
      "    for column in csv.reader(io_string, delimiter=',', quotechar='|'):\n",
      "        _, created = ItemBatch.objects.custom_update_or_create(name=column[0], pid=column[1], quantity=column[2],\n",
      "                                                               length=column[3], width=column[4], height=column[5],\n",
      "                                                               volume=column[6], weight=column[7], truck_type=column[9],\n",
      "                                                               date=column[8], origin=column[10],\n",
      "                                                               destination=column[11], uploaded_by=uploaded_by)\n",
      "\n",
      "\n",
      "    context = {}\n",
      "    return redirect('teachers:upload_batch')\n",
      "\n",
      "This is my custom-manager function:\n",
      "class CustomManager(models.Manager):\n",
      "    def custom_update_or_create (self, *args, **kwargs):\n",
      "        date_time_value = kwargs.pop('date', None)\n",
      "        if date_time_value:\n",
      "            kwargs['date'] = self.get_date_value(date_time_value)\n",
      "        return super(CustomManager, self).update_or_create(*args, **kwargs)\n",
      "\n",
      "\n",
      "    def get_date_value (self, value):\n",
      "        FORMATS = ['%d-%m-%Y %H:%M:%S', '%d-%Y-%m %H:%M:%S', '%m-%d-%Y %H:%M:%S', '%m-%Y-%d %H:%M:%S',\n",
      "            '%Y-%m-%d %H:%M:%S', '%Y-%d-%m %H:%M:%S', '%d/%m/%Y %H:%M:%S', '%d/%Y/%m %H:%M:%S', '%m/%d/%Y %H:%M:%S',\n",
      "            '%m/%Y/%d %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%Y/%d/%m %H:%M:%S',\n",
      "\n",
      "            '%d-%m-%Y %H:%M', '%d-%Y-%m %H:%M', '%m-%d-%Y %H:%M', '%m-%Y-%d %H:%M', '%Y-%m-%d %H:%M', '%Y-%d-%m %H:%M',\n",
      "            '%d/%m/%Y %H:%M', '%d/%Y/%m %H:%M', '%m/%d/%Y %H:%M', '%m/%Y/%d %H:%M', '%Y/%m/%d %H:%M', '%Y/%d/%m %H:%M',\n",
      "\n",
      "            '%d-%m-%Y %H:%M:%S %p', '%d-%Y-%m %H:%M:%S %p', '%m-%d-%Y %H:%M:%S %p', '%m-%Y-%d %H:%M:%S %p',\n",
      "            '%Y-%m-%d %H:%M:%S %p', '%Y-%d-%m %H:%M:%S %p', '%d/%m/%Y %H:%M:%S %p', '%d/%Y/%m %H:%M:%S %p',\n",
      "            '%m/%d/%Y %H:%M:%S %p', '%m/%Y/%d %H:%M:%S %p', '%Y/%m/%d %H:%M:%S %p', '%Y/%d/%m %H:%M:%S %p',\n",
      "\n",
      "            '%d-%m-%Y %H:%M %p', '%d-%Y-%m %H:%M %p', '%m-%d-%Y %H:%M %p', '%m-%Y-%d %H:%M %p', '%Y-%m-%d %H:%M %p',\n",
      "            '%Y-%d-%m %H:%M %p', '%d/%m/%Y %H:%M %p', '%d/%Y/%m %H:%M %p', '%m/%d/%Y %H:%M %p', '%m/%Y/%d %H:%M %p',\n",
      "            '%Y/%m/%d %H:%M %p', '%Y/%d/%m %H:%M %p', '%d-%m-%Y %H:%M:%S %p'\n",
      "\n",
      "        ]\n",
      "        # input_formats = formats.get_format_lazy('DATETIME_INPUT_FORMATS')\n",
      "        input_formats = FORMATS\n",
      "        for format in input_formats:\n",
      "            try:\n",
      "                print(\"value is and format is\",value,format,self.strptime(value, format))\n",
      "                return self.strptime(value, format)\n",
      "            except (ValueError, TypeError):\n",
      "                continue\n",
      "\n",
      "    def strptime (self, value, format):\n",
      "        return datetime.datetime.strptime(value, format)\n",
      "\n",
      "Now, the only problem is, when I open/edit a '.csv' file using notepad or any other software other than Microsoft Excel, it opens just fine. Here is an un-edited csv file. \n",
      " \n",
      "When I open the same file in excel, and save without changing anything, it shows me this warning:\n",
      "\n",
      "I already have written the code for decoding:\n",
      "\n",
      "data_set = csv_file.read().decode('UTF-8')\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089890/how-can-i-fit-this-naive-bayes-model-valueerror-setting-an-array-element-with\n",
      "How can I fit this Naive-Bayes model?. ValueError: setting an array element with a sequence\n",
      "\n",
      "\n",
      "I am trying to fit a NB model in Python and I am always getting the same error, even though dimensions of features and labels are correct for the fitting.\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "model = GaussianNB()\n",
      "\n",
      "model.fit(features,labels)\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "<ipython-input-67-bce1b5fdfb0c> in <module>\n",
      "      5 model = GaussianNB()\n",
      "      6 \n",
      "----> 7 model.fit(features,labels)\n",
      "      8 \n",
      "      9 #predicted = model.predict([[0.086469175340272,0.049800796812749,0.017614091273018002,0.013090495162208001,1]])\n",
      "\n",
      "c:\\users\\marta\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\naive_bayes.py in fit(self, X, y, sample_weight)\n",
      "    188         self : object\n",
      "    189         \"\"\"\n",
      "--> 190         X, y = check_X_y(X, y)\n",
      "    191         return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
      "    192                                  sample_weight=sample_weight)\n",
      "\n",
      "c:\\users\\marta\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\n",
      "    754                     ensure_min_features=ensure_min_features,\n",
      "    755                     warn_on_dtype=warn_on_dtype,\n",
      "--> 756                     estimator=estimator)\n",
      "    757     if multi_output:\n",
      "    758         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\n",
      "c:\\users\\marta\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\n",
      "    525             try:\n",
      "    526                 warnings.simplefilter('error', ComplexWarning)\n",
      "--> 527                 array = np.asarray(array, dtype=dtype, order=order)\n",
      "    528             except ComplexWarning:\n",
      "    529                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\n",
      "c:\\users\\marta\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\numpy\\core\\numeric.py in asarray(a, dtype, order)\n",
      "    536 \n",
      "    537     \"\"\"\n",
      "--> 538     return array(a, dtype, copy=False, order=order)\n",
      "    539 \n",
      "    540 \n",
      "\n",
      "ValueError: setting an array element with a sequence.\n",
      "\n",
      "My features and labels are like:\n",
      "features.shape = (4430, 5)\n",
      "len(features[n][m]) = 306\n",
      "labels.shape = (4430,)\n",
      "len(labels[i]) = 306\n",
      "\n",
      "And features and labels are of the form:\n",
      "features = array([[list([1, 2, 2, 6, 6, 6]),list([1, 2, 2, 6, 6, 6]),\n",
      "list([1, 2, 2, 6, 6, 6]),list([1, 2, 2, 6, 6, 6]),list([1, 2, 2, 6, 6, 6])],\n",
      "[list([0, 218, 234, 195, 201, 229]),list([0, 218, 234, 195, 201, 229]),\n",
      "list([0, 218, 234, 195, 201, 229]),list([0, 218, 234, 195, 201, 229]),\n",
      "list([0, 218, 234, 195, 201, 229])], dtype=object)\n",
      "\n",
      "labels = array([list([0, 0, 0, 0, 0, 0]),list([0, 0, 0, 0, 0, 0])\n",
      "\n",
      "I have also tried fitting it to other models and doesn't work also, and have reviewed other posts here and all talk about the dimension of the matrices, but .shape gives good dimensions for both to work (as far as I am concerned).\n",
      "What can I do to fit this model?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089889/when-the-label-of-lightgbm-is-continuous-values-between-0-1\n",
      "when the label of lightgbm is continuous values between （0，1）\n",
      "\n",
      "\n",
      "ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "ValueError                                Traceback (most recent call last)\n",
      "<ipython-input-34-6adcad511f10> in <module>()\n",
      "     25 kf = skf.split(train_data[feature_name],train_data['RULR__mean'])\n",
      "     26 # 交叉验证\n",
      "---> 27 for index, (train_index, test_index) in enumerate(kf):\n",
      "     28     print(index)\n",
      "     29     X_train, X_valid, y_train, y_valid = train_data[train_index][feature_name], train_data[test_index][feature_name],train_data[train_index][ 'RULR__mean'], train_data[test_index][ 'RULR__mean']\n",
      "\n",
      "\n",
      "\n",
      "3 frames\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py in _make_test_folds(self, X, y)\n",
      "    639             raise ValueError(\n",
      "    640                 'Supported target types are: {}. Got {!r} instead.'.format(\n",
      "--> 641                     allowed_target_types, type_of_target_y))\n",
      "    642 \n",
      "    643         y = column_or_1d(y)\n",
      "\n",
      "ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089874/populate-an-int64-dataframe-column-based-on-index-of-a-list-in-python\n",
      "Populate an int64 DataFrame column based on index of a list in Python\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a DataFrame with all int64-type columns.\n",
      "  City  Val  ...\n",
      "0    3    1  \n",
      "1    2   43  \n",
      "2    0   32  \n",
      "3    1   54\n",
      "\n",
      "Then, I have a list of category names:\n",
      "names = ['Sydney', 'Tokyo', 'Vancouver', 'Toronto']\n",
      "\n",
      "What I want to do is , based on the names list index i.e., 0 = 'Sydney' and 1 = 'Tokyo', populate the City column with city names.\n",
      "Desirable result:\n",
      "       City Val  ...\n",
      "0   Toronto   1  \n",
      "1 Vancouver  43  \n",
      "2    Sydney  32  \n",
      "3     Tokyo  54\n",
      "\n",
      "I tried: df['City'].loc[df['City'].isin(names), df['City']]=names.index(df['City']), but get an error \n",
      "ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "\n",
      "AND, I'd like to change the City column into a category type.\n",
      "    df['City'] = df['City'].astype('category')\n",
      "    df['City'].cat.set_categories(names, ordered=True, inplace=True)\n",
      "\n",
      "Answer\n",
      "\n",
      "Use Series.map with dictionary created by enumerate:\n",
      "names = ['Sydney', 'Tokyo', 'Vancouver', 'Toronto']\n",
      "df['City'] = df['City'].map(dict(enumerate(names)))\n",
      "print (df)\n",
      "        City  Val\n",
      "0    Toronto    1\n",
      "1  Vancouver   43\n",
      "2     Sydney   32\n",
      "3      Tokyo   54\n",
      "\n",
      "Detail:\n",
      "print (dict(enumerate(names)))\n",
      "{0: 'Sydney', 1: 'Tokyo', 2: 'Vancouver', 3: 'Toronto'}\n",
      "\n",
      "Then for categoricals:\n",
      "df['City'] = pd.CategoricalIndex(df['City'].map(dict(enumerate(names))),\n",
      "                                 ordered=True, \n",
      "                                 categories=names)\n",
      "\n",
      "Or:\n",
      "df['City'] = (df['City'].map(dict(enumerate(names)))\n",
      "                       .astype('category', ordered=True, categories=names))\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089872/some-problems-with-wiriting-my-data-into-a-pdf\n",
      "Some Problems with wiriting my Data into a PDF\n",
      "\n",
      "\n",
      "I would like to write my evaluation data in a PDF sheet.  For this I iterate through a 2 dimensional array with the log data\n",
      "Now I want to write all records that don't have a time stamp into a PDF file\n",
      "If I write it into a text file everything works without problems as I want. However, the PDF writer (reportlab) always writes only one entry in the PDF file\n",
      "def writeData(file,titel,y):\n",
      "    c = canvas.Canvas(\"Report_\" + titel + \"_\" + time.strftime(\"%d.%m.%Y\"\"_\"\"%H-%M-%S\") + \".pdf\")\n",
      "    c.drawString(240, 775, \"Evaluation \" + titel)\n",
      "    b = 775\n",
      "    for i in range(y):\n",
      "        b = b-25\n",
      "        for x in range(4):\n",
      "            if 'timestamp is zero' in file[i][3]:\n",
      "                print(file[i][x])\n",
      "                c.drawString(20, b, file[i][x])\n",
      "                b = b - 15\n",
      "\n",
      "    c.save()\n",
      "\n",
      "my print result:\n",
      "C:/Users/nc/PycharmProjects/saverissupporttools/baseanalyzer/ExampleData/Base__errorlogrec\n",
      "         0\n",
      "Mon Dec 31 23:00:00 1979\n",
      "timestamp is zero\n",
      "C:/Users/nc/PycharmProjects/saverissupporttools/baseanalyzer/ExampleData/Base__errorlogrec\n",
      "         0\n",
      "Mon Dec 31 13:00:00 1979\n",
      "timestamp is zero\n",
      "But my PDf result only shows me the first record.\n",
      "Can any of you help me?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089861/how-to-convert-a-set-to-an-array\n",
      "How to convert a set to an array?\n",
      "\n",
      "\n",
      "How to convert a set to an array?\n",
      "I tried:\n",
      "import numpy as np\n",
      "\n",
      "mySet = {1,2,3,4,5}\n",
      "\n",
      "myRandomArray = np.asarray(mySet, dtype=int, order=\"C\")\n",
      "\n",
      "print(myRandomArray)\n",
      "\n",
      "Output\n",
      "\n",
      "return array(a, dtype, copy=False, order=order)\n",
      "TypeError: int() argument must be a string, a bytes-like object or a number, not 'set'\n",
      "\n",
      "Where am I making the mistake?\n",
      "\n",
      "Answer\n",
      "\n",
      "The array factory doesn't handle non sequence iterables too well. fromiter is better here:\n",
      "a = set(range(5)) \n",
      "np.fromiter(a,int,len(a))\n",
      "# array([0, 1, 2, 3, 4])\n",
      "mySet = {1,2,3,4,5}\n",
      "print(list(mySet))\n",
      "print(np.asarray(mySet))\n",
      "myset = {1,2,3,4,5}\n",
      "np.array(list(myset))\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089817/python-is-it-possible-to-create-a-project-with-dependencies-in-pycharm\n",
      "python - Is it possible to create a project with dependencies in PyCharm?\n",
      "\n",
      "\n",
      "I have created a python project using PyCharm on my laptop and I want to get it into a VM which I do not have permissions to install anything using pip.\n",
      "I am using libraries like pandas and numpy on my project, and on that VM I do not have those installed.\n",
      "Is there any way to get my project working on that VM?\n",
      "My project is implemented using Python 3.7 and Conda interpreter.\n",
      "I have tried to install packages on that VM.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089776/on-linux-computers-display-only-port-name-port-number-process-show-python\n",
      "On linux computers display only port name, port number, process show python\n",
      "\n",
      "\n",
      "I want to show only port name, port number, process in computer. but netstat brings multiple columns. I wanted to filter columns with python. But I got a mistake. Can you help me?\n",
      "from socket import *\n",
      "\n",
      "Port = 0 #First port.\n",
      "while Port <= 65535: #Port 65535 is last port you can access.\n",
      "    try:\n",
      "        try:\n",
      "            Socket = socket(AF_INET, SOCK_STREAM, 0) #Create a socket.\n",
      "        except:\n",
      "            print(\"Error: Can't open socket!\\n\")    \n",
      "            break #If can't open socket, exit the loop.\n",
      "        Socket.connect((\"127.0.0.1\", Port)) #Try connect the port. If port is not listening, throws ConnectionRefusedError. \n",
      "        Connected = True\n",
      "    except ConnectionRefusedError:\n",
      "        Connected = False       \n",
      "    finally:\n",
      "        if(Connected and Port != Socket.getsockname()[1]): \n",
      "            print(\"{}:{} Open \\n\".format(\"127.0.0.1\", Port)) \n",
      "        Port = Port + 1 \n",
      "        Socket.close() #Close socket.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089748/how-to-solve-the-error-input-contains-nan-infinity-or-a-value-too-large-for-d\n",
      "How to solve the error : Input contains NaN, infinity or a value too large for dtype('float64').?\n",
      "\n",
      "\n",
      "I am working on Titanic Dataset. I have filled the missing values in categorical columns. The categorical columns start from index 0 to index 3.\n",
      "I have used LabelEncoder for the categorical columns.\n",
      "While using onehotencoder , an error occurs :\n",
      "Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "There are no NaN values. I am not able to correct this error\n",
      "I have tried scaling before using OneHotEncoder but still the error appears.\n",
      "y_train = train.iloc[:,-1].values\n",
      "x_train = train.iloc[:,:-1].values\n",
      "test = test.iloc[:,:].values\n",
      "\n",
      "from sklearn.preprocessing import \n",
      "LabelEncoder,OneHotEncoder,StandardScaler\n",
      "for i in range(4):\n",
      "    le = LabelEncoder()\n",
      "    x_train[:,i]=le.fit_transform(x_train[:,i])\n",
      "    test[:,i]=le.transform(test[:,i])\n",
      "\n",
      "#sc = StandardScaler()\n",
      "#x_train = sc.fit_transform(x_train)\n",
      "#test = sc.transform(test)\n",
      "\n",
      "ohe = OneHotEncoder(categorical_features=[range(4)])\n",
      "x_train = ohe.fit_transform(x_train).toarray()\n",
      "test = ohe.transform(test).toarray()\n",
      "\n",
      "How to solve this error?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089725/how-to-use-variables-set-in-instance-methods-that-are-not-called\n",
      "How to use variables set in instance methods that are not called?\n",
      "\n",
      "\n",
      "I am trying to create a pipeline to process some data in Python using a Class instead of functions. So far my Class has 5 methods (functions) that each process the data a bit further. Now what I really want is to initalise my Class and use one do_all() method to run through the entire pipeline.\n",
      "For this I would need to use variabels that are set in method A as input for method B. To illustrate with some dummy data:\n",
      "Class foo():\n",
      "\n",
      "    # class variables:\n",
      "    self.path = '\\foo'\n",
      "\n",
      "\n",
      "    def __init__(self, age):\n",
      "       self.age = age\n",
      "\n",
      "    def methodA(meters):\n",
      "       self.centimeters = meter/100\n",
      "       return self.centimeters\n",
      "\n",
      "    def methodB(centimeters=None):\n",
      "        centimeters = self.centimeters if centimeters is None else centimeters\n",
      "        self.millimeters = centimeters/100\n",
      "        return self.millimeters\n",
      "\n",
      "\n",
      "All is well if I instantiate methodA and then run methodB, because self.centimeters is 'created' when running methodA.\n",
      "dummy = foo()\n",
      "cm = dummy.methodA(5)\n",
      "mm = dummy.methodB()\n",
      "\n",
      "But if I want to run methodB from the start it returns an error. \n",
      "dummy = foo()\n",
      "\n",
      "mm = dummy.methodB()\n",
      "AttributeError: 'foo' object has no attribute 'centimeters'\n",
      "\n",
      "Now I understand that I need to run methodA before, so the self.centimeters exists within the class. But I want to know if there is another way.\n",
      "What I want is: input data > several processes (methodA + methodB) > output data. I also want to be able to run each process methodA or methodB seperately. \n",
      "What are my solutions? Should I just run all of the methods in a final method do_all()? In a functional paradigm I would create several functions functionA, functionB etc and just include functionA in functionB Is that the way to go in a Class as well?\n",
      "\n",
      "Answer\n",
      "\n",
      "Some strange logic here in your methodB: if you passed nonzero value to centimeters, method ignores it and uses existing self.centimeters (which can not exist at the moment of calling methodB), and if you pass None, you use passed value (i.e. None). Maybe first line in your method should be like this?\n",
      "centimeters = centimeters if centimeters else self.centimeters\n",
      "\n",
      "Or you can just initiate self.centimeters directly in init\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089723/csrf-token-missing-or-incorrect-while-csrf-token-added-in-form\n",
      "CSRF token missing or incorrect while csrf_token added in form\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have just started on a project involving Django and unfortunately got the error CSRF token missing or incorrect.\n",
      "This is my file in the views directory.\n",
      "from django.shortcuts import render_to_response\n",
      "from django.template import RequestContext\n",
      "\n",
      "\n",
      "def spot_preview(request, token):\n",
      "    TOKEN = token\n",
      "    spot = TVSpot.objects.get(preview_token=token)\n",
      "    title = \"Sample Video\"\n",
      "\n",
      "    return render_to_response(\"client/spotpreview.html\", {\n",
      "        \"spot\": spot,\n",
      "        \"Titel\": title\n",
      "    })\n",
      "\n",
      "\n",
      "@require_http_methods((\"POST\",))\n",
      "def feedback_from_user(request):\n",
      "    \"\"\"Submit an email and slack message to support based on in-app feedback.\n",
      "\n",
      "    POST Args:\n",
      "        message (str)\n",
      "\n",
      "    \"\"\"\n",
      "    print('POST executed!')\n",
      "    context = RequestContext(request)\n",
      "    feedback = SpotFeedback.objects.create(\n",
      "        message=request.data[\"message\"].strip(),\n",
      "        token=TOKEN\n",
      "        )\n",
      "    feedback.process()\n",
      "    feedback.save()\n",
      "\n",
      "    return render_to_response('client/success.html', RequestContext(request))\n",
      "\n",
      "Following is my form in my template:\n",
      "<form method=\"post\">\n",
      "    {% csrf_token %}\n",
      "    <div class=\"form-group purple-border shadow-textarea\">\n",
      "        <label for=\"feedbackTextarea\">Rückmeldung</label>                   \n",
      "        <textarea class=\"form-control z-depth-1\" id=\"feedbackTextarea\" rows=\"4\" placeholder=\"Ihre Rückmeldung!\"></textarea>\n",
      "    </div>\n",
      "    <input class=\"btn btn-primary btn-success\" type=\"submit\" value=\"Submit\">\n",
      "</form>\n",
      "\n",
      "I already have tried the suggestions on multiple posts on stackoverflow but could not achieve success. Can someone help me fixing this?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089681/visualize-different-dataframe-in-single-graph-using-matplotlib\n",
      "visualize different dataframe in single graph using matplotlib\n",
      "\n",
      "\n",
      "I have 300 files (one file is equal to one hour) every file has different column names (WRES_LD, RRES_LD, VRES_LD and more) and all these 300 files contain same column name. Now, WRES_LD, RRES_LD,VRES_LD has total 1100 rows and out of those only 132 values has the data. Now, I have to visualize the data for 300 (files) hours on the y-axis and for the x-axis for LD=1 then WRES_LD_RRES_LD,VRES_LD for all the columns should have first row value plt on y-axis. similarly for LD=2. \n",
      "I have combined all the 300 files column wise. So, I am thinking for making different data frames and then plot these values.\n",
      "path = r'converted_Dataset/FinalRes/' # use your path\n",
      "all_files = glob.glob(path + \"*.csv\")\n",
      "li = []\n",
      "for filename in all_files:\n",
      "    df = pd.read_csv(filename,  delimiter=',' )\n",
      "    li.append(df)\n",
      "\n",
      "frame = pd.concat(li, axis=1, ignore_index=False)\n",
      "frame.to_csv('converted_Dataset/FinalRes/FinalwithouVres12.csv',index=False)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "df=pd.read_csv('converted_Dataset/FinalRes/FinalwithouVres12.csv')\n",
      "x=df['WRES_LD'].iloc[1:57]\n",
      "y=df['RRES_LD'].iloc[1:57]\n",
      "z=df['VRES_LD'].iloc[1:57]\n",
      "df = pd.DataFrame(x,y,z)\n",
      "df\n",
      "##df2 = pd.DataFrame(y,index=range(1,30,1),color'green')\n",
      "#lines = df.plot.line()\n",
      "\n",
      "#df.plot(kind='line',x=x,y=y,ax=ax)\n",
      "#df.plot(kind='line',x=x,y=y, color='red', ax=ax)\n",
      "\n",
      "#plt.show()\n",
      "#lines\n",
      "\n",
      "I am unable to come up with the right idea to solve this problem.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089673/writing-values-of-a-csv-file-into-dataframe-as-they-are\n",
      "Writing values of a .csv file into dataframe as they are\n",
      "\n",
      "\n",
      "I have 2 CSV files with similar data as below:\n",
      "File 1:\n",
      "1234    | Hamlet\n",
      "2345    | Shakespeare\n",
      "234     | Juliet\n",
      "hello   | Romeo\n",
      "hi      | 12334\n",
      "\n",
      "\n",
      "File 2:\n",
      "1234    | Achilles\n",
      "2233    | Odysses\n",
      "22334   | Hector\n",
      "\n",
      "\n",
      "But when I load these into dataframes, all the values get loaded as string as below:\n",
      "File 1:\n",
      "'1234'    | 'Hamlet'\n",
      "'2345'    | 'Shakespeare'\n",
      "'234'     | 'Juliet'\n",
      "'hello'   | 'Romeo'\n",
      "'hi'      | '12334'\n",
      "\n",
      "\n",
      "File 2:\n",
      "'1234'    | 'Achilles'\n",
      "'2233'    | 'Odysses'\n",
      "'22334'   | 'Hector'\n",
      "\n",
      "\n",
      "Is there a way where I can load int values as int and float as float and string as str? \n",
      "Note: We don't know what data will be present in the csv files\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089645/pandas-data-frame-using-applylambda-x-but-depends-on-last-x-value\n",
      "Pandas Data-frame, Using .apply(lambda x :…) but depends on last x value\n",
      "\n",
      "\n",
      "I want to have a quicker way to do the below in a column of DataFrame.\n",
      "Now I can only do this in for loop, and it is quite slow. but I cannot depends on last (x) in using lambda!\n",
      "for i in range(len(Zscore_list)):\n",
      "    if len(Pos_list) != 0:\n",
      "        if Pos_list[i-1] == 1:\n",
      "            if Zscore_list[i] < -Thre2:\n",
      "                Pos_list.append(1)\n",
      "            else:\n",
      "                Pos_list.append(0)\n",
      "        elif Pos_list[i-1] == -1:\n",
      "            if Zscore_list[i] > Thre2:\n",
      "                Pos_list.append(-1)\n",
      "            else:\n",
      "                Pos_list.append(0)\n",
      "        elif Pos_list[i-1] == 0:\n",
      "            if Zscore_list[i] > Thre:\n",
      "                Pos_list.append(-1)\n",
      "            elif Zscore_list[i] < -Thre:\n",
      "                Pos_list.append(1)\n",
      "            else:\n",
      "                Pos_list.append(0) \n",
      "    else:\n",
      "        if Zscore_list[i] > Thre:\n",
      "             Pos_list.append(-1)\n",
      "        elif Zscore_list[i] < -Thre:\n",
      "            Pos_list.append(1)\n",
      "        else:\n",
      "            Pos_list.append(0)\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089643/how-to-attach-a-python-file-to-each-rowi-e-each-data-entry-in-database-formed\n",
      "How to attach a python file to each row(i.e. each data entry) in database formed using Django?\n",
      "\n",
      "\n",
      "Ive used default django superuser to create an admin and created a DB using it. But now in that i want to add a python script to each data entry i.e. row. How do i do this???\n",
      "Nothing special. Used basic Django.\n",
      "\n",
      "Answer\n",
      "\n",
      "There doesn't seem to be anything particularly complex here. You're just asking if you can use a field on the model to choose something; of course you can.\n",
      "For instance:\n",
      "# actions.py\n",
      "def thing1(obj):\n",
      "   # do something with obj\n",
      "\n",
      "def thing2(obj):\n",
      "   # do something else with obj\n",
      "\n",
      "\n",
      "# models.py\n",
      "from . import actions\n",
      "\n",
      "ACTIONS = {\n",
      "    \"do_thing_1\": actions.thing1,\n",
      "    \"do_thing_2\": actions.thing2,\n",
      "}\n",
      "ACTION_CHOICES = [(action, action) for action in ACTIONS]\n",
      "\n",
      "class MyModel(models.Model):\n",
      "    action = models.CharField(max_length=20, choices=ACTION_CHOICES)\n",
      "\n",
      "    def do_action(self):\n",
      "        return ACTIONS[self.action](self)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089635/how-can-i-plot-an-ellipse-over-different-centers-defined-in-an-array\n",
      "How can I plot an ellipse over different centers defined in an array\n",
      "\n",
      "\n",
      "I am plotting an ellipse and the translating it using the translate function where are define manually dx & dy\n",
      "Now I would like to have more plots with different values of dx,dy which are contained in this array. \n",
      "translation_points = \n",
      "[ (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (6, 12), (6, 13), (6, 14), (7, 5), (7, 6), (7, 7), (7, 8), (7, 9), (7, 10), (7, 11), (7, 12)]\n",
      "\n",
      "How can I do that?\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def ellipse(x, y):\n",
      "    value = (x*x) + (y*y)/3\n",
      "    if (value >= 300):\n",
      "        return 0\n",
      "    else:\n",
      "        return 1\n",
      "\n",
      "def translate(x, y):\n",
      "    DX = 5\n",
      "    DY = 5\n",
      "    return (x- DX, y - DY)    \n",
      "\n",
      "\n",
      "def rotate(x, y):\n",
      "    theta = np.radians(40)\n",
      "    matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
      "    return np.dot(matrix, (x,y))\n",
      "\n",
      "data = np.zeros((100,100))\n",
      "\n",
      "for i in range(0, 100):\n",
      "    for j in range(0, 100):\n",
      "        (x, y) = translate(i,j)\n",
      "        (x, y) = rotate(x, y)\n",
      "        data[i,j] = ellipse(x, y)\n",
      "\n",
      "plt.imshow(data, cmap=\"gray\")\n",
      "plt.show()\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089612/activating-a-python-virtual-environment-within-a-bash-script-fails-with-sudo-s\n",
      "Activating a python virtual environment within a bash script fails with “sudo: source: command not found”\n",
      "\n",
      "\n",
      "I'm trying to automate the deployment of my Python-Flask app on Ubuntu 18.04 using Bash by going through the motion of preparing all the necessary files/directories and cloning the source code from Github followed by creating the virtual environment, installing the pre-requisite modules and etc.\n",
      "Now because I have to execute my Bash script using sudo, this means that the entire script will be executed as root except where I specify otherwise using sudo -u myuser and when it comes to activating my virtual environment, I get the following output: sudo: source: command not found and my subsequent pip installs are all installed outside of the virtual environment. Excerpts of my code below:\n",
      "#!/bin/bash\n",
      "...\n",
      "sudo -u \"$user\" python3 -m venv .env\n",
      "sudo -u $SUDO_USER source /srv/www/www.mydomain.com/.env/bin/activate\n",
      "sudo -u \"$user\" pip install wheel\n",
      "sudo -u \"$user\" pip install uwsgi\n",
      "sudo -u \"$user\" pip install -r requirements.txt\n",
      "...\n",
      "\n",
      "Now for the life of me, I can't figure out how to activate the virtual environment in the context of the virtual environment if this makes any sense.\n",
      "I've scoured the web and most of the questions/answers I found revolves around how to activate the virtual environment in a Bash script but not how to activate the virtual environment as a separate user within a Bash script that was executed as sudo.\n",
      "\n",
      "Answer\n",
      "\n",
      "That's because source is not an executable file, but a built-in bash command. It won't work with sudo, since the latter accepts a program name (i.e. executable file) as argument.\n",
      "P.S. It's not clear why you have to execute the whole script as root.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089608/python-dash-how-to-subset-and-generate-a-dataframe-according-to-the-users-inp\n",
      "Python Dash - How to subset and generate a dataframe according to the user's input?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First of all I'm not an English-Speaker, I will do my best to explain my problem. Ask for clarification if necessary!\n",
      "I'm trying to create a Dash app that must:\n",
      "\n",
      "Read a csv file and convert it to a dataframe\n",
      "Subset this dataframe according to the user's choices\n",
      "Generate the subseted dataframe in a csv file\n",
      "\n",
      "I got two dataframes  gas3 and gas4 that I use in specific cases.\n",
      "I want to generate a dataframe (gas_genere) based on gas3 or gas4 in function of the user's choices. He can filter the dataframe by:\n",
      "\n",
      "Date (DatePickerRange)\n",
      "Flag (radio button)\n",
      "Inlet (checklist)\n",
      "Temperature minimum and maximum values (input)\n",
      "\n",
      "All the variables containing this information are in gas3 and gas4. Here is a \"test\" code (A lot of packages might be useless here, don't pay attention to them):\n",
      "import dash\n",
      "import dash_core_components as dcc # Graphs\n",
      "import dash_html_components as html # Tags\n",
      "from dash.dependencies import Input, Output, Event, State\n",
      "from pandas_datareader import DataReader\n",
      "import time\n",
      "import pandas as pd\n",
      "import plotly\n",
      "import plotly.graph_objs as go\n",
      "from collections import deque\n",
      "import random\n",
      "import os\n",
      "import glob\n",
      "import numpy as np\n",
      "import statistics\n",
      "from datetime import *\n",
      "from pytz import *\n",
      "import dash_table_experiments as dte\n",
      "import io\n",
      "from flask import send_file\n",
      "import flask\n",
      "import urllib.parse\n",
      "\n",
      "### Dataframe import\n",
      "\n",
      "gas3 = pd.read_csv(\"C:/Path/gas3.csv\", sep=';') # first data frame\n",
      "gas4 = pd.read_csv(\"C:/Path/gas4.csv\", sep=';') # second data frame\n",
      "gas3['Date_Local_Time'] = pd.to_datetime(gas3['Date_Local_Time'], format='%Y/%m/%d %H:%M') # String to datetime\n",
      "gas4['Date_Local_Time'] = pd.to_datetime(gas4['Date_Local_Time'], format='%Y/%m/%d %H:%M') # String to datetime\n",
      "\n",
      "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
      "\n",
      "app = dash.Dash(__name__, external_stylesheets=external_stylesheets) # Starting application\n",
      "\n",
      "app.layout = html.Div(children=[ # HTML of the entire project\n",
      "\n",
      "### Date picker range\n",
      "\n",
      "    html.Div([\n",
      "            html.Label(\"Choose your time period :\",\n",
      "                    htmlFor='date_picker_range',\n",
      "                    ),\n",
      "            html.Br(),\n",
      "            html.Br(),\n",
      "            dcc.DatePickerRange(\n",
      "                id='date-picker-range',\n",
      "                min_date_allowed=gas3['Date_Local_Time'][0].date(),\n",
      "                max_date_allowed=gas3['Date_Local_Time'][len(gas3)-1].date(),\n",
      "                start_date=gas3['Date_Local_Time'][0].date(),\n",
      "                end_date=gas3['Date_Local_Time'][len(gas3)-1].date(),\n",
      "                start_date_placeholder_text='Start date',\n",
      "                end_date_placeholder_text='End date',\n",
      "                display_format = 'DD/MM/YYYY'\n",
      "                ),\n",
      "            html.Br(),\n",
      "            html.Br()\n",
      "            ]),\n",
      "\n",
      "### Flag Choice\n",
      "\n",
      "    html.Div([\n",
      "            html.Label(\"Select a flag :\",\n",
      "                    htmlFor='radioflag',\n",
      "                    ),\n",
      "            html.Br(),\n",
      "            html.Br(),\n",
      "            dcc.RadioItems(\n",
      "                    id='radioflag',\n",
      "                    options=[\n",
      "                        {'label': 'Flag 0', 'value': 'Flag0'},\n",
      "                        {'label': 'Flag 1', 'value': 'Flag1'},\n",
      "                        {'label': 'Flag 3', 'value': 'Flag3'},\n",
      "                        {'label': 'Chambre à flux', 'value': 'CAF'}\n",
      "                        ]\n",
      "                        ),\n",
      "            html.Br(),\n",
      "            ]),\n",
      "\n",
      "### Inlet(s) choice\n",
      "\n",
      "    html.Div(children=[\n",
      "            html.Label(\"Select one or several inlet(s) :\",\n",
      "                    htmlFor='checkbox_1',\n",
      "                    ),\n",
      "            html.Br(),\n",
      "            html.Br(),\n",
      "        html.Div(style={'width':'15%', 'height':'100%','float':'left'},\n",
      "                children=[dcc.Checklist(id='ST1', className ='checkbox_1',\n",
      "                        options=[\n",
      "                            {'label': 'Inlet 1 ST1', 'value': 'I1ST1'},\n",
      "                            {'label': 'Inlet 2 ST1', 'value': 'I2ST1'},\n",
      "                            {'label': 'Inlet 3 ST1', 'value': 'I3ST1'},\n",
      "                            {'label': 'Inlet 4 ST1', 'value': 'I4ST1'},\n",
      "                            {'label': 'Inlet 5 ST1', 'value': 'I5ST1'},\n",
      "                            {'label': 'Inlet 6 ST1', 'value': 'I6ST1'}\n",
      "                                ],\n",
      "                        values=[],\n",
      "                        labelStyle = {'display': 'block'}\n",
      "                                )\n",
      "                        ]\n",
      "                    ),\n",
      "\n",
      "                ]\n",
      "            ),\n",
      "\n",
      "    html.Br(),\n",
      "    html.Br(),\n",
      "    html.Br(),\n",
      "    html.Br(),\n",
      "\n",
      "### Minimum temperature :\n",
      "\n",
      "    html.Div(style={'width':'20%', 'height':'100%','float':'left'},\n",
      "            children=[\n",
      "            html.Label(\"Minimum temperature (°C) :\",\n",
      "                    htmlFor='tempmin',\n",
      "                    ),\n",
      "                       html.Br(),\n",
      "            dcc.Input(\n",
      "                    id = 'tempmin',\n",
      "                    placeholder='Enter a value',\n",
      "                    type='float',\n",
      "                    value=''\n",
      "                    )\n",
      "            ]\n",
      "            ),\n",
      "\n",
      "### Maximum temperature :\n",
      "\n",
      "    html.Div([\n",
      "            html.Label(\"Maximum temperature (°C) :\",\n",
      "                    htmlFor='tempmax',\n",
      "                    ),\n",
      "                       html.Br(),\n",
      "            dcc.Input(\n",
      "                    id = 'tempmax',\n",
      "                    placeholder='Enter a value',\n",
      "                    type='float',\n",
      "                    value=''\n",
      "                    )\n",
      "            ]\n",
      "            ),\n",
      "\n",
      "### Download button\n",
      "\n",
      "    html.Div(id='table'),\n",
      "    html.A(\n",
      "        'Download Data',\n",
      "        id='download-link',\n",
      "        download=\"gas_genere.csv\",\n",
      "        href=\"\",\n",
      "        target=\"_blank\"\n",
      "    )\n",
      "])\n",
      "\n",
      "### Subset function\n",
      "\n",
      "def filter_data(date1, date2, flag, ST1, tempmin, tempmax):   \n",
      "    if flag == 'Flag0':\n",
      "        gas_genere = gas3[gas3['Flag']==0]\n",
      "    elif flag == 'Flag1':\n",
      "        gas_genere = gas4.copy()\n",
      "    elif flag == 'Flag3':\n",
      "        gas_genere = gas3[gas3['Flag']==3]\n",
      "    elif flag == 'CAF':\n",
      "        gas_genere = gas3[gas3['3PV4']==1]\n",
      "    else:\n",
      "        gas_genere = gas3.copy()\n",
      "    # gas_genere = gas_genere[(gas_genere['Temperature_air']>= tempmin) & (gas_genere['Temperature_air']<= tempmax)]\n",
      "    # gas_genere = gas_genere[gas_genere['ST_Valve'] in ST1]\n",
      "    # gas_genere = gas_genere[(gas_genere['Date_Local_Time'].time()>= date1) & (gas_genere['Date_Local_Time'].time()<= date2)]\n",
      "    return gas_genere\n",
      "\n",
      "### Callback :\n",
      "\n",
      "@app.callback(\n",
      "    Output('download-link', 'href'),\n",
      "    [Input('date-picker-range', 'start_date'),\n",
      "     Input('date-picker-range', 'end_date'),\n",
      "     Input('radioflag', 'value'),\n",
      "     Input('ST1', 'values'),\n",
      "     Input('tempmin', 'value'),\n",
      "     Input('tempmax', 'value')])\n",
      "\n",
      "### Update download link\n",
      "\n",
      "def update_download_link(date1, date2, flag, ST1, tempmin, tempmax):\n",
      "    gas_genere = filter_data(date1, date2, flag, ST1, tempmin, tempmax)\n",
      "    csv_string = gas_genere.to_csv(index=False, encoding='utf-8', sep=';')\n",
      "    csv_string = \"data:text/csv;charset=utf-8,%EF%BB%BF\" + urllib.parse.quote(csv_string)\n",
      "    return csv_string\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app.run_server(debug=True)\n",
      "\n",
      "To subset my dataframe, I use the filter_data function. But it does not work very well! I put all the \"filtering lines\" that does not work in comments #. \n",
      "Actually, the only thing that works is my radiobutton to choose a \"Flag\". I can easily generate a csv file by choosing the \"Flag\" I want:\n",
      " \n",
      "But I can't choose a date range, a mininum/maximum temperature or one/several inlets. If I remove the # corresponding to one of these lines, I got this kind of csv file:\n",
      " \n",
      "What's wrong with my code?\n",
      "Thank you!\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089563/create-dummy-variables-for-a-column-values-and-fill-them-with-the-count-of-rows\n",
      "Create dummy variables for a column values and fill them with the count of rows with unique combination of rest of the columns\n",
      "\n",
      "\n",
      "If there are 4 columns, and we create dummy columns with the values of one of those columns with a condition:\n",
      "The value of each newly created variable (dummy variable) will be the count of the number of rows with a unique combination of rest of the column values and the dummy variable created.\n",
      "The attached tables (source and destination) will help understand the problem better\n",
      "I tried the added code for generating the attached destination table from the attached source table (modified the actual example with test case), and it worked, but as the real data has millions of records, the code runs endlessly. Is there a faster way to achieve this? \n",
      "# df_d[(df_d['Type1'] == \"X11\"])&(df_d['Type2'] == \"X1\")&(df_d['Type3'] == \"Y1\") &(df_d[\"Action\"]== action)].shape[0]\n",
      "above statement takes a lot of time to process.Any suggestion on faster way will be helpful\n",
      "def find_number(k, action):\n",
      "    return df_d[(df_d['Type1'] == \"X11\"])&(df_d['Type2'] == \"X1\")&(df_d['Type3'] == \"Y1\") &(df_d[\"Action\"]== action)].shape[0]\n",
      "\n",
      "vals = df_d[\"Action\"].count_values.keys()\n",
      "\n",
      "for i in vals:\n",
      "    ### code to call with each action values\n",
      "\n",
      "\n",
      "\n",
      "Source table\n",
      "Code to create the Source table:\n",
      "import pandas as pd\n",
      "\n",
      "df1 = pd.DataFrame({\"Type1\": [\"x11\",\"x11\",\"x11\",\"x12\",\"x12\",\"x12\",\"x12\",\"x12\",\"x12\"], \"Type2\": [\"x1\",\"x2\",\"x2\",\"x2\",\"x1\",\"x1\",\"x2\",\"x1\",\"x1\"], \"Type3\":[\"y1\",\"y2\",\"y3\",\"y1\",\"y2\",\"y2\",\"y2\",\"y2\", \"y1\"], \"action\":[\"A\",\"A\",\"A\",\"B\",\"B\",\"B\",\"A\",\"A\",\"A\"]\n",
      "             })\n",
      "\n",
      "destination table\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089454/how-can-i-change-a-value-in-dataframe-pandas-with-if-condition\n",
      "How can i change a value in dataframe (pandas) with if condition [duplicate]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a Data Frame column with numeric values:\n",
      "df['percentage'].head()\n",
      "46.5\n",
      "44.2\n",
      "100.0\n",
      "42.12\n",
      "\n",
      "I want to see the column as bin counts:\n",
      "bins = [0, 1, 5, 10, 25, 50, 100]\n",
      "\n",
      "How can I get the result as bins with their value counts?\n",
      "[0, 1] bin amount\n",
      "[1, 5] etc \n",
      "[5, 10] etc \n",
      "......\n",
      "\n",
      "Answer\n",
      "\n",
      "You can use pandas.cut:\n",
      "bins = [0, 1, 5, 10, 25, 50, 100]\n",
      "df['binned'] = pd.cut(df['percentage'], bins)\n",
      "print (df)\n",
      "   percentage     binned\n",
      "0       46.50   (25, 50]\n",
      "1       44.20   (25, 50]\n",
      "2      100.00  (50, 100]\n",
      "3       42.12   (25, 50]\n",
      "\n",
      "\n",
      "bins = [0, 1, 5, 10, 25, 50, 100]\n",
      "labels = [1,2,3,4,5,6]\n",
      "df['binned'] = pd.cut(df['percentage'], bins=bins, labels=labels)\n",
      "print (df)\n",
      "   percentage binned\n",
      "0       46.50      5\n",
      "1       44.20      5\n",
      "2      100.00      6\n",
      "3       42.12      5\n",
      "\n",
      "Or numpy.searchsorted:\n",
      "bins = [0, 1, 5, 10, 25, 50, 100]\n",
      "df['binned'] = np.searchsorted(bins, df['percentage'].values)\n",
      "print (df)\n",
      "   percentage  binned\n",
      "0       46.50       5\n",
      "1       44.20       5\n",
      "2      100.00       6\n",
      "3       42.12       5\n",
      "\n",
      "\n",
      "...and then value_counts or groupby and aggregate size:\n",
      "s = pd.cut(df['percentage'], bins=bins).value_counts()\n",
      "print (s)\n",
      "(25, 50]     3\n",
      "(50, 100]    1\n",
      "(10, 25]     0\n",
      "(5, 10]      0\n",
      "(1, 5]       0\n",
      "(0, 1]       0\n",
      "Name: percentage, dtype: int64\n",
      "\n",
      "\n",
      "s = df.groupby(pd.cut(df['percentage'], bins=bins)).size()\n",
      "print (s)\n",
      "percentage\n",
      "(0, 1]       0\n",
      "(1, 5]       0\n",
      "(5, 10]      0\n",
      "(10, 25]     0\n",
      "(25, 50]     3\n",
      "(50, 100]    1\n",
      "dtype: int64\n",
      "\n",
      "By default cut return categorical.\n",
      "Series methods like Series.value_counts() will use all categories, even if some categories are not present in the data, operations in categorical.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089430/asyncio-task-cancel-is-is-synchronous\n",
      "asyncio task cancel. Is is synchronous?\n",
      "\n",
      "\n",
      "I understand that task.cancel() arranges an exception to be thrown inside the task function. Is that happen in a synchronous way? (As I don't await task.cancel()). Can code that follows the line task.cancel() assume that the task will no longer run?\n",
      "A simple example:  \n",
      "async def task1():\n",
      "    await asyncio.sleep(3)\n",
      "    print(\"after sleep\")\n",
      "\n",
      "async def task2():\n",
      "    t = loop.create_task(task1())\n",
      "    await asyncio.sleep(1)\n",
      "    t.cancel()\n",
      "    # can the following code lines assume that task1 is no longer running?\n",
      "\n",
      "loop = asyncio.get_event_loop()\n",
      "loop.run_forever()\n",
      "\n",
      "Answer\n",
      "\n",
      "Can code that follows the line task.cancel() assume that the task will\n",
      "  no longer run?\n",
      "\n",
      "No. task.cancel() only marks task to be cancelled later. You should explicitly await task after it and catch CancelledError to be sure task is cancelled.\n",
      "See example here.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089427/how-can-i-get-keyword-only-once\n",
      "How can I get keyword only once?\n",
      "\n",
      "\n",
      "I made a query that lists keyword for each page. What I want to do is that I want to see the keyword value with its highest page value. For example: I have \"try\" data for page 1,2,3 but I want to show the highest one which is 3. I want this for each page.\n",
      "This is my code:\n",
      "            \"aggs\": {\n",
      "                \"Group1\": {\n",
      "                    \"terms\": {\n",
      "                        \"field\": \"method.keyword\",\n",
      "                        \"include\": \".*POST.*\",\n",
      "                    },\n",
      "                    \"aggs\": {\n",
      "                        \"Group2\": {\n",
      "                            \"terms\": {\n",
      "                                \"field\": \"page\",\n",
      "                                \"size\": 1000,\n",
      "                                \"order\": {\"_key\": \"desc\"},\n",
      "                            },\n",
      "                            \"aggs\": {\n",
      "                                \"Group3\": {\n",
      "                                    \"terms\": {\n",
      "                                        \"field\": \"contains.keyword\",\n",
      "\n",
      "                                    }\n",
      "                                }\n",
      "\n",
      "                            },\n",
      "                        }\n",
      "                    },\n",
      "\n",
      "\n",
      "\n",
      "                }\n",
      "\n",
      "            }\n",
      "\n",
      "This is what the output is:\n",
      "https://paste.ubuntu.com/p/vQfprgW2cn/\n",
      "As you see, in the output it shows \"sleep\" for its every page. But I just want to have the highest value for \"sleep\" data which is \"19\".\n",
      "Note: Please don't want me to put this thorough kibana as I don't have it. I use this query in python-elasticsearch librar.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57089399/i-need-to-fetch-the-common-values-across-multiple-groups-in-python-from-one-sing\n",
      "I need to fetch the common values across multiple groups in python from one single data frame [on hold]\n",
      "\n",
      "\n",
      "I have a requirement in python. The data is like this\n",
      "Parts Group\n",
      "D123    G-1\n",
      "A231    G-1\n",
      "D123    G-2\n",
      "D345    G-2\n",
      "F231    G-3\n",
      "F897    G-3\n",
      "F111    G-3\n",
      "F111    G-4\n",
      "F338    G-4\n",
      "F338    G-5\n",
      "F555    G-5\n",
      "\n",
      "OUT PUT REQUIRED:\n",
      "PARTS   GROUP\n",
      "D123    NEW_GRP-1\n",
      "A231    NEW_GRP-1\n",
      "D345    NEW_GRP-1\n",
      "F231    NEW_GRP-1\n",
      "F897    NEW_GRP-1\n",
      "F111    NEW_GRP-1\n",
      "F338    NEW_GRP-1\n",
      "F555    NEW_GRP-1\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "\n",
    "page= urlopen(\"https://stackoverflow.com/questions/tagged/python\")\n",
    "document=page.read()\n",
    "soup=BeautifulSoup(document, 'html.parser')\n",
    "questions=soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "# questions=[]\n",
    "for questions in questions_list:\n",
    "    print(\"Question\\n\")\n",
    "    print('http://stackoverflow.com'+questions.get('href'))\n",
    "    print(questions.get_text())\n",
    "    print(\"\\n\")\n",
    "    url='https://stackoverflow.com'+questions.get('href')\n",
    "    response = req.urlopen(url)\n",
    "    soup= BeautifulSoup(response,'html.parser')\n",
    "    for question in soup.select(\"div.postcell div.post-text\"):\n",
    "        print(question.get_text().strip())\n",
    "    print(\"\\nAnswer\\n\")\n",
    "    if len(soup.select(\"div.answercell div.post-text\"))==0:\n",
    "        print('no answer')\n",
    "    else:\n",
    "        for answer in soup.select(\"div.answercell div.post-text\"):\n",
    "            print(answer.get_text().strip())\n",
    "\n",
    "    print('='*40,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "site = \"https://kin.naver.com/search/list.nhn?\"\n",
    "tag = input(\"검색어를 입력해주십시오-->\")\n",
    "num = input(\"검색할 페이지 번호를 입력하십시오-->\")\n",
    "temp_url = site + \"sort=none&query=\" + tag \n",
    "temp_url_encode=parse.urlparse(temp_url)\n",
    "query = parse.parse_qs(temp_url_encode.query)\n",
    "query_encode = parse.urlencode(query, doseq=True)\n",
    "\n",
    "url = site+query_encode+\"&section=kin&page=\"+ num\n",
    "\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "soup = BeautifulSoup(document.decode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "temp_qna = soup.find(class_=\"basic1\")\n",
    "qna_list = temp_qna.select(\"li > dl > dt > a\")\n",
    "\n",
    "for qna in qna_list:\n",
    "    \n",
    "    # 링크 생성\n",
    "    qna_url = qna.attrs[\"href\"]\n",
    "    print(\"=\"*30+\"링크\"+\"=\"*30)\n",
    "    print(qna_url)\n",
    "    \n",
    "    # 링크 읽기\n",
    "    qna_page = urlopen(qna_url.encode(\"ascii\",\"ignore\").decode(\"ascii\",\"ignore\")) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성\n",
    "    soup_qna = BeautifulSoup(qna_document.decode(\"utf-8\"), \"html.parser\")\n",
    "    \n",
    "    # 질문\n",
    "    print(\"*\"*10 + \"질문 제목\")\n",
    "    qna_questions = soup_ qna.find(class_=\"question-content__inner\")\n",
    "    \n",
    "    if qna_questions == None:\n",
    "        pass\n",
    "    else:\n",
    "        title_q = qna_questions.select_one(\"div.c-heading > div.c-heading__title > div.c-heading__title-inner > div.title\").text\n",
    "        print(title_q.strip())\n",
    "    \n",
    "    content_q = qna_questions.select_one(\"div.c-heading > div.c-heading__content\")\n",
    "    if content_q == None:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*10 + \"질문 내용\")\n",
    "        print(content_q.text.strip())\n",
    "        \n",
    "    # 답변\n",
    "    qna_answers = soup_qna.find(class_=\"answer-content__inner\")\n",
    "    \n",
    "    title_q_list = qna_answers.select(\"div.c-heading-answer__title > p\")\n",
    "    content_q_list = qna_answers.select(\"div._endContentsText\")\n",
    "    \n",
    "    if title_q == None:\n",
    "        print(\"답변이 없습니다\")\n",
    "    else:\n",
    "        for title_q in title_q_list:\n",
    "            for content_q in content_q_list:\n",
    "                print(\"\\n\")\n",
    "                print(\"+\"*10 + \"답변자\" + \"+\"*10)\n",
    "                print(title_q.text.strip())\n",
    "                print(\"+\"*26)\n",
    "                print(\"\\n\")\n",
    "                print(\"-\"*10 + \"답변 내용\" + \"-\"*10)\n",
    "                print(content_q.text.strip())\n",
    "                print(\"-\"*29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "# 검색어 설정\n",
    "tag = input(\"검색어를 입력하십시오-->\")\n",
    "\n",
    "# url 설정 및 url 읽기\n",
    "url = \"https://stackoverflow.com/questions/tagged/\" + tag\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "\n",
    "# 객체 생성 및 파일 읽기\n",
    "soup = BeautifulSoup(document, \"html.parser\")\n",
    "questions = soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "\n",
    "# 메인 알고리즘\n",
    "# for questions in questions_list:\n",
    "    \n",
    "    print(\"@\"*50, \"제목\", \"@\"*50)\n",
    "    \n",
    "    # Q&A 질문 요약\n",
    "    print(\"질문\",questions.get_text()) # 조금 더 가벼움!\n",
    "    \n",
    "    # Q&A 링크 생성\n",
    "    print(\"=\"*100)\n",
    "    print(\"링크:\",\"https://stackoverflow.com\"+questions.get(\"href\"))\n",
    "          \n",
    "    \n",
    "    # Q&A 링크 읽기\n",
    "    qna_url=\"https://stackoverflow.com\"+questions.get(\"href\")\n",
    "    qna_page = urlopen(qna_url) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성 및 파일 읽기\n",
    "    soup_qna = BeautifulSoup(qna_document, \"html.parser\")\n",
    "    qna_questions = soup_qna.find(class_=\"question\")\n",
    "    \n",
    "    # 질문 내용 출력\n",
    "    print(\"*\"*50 ,\"질문 내용\", \"*\"*50)\n",
    "    print(qna_questions.select(\"div.post-text\")[0].text)\n",
    "    \n",
    "    # 답변 내용 출력\n",
    "    print(\"*\"*50 ,\"답변 내용\", \"*\"*50)\n",
    "    qna_answers = soup_qna.find(id=\"answers\")\n",
    "    if qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\") == None:\n",
    "        print(\"#\"*50,\"답변이 없습니다\",\"#\"*50)\n",
    "    else:\n",
    "        print(qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\").text)\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "# 검색어 설정\n",
    "tag = input(\"검색어를 입력하십시오-->\")\n",
    "\n",
    "# url 설정 및 url 읽기\n",
    "url = \"https://stackoverflow.com/questions/tagged/\" + tag\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "\n",
    "# 객체 생성 및 파일 읽기\n",
    "soup = BeautifulSoup(document, \"html.parser\")\n",
    "questions = soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "\n",
    "# 메인 알고리즘\n",
    "for questions in questions_list:\n",
    "    \n",
    "    print(\"@\"*50, \"제목\", \"@\"*50)\n",
    "    \n",
    "    # Q&A 질문 요약\n",
    "    print(\"질문\",questions.get_text()) # 조금 더 가벼움!\n",
    "    \n",
    "    # Q&A 링크 생성\n",
    "    print(\"=\"*100)\n",
    "    print(\"링크:\",\"https://stackoverflow.com\"+questions.get(\"href\"))\n",
    "          \n",
    "    \n",
    "    # Q&A 링크 읽기\n",
    "    qna_url=\"https://stackoverflow.com\"+questions.get(\"href\")\n",
    "    qna_page = urlopen(qna_url) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성 및 파일 읽기\n",
    "    soup_qna = BeautifulSoup(qna_document, \"html.parser\")\n",
    "    qna_questions = soup_qna.find(class_=\"question\")\n",
    "    \n",
    "    # 질문 내용 출력\n",
    "    print(\"*\"*50 ,\"질문 내용\", \"*\"*50)\n",
    "    print(qna_questions.select(\"div.post-text\")[0].text)\n",
    "    \n",
    "    # 답변 내용 출력\n",
    "    print(\"*\"*50 ,\"답변 내용\", \"*\"*50)\n",
    "    qna_answers = soup_qna.find(id=\"answers\")\n",
    "    if qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\") == None:\n",
    "        print(\"#\"*50,\"답변이 없습니다\",\"#\"*50)\n",
    "    else:\n",
    "        print(qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\").text)\n",
    "    print(\"=\"*100)\n",
    "\n",
    "\n",
    "# In[223]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지식인 검색\n",
    "site = \"https://kin.naver.com/search/list.nhn?\"\n",
    "tag = input(\"검색어를 입력해주십시오-->\")\n",
    "num = input(\"검색할 페이지 번호를 입력하십시오-->\")\n",
    "temp_url = site + \"sort=none&query=\" + tag \n",
    "temp_url_encode=parse.urlparse(temp_url)\n",
    "query = parse.parse_qs(temp_url_encode.query)\n",
    "query_encode = parse.urlencode(query, doseq=True)\n",
    "\n",
    "url = site+query_encode+\"&section=kin&page=\"+ num\n",
    "\n",
    "#\n",
    "\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "soup = BeautifulSoup(document.decode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "temp_qna = soup.find(class_=\"basic1\")\n",
    "qna_list = temp_qna.select(\"li > dl > dt > a\")\n",
    "\n",
    "for qna in qna_list:\n",
    "    \n",
    "    # 링크 생성\n",
    "    qna_url = qna.attrs[\"href\"]\n",
    "    print(\"=\"*30+\"링크\"+\"=\"*30)\n",
    "    print(qna_url)\n",
    "    \n",
    "    # 링크 읽기\n",
    "    qna_page = urlopen(qna_url.encode(\"ascii\",\"ignore\").decode(\"ascii\",\"ignore\")) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성\n",
    "    soup_qna = BeautifulSoup(qna_document.decode(\"utf-8\"), \"html.parser\")\n",
    "    \n",
    "    # 질문\n",
    "    print(\"*\"*10 + \"질문 제목\")\n",
    "    qna_questions = soup_qna.find(class_=\"question-content__inner\")\n",
    "    \n",
    "    if qna_questions == None:\n",
    "        pass\n",
    "    else:\n",
    "        title_q = qna_questions.select_one(\"div.c-heading > div.c-heading__title > div.c-heading__title-inner > div.title\").text\n",
    "        print(title_q.strip())\n",
    "    \n",
    "    content_q = qna_questions.select_one(\"div.c-heading > div.c-heading__content\")\n",
    "    if content_q == None:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*10 + \"질문 내용\")\n",
    "        print(content_q.text.strip())\n",
    "        \n",
    "    # 답변\n",
    "    qna_answers = soup_qna.find(class_=\"answer-content__inner\")\n",
    "    \n",
    "    title_q_list = qna_answers.select(\"div.c-heading-answer__title > p\")\n",
    "    content_q_list = qna_answers.select(\"div._endContentsText\")\n",
    "    \n",
    "    if title_q == None:\n",
    "        print(\"답변이 없습니다\")\n",
    "    else:\n",
    "        for title_q in title_q_list:\n",
    "            for content_q in content_q_list:\n",
    "                print(\"\\n\")\n",
    "                print(\"+\"*10 + \"답변자\" + \"+\"*10)\n",
    "                print(title_q.text.strip())\n",
    "                print(\"+\"*26)\n",
    "                print(\"\\n\")\n",
    "                print(\"-\"*10 + \"답변 내용\" + \"-\"*10)\n",
    "                print(content_q.text.strip())\n",
    "                print(\"-\"*29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 -> 수치화(DTM, Word2Vec 등)\n",
    "#문서간 단어들의 차이를 계산? 유클리드, 코사인 유사도 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n",
      "0.6666666666666667\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# 문서1     1         1         0         1\n",
    "# 문서2     1         0         1         1\n",
    "# 문서3     2         0         2         2\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(x,y):\n",
    "     return np.dot(x,y)/(norm(x)*norm(y))\n",
    "    \n",
    "doc1=np.array([1,1,0,1])\n",
    "doc2=np.array([1,0,1,1])\n",
    "doc3=np.array([2,0,2,2])\n",
    "\n",
    "print(cos_sim(doc1, doc2))\n",
    "print(cos_sim(doc1, doc3))\n",
    "print(cos_sim(doc3, doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"movies_metadata.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()['overview']\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#단순 코사인 유사도 기반 계산(연습)\n",
    "tfidf=TfidfVectorizer(stop_words='english')\n",
    "tfidf\n",
    "#data['overview'].isnull().value_counts()\n",
    "data['overview']=data['overview'].fillna('') \n",
    "#NaN의 경우는 ''로 (tfidf 작업시 NaN있으면 에러가 발생)\n",
    "data['overview'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat=tfidf.fit_transform(data['overview'])\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cos_sim=cos_sim):\n",
    "    idx_title=idx[title] # 12356 = idx['Rambo']\n",
    "    sim_score=list(enumerate(cos_sim[idx_title]))\n",
    "    sim_score=sorted(sim_score, key=lambda x:x[1] ,reverse=True)\n",
    "    mi=(sim_score[1:11])\n",
    "    res=[i[0]for i in mi]\n",
    "    print(data['title'].iloc[res])\n",
    "#     print(sim_score[1:11])\n",
    "#     mi=[i[0]for i in sim_score]\n",
    "#     print(mi)\n",
    "#     print(sim_score)\n",
    "#     idx_title #12356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('Rambo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_info={'m_id':\"aporlo21\",\n",
    "           'm_passwd':\"1234!@#$\"}\n",
    "url_login= \"http://www.hanbit.co.kr/member/login_proc.php\"\n",
    "# post방식으로 서버 연결\n",
    "session=requests.session()\n",
    "res=session.post(url_login, data=login_info)\n",
    "res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_mypage= \"http://www.hanbit.co.kr/myhanbit/myhanbit.html\"\n",
    "res=session.get(url_mypage)\n",
    "# res.text\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "mi=soup.select_one(\".mileage_section1 > dd > span\").text\n",
    "ec=soup.select_one(\".mileage_section2 > dd > span\").text #get.text : method 형 도출\n",
    "ec\n",
    "print(\"마일리지:\"+mi,\"이코인:\"+ec)\n",
    "#container > div > div.sm_mymileage > dl.mileage_section1 > dd > span\n",
    "# 4로 시작하는 error\n",
    "# 5로 시작하는 ser측 문제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
