{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cats vs dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterator_반복자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cats vs dogs data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation : 검증용 data\n",
    "\n",
    "# validation _ ( 1000 - 1499 ) in cats vs dogs \n",
    "\n",
    "# 전체 data => train / test ( 7 : 3 )\n",
    "# train data => train / validation\n",
    "# validation : train data 의 일부분을 => validation 내에서 모델의 성능 1차적 평가\n",
    "# data 가 너무 작을 validation 작업 필요 x\n",
    "# 그럴 당시 validation 작업 대신, cross validation = k-fold = k개 만큼 나누어 처리 진행\n",
    "\n",
    "# train / validation 비교 시 acc 차이가 나는 경우 : overfitting 간주, \n",
    "# 데이터가 방대할시 이런 sol 로써 overfitting 을 방지한다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense\n",
    "\n",
    "# Dense (계층) : FullyConnectedLayer 생성시 호출하는 함수 \n",
    "# I : 4, O : 8 => 연결강도 : 32\n",
    "# ex) 성별판별기 = ( 머리카락 길이x1 + 신장x2 + 혈액형x3 ) * w3\n",
    "# Dense (출력 뉴런수[고정],\n",
    "#        속성이름(입력뉴런) = 값[input_dim:입력뉴런수],\n",
    "#       init ( weight ) : normal/uniform,\n",
    "#       activation\n",
    "#       default = linear [결과값 여과없이 도출],\n",
    "#        relu,sigmoid\n",
    "#       softmax : 다중분류시 사용 )\n",
    "\n",
    "# ex) Dense<1, input_dim=3, act=sigmoid // weight = 3\n",
    "# ex) Dense<3, input_dim=4, act=softmax // weight = 12 \n",
    "# ex) Dense<4, input_dim=5, act=relu // weight = 20\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN plus Summary\n",
    "\n",
    "# Convolution Layer : filter 사용해서 이미지로 부터 feature 추출 을 위해 활용\n",
    "# Conv2D (32(필터의 개수), (5,5) kernal size[filter], activation func) \n",
    "# 필터와 원본 이미지 사이에서는 각각의 요소 끼리 합성곱이 이루어지고\n",
    "# stride optioning 을 통해 kernal 이동을 이루어지게 한다\n",
    "# padding optining : ( SAME : 64 x 64 -> 60 x 60 [by 5x5 kernal] 소실되는 문제를 방지해줌\n",
    "#                     or Valid  ) [ 경계처리 목적 ]\n",
    "# MaxPooling \n",
    "\n",
    "# filter : 사실상 weight 역할을 담당한다\n",
    "# 필터하나가 입력이미지를 돌아다니면서 연산을 통해 결과를 통해 출력이미지를 도출해낸다\n",
    "# 필터의 개수... 가중치의 개수 를 결정하는 작업이므로, 중요하다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도형 data CNN modeling\n",
    "### 0. 진행 순서\n",
    "#### 1. 문제정의\n",
    "#### 2. 데이터수집\n",
    "#### 3. 모델생성\n",
    "#### 4. 학습 \n",
    "#### 5. 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문제 정의 \n",
    "# 다중분류에 해당한다 \n",
    "# 입력 : 3가지 도형 이미지 circle, rectangle, triangle\n",
    "# 출력 : 각 도형 확률 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential \n",
    "from keras.layers import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. 데이터 수집 (데이터부족 -> 데이터 생성)\n",
    "# 이미지 파일 학습과정에서 이미지 파일 생성 (증식) 이 가능하게해주는 함수 \n",
    "# ImageDataGenerator 가 제공(케라스제공)\n",
    "\n",
    "# preprocessing_image package_ImageDataGenerator\n",
    "# flow_from_directory func 을 통해 data 증식이 가능\n",
    "# flow_from_directory(image 경로(subclass 형태로 종식되어져있어야함__circle까지),\n",
    "#                    target size(행,렬) (이미지크기...현재 이미지 사이즈들 각기 다달라,\n",
    "#                                     )) \n",
    "# # 256,256\n",
    "\n",
    "# # keras API\n",
    "# # https://keras.io/preprocessing/image/#imagedatagenerator-methods\n",
    "\n",
    "# func(_, = , = ) = : default, _ : 필수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255) \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255) \n",
    "# 0 -1 사이로 자동표현되게하는 옵셔닝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_directory(\n",
    "'data/hand/handwriting_shape/train',\n",
    "    # 위에 있는 각각의 파일들에 대해서 \n",
    "    target_size = (24,24), \n",
    "    # 소괄호 ( ) : 튜플\n",
    "    class_mode = 'categorical', \n",
    "    # 3가지 = 범주형\n",
    "    # 대부분의 이미지 = categorical 자료형\n",
    "    # sparse : 밀집형, 벡터형태로 = 고차원으로 표현되어진 상태 [분류는 넓게한다]\n",
    "    # <=> dense : 밀집형, 1차원으로 늘려서 쭉 파악하고자할시 \n",
    "    batch_size = 3 \n",
    "    # train data = 15 / 3 = 1 epochs \n",
    "    # 몇개 씩 한번에 가져올래? # 보통 클래스의 개수 # 성능 = 모델링 처리 속도\n",
    ")\n",
    "# train_gen을 각각의 함수 옵셔닝을 통해 변환해준다  \n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "'data/hand/handwriting_shape/test',\n",
    "target_size = (24,24),     \n",
    "class_mode = 'categorical', \n",
    "batch_size = 3 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.directory_iterator.DirectoryIterator at 0x1c8f17bd358>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_gen)\n",
    "train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]]\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [0.6666667  0.6666667  0.6666667 ]\n",
      "   [0.07058824 0.07058824 0.07058824]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [0.9568628  0.9568628  0.9568628 ]\n",
      "   [0.23529413 0.23529413 0.23529413]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]]\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]]]\n",
      "==============================================\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "==============================================\n",
      "(3, 24, 24, 3)\n",
      "==============================================\n",
      "(3, 3)\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_gen:\n",
    "    print(x)\n",
    "    print('='*46)\n",
    "    print(y) # lable\n",
    "    print('='*46)\n",
    "    print(x.shape) # lable\n",
    "    print('='*46)\n",
    "    print(y.shape) # lable\n",
    "    print('='*46)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델생성\n",
    "#### 1. conv layer : 입력(24*24), 채널(3), 필터(3x3), 필터개수(32), 활성화(relu)\n",
    "#### 2. pooling : 크기 ( 2 * 2 )\n",
    "#### 3. flatten : 평탄화 (FCL_20개 => 3가지분류 weight : 60,  형성하기위한 작업 \n",
    "#### 4. dense : 출력 (128), 활성화(relu)\n",
    "#### 5. dense : 출력 (3), 활성화(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0820 13:33:08.319033  6556 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0820 13:33:08.337982  6556 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0820 13:33:08.340975  6556 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0820 13:33:08.368900  6556 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               819328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 839,107\n",
      "Trainable params: 839,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 전체 모델이름 (model ( 1-5 step))\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                activation='relu', # padding='SAME',\n",
    "                 input_shape=(24,24,3))) # (출력:필터 개수, 필터 크기, )\n",
    "# (valid = default) = > padding = 'SAME' \n",
    "# Conv2D 생성하여 모델에 추가하는 작업 완료 \n",
    "model.add(Conv2D(64,(3,3), activation='relu')) \n",
    "# 3차원 ... [24,24,32(depth)] => 입력으로 들어간다\n",
    "# 출력이 기본적으로 (3,3) * 3 이 (24,24) 에 해당하는 kernal * 3 \n",
    "# 합성곱이 더해진다 ..\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128,activation='relu')) \n",
    "model.add(Dense(3,activation='softmax')) \n",
    "model.summary()\n",
    "\n",
    "################################ 모델생성 완료 ######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 1.2438e-06 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9333\n",
      "Epoch 2/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 2.0133e-07 - acc: 1.0000 - val_loss: 0.0719 - val_acc: 0.9333\n",
      "Epoch 3/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 4.0389e-04 - val_acc: 1.0000\n",
      "Epoch 4/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 0.9333\n",
      "Epoch 5/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1444 - val_acc: 0.8667\n",
      "Epoch 6/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 0.9333\n",
      "Epoch 7/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 0.9333\n",
      "Epoch 8/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 6.1756e-04 - val_acc: 1.0000\n",
      "Epoch 9/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.8667\n",
      "Epoch 10/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 11/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0694 - val_acc: 0.9333\n",
      "Epoch 12/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9333\n",
      "Epoch 13/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 14/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n",
      "Epoch 15/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 16/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n",
      "Epoch 17/60\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0694 - val_acc: 0.9333\n",
      "Epoch 18/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9333\n",
      "Epoch 19/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 20/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 8.2798e-05 - val_acc: 1.0000\n",
      "Epoch 21/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.8667\n",
      "Epoch 22/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 23/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n",
      "Epoch 24/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 6.1774e-04 - val_acc: 1.0000\n",
      "Epoch 25/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 26/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n",
      "Epoch 27/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.8667\n",
      "Epoch 28/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.4929e-04 - val_acc: 1.0000\n",
      "Epoch 29/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9333\n",
      "Epoch 30/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.8667\n",
      "Epoch 31/60\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 4.1676e-04 - val_acc: 1.0000\n",
      "Epoch 32/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.8667\n",
      "Epoch 33/60\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 34/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n",
      "Epoch 35/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 3.5027e-04 - val_acc: 1.0000\n",
      "Epoch 36/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1388 - val_acc: 0.8667\n",
      "Epoch 37/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 38/60\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 5.6744e-04 - val_acc: 1.0000\n",
      "Epoch 39/60\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.8667\n",
      "Epoch 40/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 41/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0694 - val_acc: 0.9333\n",
      "Epoch 42/60\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9333\n",
      "Epoch 43/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n",
      "Epoch 44/60\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.6548e-04 - val_acc: 1.0000\n",
      "Epoch 45/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1393 - val_acc: 0.8667\n",
      "Epoch 46/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 47/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9333\n",
      "Epoch 48/60\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9333\n",
      "Epoch 49/60\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n",
      "Epoch 50/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0694 - val_acc: 0.9333\n",
      "Epoch 51/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 52/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 3.3408e-04 - val_acc: 1.0000\n",
      "Epoch 53/60\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1394 - val_acc: 0.8667\n",
      "Epoch 54/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n",
      "Epoch 55/60\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9333\n",
      "Epoch 56/60\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 2.8378e-04 - val_acc: 1.0000\n",
      "Epoch 57/60\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9333\n",
      "Epoch 58/60\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 0.8667\n",
      "Epoch 59/60\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 3.6646e-04 - val_acc: 1.0000\n",
      "Epoch 60/60\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8f1e6a208>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile 통하여,# cost, optimizer 등 정리할수 있따 \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics=['accuracy']\n",
    "             )\n",
    "# fit : keras model train func\n",
    "model.fit_generator(train_gen, steps_per_epoch=15, epochs=60, \n",
    "                   validation_data = test_gen,\n",
    "                   validation_steps = 5) \n",
    "\n",
    "#  3(abf) / 15 = > 45 = 1 epoches\n",
    "# validation_data = test_gen // 5개씨 \n",
    "# validation_step = test_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "scores= model.evaluate_generator(test_gen, steps= 5)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'circle': 0, 'rectangle': 1, 'triangle': 2}\n",
      "**********************************************\n",
      "[[0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.001 0.999]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.599 0.353 0.048]\n",
      " [0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000]]\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 클래스벡터로 표현 \n",
    "output = model.predict_generator(test_gen, steps = 5)\n",
    "np.set_printoptions(formatter = {'float':lambda x:\"{0:0.3f}\".format(x)})# 출력형식지정\n",
    "\n",
    "print(test_gen.class_indices) # 데이터 자체가 명확하다\n",
    "print('*'* 46)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generator 사용용도\n",
    "# 1. 이미지 스케일링\n",
    "# 2. (이미지)데이터 증식\n",
    "\n",
    "from keras.preprocessing.image \\\n",
    "import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug_gen = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=[0.8, 1.2], # 원본이미지 80 - 120 %\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    shear_range=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=24x24 at 0x1C8F1E80B38>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_img('data/hand/handwriting_shape/train/triangle/triangle007.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 24, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = img_to_array(img) \n",
    "# 변환 해야할 데이터 x : (24,24,3)\n",
    "x = x.reshape((1,)+x.shape)\n",
    "np.shape(x) # (None,24,24,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가짜 이미지 50개 생성\n",
    "# train data (train_gen)\n",
    "i = 0\n",
    "for data in data_aug_gen.flow(x, batch_size = 1, save_to_dir='data/hand',\n",
    "                               save_format = 'png', save_prefix='sample'):\n",
    "    i += 1\n",
    "    if i > 50:\n",
    "        break\n",
    "    # data 생성 # 어디에 저장할지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
