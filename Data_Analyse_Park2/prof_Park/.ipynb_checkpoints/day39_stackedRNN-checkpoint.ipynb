{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day39\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='gruvboxd', context='paper', spines=True, \n",
    "             ticks=True, grid=True, gridlines='dotted', figsize=(6,4.5))\n",
    "# fit : 모델 학습 \n",
    "#     model.fit(x, y, batch_size = 1, epochs = 10)\n",
    "#     문제 x = 100, 정답 y = 100, epochs = 100 문제를 1.2. ... 10 번 푸는것\n",
    "#     model.fit(validation_data = (xval, yval))\n",
    "#     hist.history['loss'] = cost 함수,['acc']['val_loss']['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Tensor dense_13_input:0, specified in either feed_devices or fetch_devices was not found in the Graph",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-ade5735f97dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#조기 종료 콜백함수 객체\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;31m# 모델불러올때마다 호출되는 callbacks = [es]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2671\u001b[1;33m                                 session)\n\u001b[0m\u001b[0;32m   2672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[1;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[0;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2622\u001b[0m         \u001b[1;31m# Create callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2623\u001b[1;33m         \u001b[0mcallable_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2624\u001b[0m         \u001b[1;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2625\u001b[0m         \u001b[1;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[1;34m(self, callable_options)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     \"\"\"\n\u001b[0;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session, callable_options)\u001b[0m\n\u001b[0;32m   1444\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[1;32m-> 1446\u001b[1;33m             session._session, options_ptr)\n\u001b[0m\u001b[0;32m   1447\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Tensor dense_13_input:0, specified in either feed_devices or fetch_devices was not found in the Graph"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "\n",
    "# 훈련셋과 시험셋 로딩\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "from keras.callbacks import EarlyStopping\n",
    "es=EarlyStopping(patience=20) #조기 종료 콜백함수 객체\n",
    "hist = model.fit(X_train, Y_train,callbacks=[es], epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
    "# 모델불러올때마다 호출되는 callbacks = [es]\n",
    "\n",
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=(\"The regret after not doing something is bigger than that of doing something \"\n",
    "          \"Ability is decided by one's own effort \"\n",
    "          \"The difficulty in life is the choice.\")\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d': 0,\n",
       " 'a': 1,\n",
       " 'r': 2,\n",
       " 'n': 3,\n",
       " 'u': 4,\n",
       " '.': 5,\n",
       " 'T': 6,\n",
       " 'l': 7,\n",
       " ' ': 8,\n",
       " 'h': 9,\n",
       " 'A': 10,\n",
       " 's': 11,\n",
       " 'g': 12,\n",
       " 'y': 13,\n",
       " 'e': 14,\n",
       " 'f': 15,\n",
       " 'b': 16,\n",
       " 'w': 17,\n",
       " 'm': 18,\n",
       " 'o': 19,\n",
       " 'i': 20,\n",
       " \"'\": 21,\n",
       " 'c': 22,\n",
       " 't': 23}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charSet=list(set(sentence))\n",
    "charDic={w:i for i, w in enumerate(charSet)}\n",
    "charDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim=len(charDic) #input_dim = 24차원\n",
    "num_classes=hidden_size=data_dim\n",
    "sequence_length=10\n",
    "learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot:0\", shape=(?, 10, 24), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "datax=[]\n",
    "datay=[]\n",
    "#len(sentence) # 글자수 152\n",
    "for i in range(0, len(sentence)-sequence_length): #(0,152-10)=>(0,142)\n",
    "    xstr=sentence[i:i+sequence_length] #1~10\n",
    "    ystr=sentence[i+1:i+sequence_length+1] #2~11\n",
    "    #print(i, xstr, '->', ystr)\n",
    "    x=[charDic[c] for c in xstr]\n",
    "    y=[charDic[c] for c in ystr]\n",
    "#     print(x)\n",
    "#     print(y)\n",
    "    datax.append(x)\n",
    "    datay.append(y)\n",
    "batch_size=len(datax) #142\n",
    "\n",
    "x=tf.placeholder(tf.int32, [None, sequence_length])\n",
    "y=tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "x_one_hot=tf.one_hot(x, num_classes)\n",
    "print(x_one_hot)\n",
    "\n",
    "def lstm_cell():\n",
    "    cell=rnn.BasicLSTMCell(hidden_size)\n",
    "    return cell\n",
    "multi_cells=rnn.MultiRNNCell([lstm_cell() for _ in range(2)])\n",
    "outputs, _states=tf.nn.dynamic_rnn(multi_cells,x_one_hot, dtype=tf.float32)\n",
    "\n",
    "xforfc=tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs=tf.contrib.layers.fully_connected(xforfc, num_classes, activation_fn=None)\n",
    "outputs=tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "weights=tf.ones([batch_size, sequence_length])\n",
    "sequence_loss=tf.contrib.seq2seq.sequence_loss(\n",
    "logits=outputs, targets=y, weights=weights)\n",
    "meanLoss=tf.reduce_mean(sequence_loss)\n",
    "train=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(meanLoss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he regret  after not doing something is bigger than that of doing something ibility is decided by one's own effort The difficulty in life is the choice."
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(500):\n",
    "    _, cv, res=sess.run([train, meanLoss, outputs], feed_dict={x:datax, y:datay})\n",
    "    for j,result in enumerate(res):\n",
    "        index=np.argmax(result, axis=1)\n",
    "        #print(i,j,''.join([charSet[t] for t in index]), cv)\n",
    "\n",
    "res=sess.run(outputs, feed_dict={x:datax})        \n",
    "#print(res)\n",
    "for j, result in enumerate(res):    \n",
    "    index=np.argmax(result, 1)\n",
    "    if j is 0:\n",
    "        print(''.join([charSet[t] for t in index]), end='')\n",
    "    \n",
    "    print(charSet[index[-1]],end='')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 클래스\n",
    "# ## keras - Layer \n",
    "# Dense : 모든입력. 모든출력을 연결\n",
    "#     fully Connected\n",
    "# Sequential\n",
    "# model = sequential()\n",
    "# model.add(Dense(64, input_dim=1)) # 64계층을 지닌 dense 계층\n",
    "# Dense(1) # 하나의 값을 도출한다 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6      ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8     spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9     spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "10     ham  I'm gonna be home soon and i don't want to tal...        NaN   \n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...        NaN   \n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...        NaN   \n",
       "13     ham  I've been searching for the right words to tha...        NaN   \n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!        NaN   \n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...        NaN   \n",
       "16     ham                         Oh k...i'm watching here:)        NaN   \n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...        NaN   \n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...        NaN   \n",
       "19    spam  England v Macedonia - dont miss the goals/team...        NaN   \n",
       "20     ham          Is that seriously how you spell his name?        NaN   \n",
       "21     ham  IÛ÷m going to try for 2 months ha ha only joking        NaN   \n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...        NaN   \n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...        NaN   \n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...        NaN   \n",
       "25     ham  Just forced myself to eat a slice. I'm really ...        NaN   \n",
       "26     ham                     Lol your always so convincing.        NaN   \n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...        NaN   \n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...        NaN   \n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5542   ham           Armand says get your ass over to epsilon        NaN   \n",
       "5543   ham             U still havent got urself a jacket ah?        NaN   \n",
       "5544   ham  I'm taking derek &amp; taylor to walmart, if I...        NaN   \n",
       "5545   ham      Hi its in durban are you still on this number        NaN   \n",
       "5546   ham         Ic. There are a lotta childporn cars then.        NaN   \n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...        NaN   \n",
       "5548   ham                 No, I was trying it all weekend ;V        NaN   \n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...        NaN   \n",
       "5550   ham        Cool, what time you think you can get here?        NaN   \n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...        NaN   \n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...        NaN   \n",
       "5553   ham                        Hahaha..use your brain dear        NaN   \n",
       "5554   ham  Well keep in mind I've only got enough gas for...        NaN   \n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...        NaN   \n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...        NaN   \n",
       "5557   ham  No. I meant the calculation is the same. That ...        NaN   \n",
       "5558   ham                             Sorry, I'll call later        NaN   \n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...        NaN   \n",
       "5560   ham                  Anything lor. Juz both of us lor.        NaN   \n",
       "5561   ham  Get me out of this dump heap. My mom decided t...        NaN   \n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...        NaN   \n",
       "5563   ham                                Ard 6 like dat lor.        NaN   \n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...        NaN   \n",
       "5565   ham                                       Huh y lei...        NaN   \n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...        NaN   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "5           NaN        NaN  \n",
       "6           NaN        NaN  \n",
       "7           NaN        NaN  \n",
       "8           NaN        NaN  \n",
       "9           NaN        NaN  \n",
       "10          NaN        NaN  \n",
       "11          NaN        NaN  \n",
       "12          NaN        NaN  \n",
       "13          NaN        NaN  \n",
       "14          NaN        NaN  \n",
       "15          NaN        NaN  \n",
       "16          NaN        NaN  \n",
       "17          NaN        NaN  \n",
       "18          NaN        NaN  \n",
       "19          NaN        NaN  \n",
       "20          NaN        NaN  \n",
       "21          NaN        NaN  \n",
       "22          NaN        NaN  \n",
       "23          NaN        NaN  \n",
       "24          NaN        NaN  \n",
       "25          NaN        NaN  \n",
       "26          NaN        NaN  \n",
       "27          NaN        NaN  \n",
       "28          NaN        NaN  \n",
       "29          NaN        NaN  \n",
       "...         ...        ...  \n",
       "5542        NaN        NaN  \n",
       "5543        NaN        NaN  \n",
       "5544        NaN        NaN  \n",
       "5545        NaN        NaN  \n",
       "5546        NaN        NaN  \n",
       "5547        NaN        NaN  \n",
       "5548        NaN        NaN  \n",
       "5549        NaN        NaN  \n",
       "5550        NaN        NaN  \n",
       "5551        NaN        NaN  \n",
       "5552        NaN        NaN  \n",
       "5553        NaN        NaN  \n",
       "5554        NaN        NaN  \n",
       "5555        NaN        NaN  \n",
       "5556        NaN        NaN  \n",
       "5557        NaN        NaN  \n",
       "5558        NaN        NaN  \n",
       "5559        NaN        NaN  \n",
       "5560        NaN        NaN  \n",
       "5561        NaN        NaN  \n",
       "5562        NaN        NaN  \n",
       "5563        NaN        NaN  \n",
       "5564        NaN        NaN  \n",
       "5565        NaN        NaN  \n",
       "5566        NaN        NaN  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"spam.csv\", encoding='latin1') # decoding 불가시\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      "v1            5572 non-null object\n",
      "v2            5572 non-null object\n",
      "Unnamed: 2    50 non-null object\n",
      "Unnamed: 3    12 non-null object\n",
      "Unnamed: 4    6 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.head()\n",
    "## Unnamed 열 인덱스 제거 \n",
    "data.info()\n",
    "del data['Unnamed: 2']\n",
    "del data['Unnamed: 3']\n",
    "del data['Unnamed: 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN ___ 0 OR 1 로 output 나와야함\n",
    "# earlyStopping  #overfitting 방지   함수\n",
    "# data.info()\n",
    "# ham => 0 \n",
    "# spam => 1\n",
    "# data\n",
    "y = pd.get_dummies(data,'v1')\n",
    "x = data.v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a712e7a390>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "data['v1'].value_counts().plot(kind='bar')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=x\n",
    "ydata=y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문장을 단어 단위로 토큰화\n",
    "# 2. 단어 토큰 - 정수로 인코딩 \n",
    "# ohe 차원의 개수.. 단어의 개수 ... 셀의 길이 가 다다르므로, padding(앞쪽에)놓자\n",
    "# keras - 0,1 => 1 개 (RNN)\n",
    "# 모든셀마다 출력되는게 아니고, 출력되는것은 0,1 인 하나만 출력됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(xdata) # 각행에 대한 토큰화 수행\n",
    "word_index = tokenizer.word_index # 각행에대한 단어에 인덱스부여 # 딕셔너리 형태\n",
    "# 인덱스에 0 번이 없다 \n",
    "# 중복은없다 \n",
    "sequences = tokenizer.texts_to_sequences(xdata) \n",
    "# 원본데이터에 있는걸 딕셔너리 word_index를기반으로, 정수로 저장 \n",
    "# xdata = 단어의 인덱스를 토대로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]\n",
    "\n",
    "len(sequences)\n",
    "trainData = int(len(sequences)*0.8)\n",
    "testData = int(len(sequences)-trainData)\n",
    "trainData # 4457\n",
    "testData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.794867193108399"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메일의 최대길이 출력(xdata)\n",
    "max(len(d) for d in sequences)\n",
    "# 메일의 평균 길이 \n",
    "sum(map(len, sequences)) / len(sequences) # 15,79\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xdata = sequences\n",
    "plt.hist([len(s) for s in xdata], bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 메일의 길이 : 189\n",
    "# 50 미만이 대부분(업데이트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import * \n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8921"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word_index) + 1\n",
    "# 8920 + 1 => 8921\n",
    "vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 189)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터셋의 길이를 189로 통일\n",
    "max_len = 189\n",
    "data = pad_sequences(xdata, maxlen = max_len) # pre padding\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = data[trainData:]   # 뒤쪽 1115개\n",
    "ytest = ydata[trainData:]\n",
    "\n",
    "xtrain = data[:trainData]  # 앞쪽 4457개\n",
    "ytrain = ydata[:trainData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (1,) but got array with shape (5171,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-1f4aa4098a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (1,) but got array with shape (5171,)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(xtrain, ytrain, epochs=5, batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (1,) but got array with shape (5171,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-b94e7809d62b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1102\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (1,) but got array with shape (5171,)"
     ]
    }
   ],
   "source": [
    "cost, acc = model.evaluate(xtest, ytest)\n",
    "print(cost, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history['acc']+1))\n",
    "plt.plot(epochs, history.history['loss'])\n",
    "plt.plot(epochs, history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
