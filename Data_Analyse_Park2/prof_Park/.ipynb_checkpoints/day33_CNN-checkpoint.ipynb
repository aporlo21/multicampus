{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# day33_CNN\n",
    "## 오전수업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 11:22:51.999725 10072 deprecation.py:323] From <ipython-input-7-40862fbacaaa>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0819 11:22:52.002717 10072 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0819 11:22:52.034631 10072 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "W0819 11:22:52.822762 10072 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 11:22:53.368514 10072 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0819 11:22:53.371507 10072 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 11:22:54.100965 10072 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# question mnist data 를 RNN 모델로 구현이 가능한가? \n",
    "# 과거 현재 미래.. 순서에 따라 이미지를 인식하겠다 \n",
    "# ex) 글씨 쓸 때, 위 -> 아래 좌 -> 우 \n",
    "# 위, 아래 데이터간의 연속성이있다\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "# mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1]) \n",
    "# xdata # 흑백 , 4차원\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 순서\n",
    "# conv2d\n",
    "# relu\n",
    "# maxpooling \n",
    "\n",
    "# 첫번째 계층의 Weight 부여\n",
    "w1 = tf.Variable(tf.random_normal([3,3,1,32])) # kernal OR filter = 3 x 3, 1, 32\n",
    "# [ 3,3 ] : 필터 OR KERNAL 의 개수 ... 1 : 채널 특성 ( 흑백 )  필터의 개수 32\n",
    "# => 32개의 특성가지고 합성곱 연산하겠다 \n",
    "\n",
    "# 한칸씩 한칸씩 이동시키는 conv layer를 생성하자\n",
    "L1 = tf.nn.conv2d(x, w1, strides=[1,1,1,1], padding = 'SAME') # stride시 외곽부분때문\n",
    "# 옵션은 stride [ 1,칸, 줄, 1] (슬라이드하는것과 관련된 옵션, \n",
    "# 양쪽 끝은 고정시키고, 이동하는 간격을 조정, 설정해주는 옵션 ) \n",
    "# OR padding (외곽 한칸씩 증식, shape 유지 된다 \n",
    "\n",
    "# pooling maxpooling 필수적인 작업아니고 상황에 맞게 조정\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME') \n",
    "# 14,14 가 되는데\n",
    "# 15,15일때, 2,2로풀링 하려할때 맞춰주기위해 하는 작업  \n",
    "# 짝수 일때 \n",
    "\n",
    "# kernal size = [1,2,2,1] # 2x2 짜리를 다음 것에 대해서 max pooling 하면 지나가겠다\n",
    "# ksize 커질수록, 성능 : 2x2 > 4x4 적은 영역에 대한 대표값,,, 정확도 떨어져\n",
    "\n",
    "# 결과정리)\n",
    "# W1 : [3, 3, 1, 32] # 필터 사이즈 3,3, 32개 - (L1) -> Conv [None,28,28,32]\n",
    "# L1 : CONV -> shape () \n",
    "# x이미지가 (NONE), 28x28, (1) \n",
    "# [None,28,28,32]\n",
    "# pooling  = (shape) : [None,14,14,32] 2x2가 이동한다 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.Variable(tf.random_normal([3,3,32,64])) # kernal OR filter = 3 x 3, 1, 32\n",
    "# 출력을 64개로 하고 싶다 # 채널 1 -> 32(이전 계층 출력 특성),,, 필터링 개수 64\n",
    "L2 = tf.nn.conv2d(L1, w2, strides=[1,1,1,1], padding = 'SAME') \n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "# L2 CONV => [None, 14,14, 64]\n",
    "# pooling = > [None,7,7,64]\n",
    "\n",
    "# FC 계층 ㅣ 입력 7*7*64 -> 출력 NOibem 256 [-> 차원을줄인다 (reshaping)] \n",
    "w3 = tf.Variable(tf.random_normal([7*7*64, 256]))\n",
    "L3 = tf.reshape(L2, [-1, 7*7*64]) # 1차원 flatten\n",
    "# matrix 합성곱 ( L3 W3 )\n",
    "L3 = tf.matmul(L3, w3) # 수치로 표현되어진 상태 # [-1, 256]\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob) # keep_prob : 반영률\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([256,10]))\n",
    "model = tf.matmul(L3, w4) \n",
    "# softmax 함수 통해 cost func 낮아지는 방향으로 updating 재변화\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model, \n",
    "                                                               labels = y)) \n",
    "# y = 10 \n",
    "optimizer=tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "# optima = * asterisk : (최적화값)\n",
    "# softmax 들어가기전 score 값을 넘겨줘야한다,,,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오후 수업 : ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "batch_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100, 784) for Tensor 'Placeholder_3:0', which has shape '(?, 28, 28, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-83c314ddd80b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 feed_dict = {x:batch_xs,\n\u001b[0;32m     12\u001b[0m                             \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                             keep_prob:0.7})\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mtotal_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# 60,000 개 의 샘플 = 100(batch size) * 600 (total batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1149\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1150\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (100, 784) for Tensor 'Placeholder_3:0', which has shape '(?, 28, 28, 1)'"
     ]
    }
   ],
   "source": [
    "total_batch = mnist.train.num_examples/batch_size\n",
    "# total_batch = total_batch.astype('int')\n",
    "\n",
    "for epoch in range(15):\n",
    "    # cost 구하는 작업 \n",
    "    total_cost = 0 # 초기화\n",
    "    for i in range(int(total_batch)): # 600번 ( 1에폭 )\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs.reshape(-1, 28, 28, 1)\n",
    "        _, cv = sess.run([optimizer, cost],\n",
    "                feed_dict = {x:batch_xs,\n",
    "                            y:batch_ys,\n",
    "                            keep_prob:0.7})\n",
    "        total_cost += cv\n",
    "        # 60,000 개 의 샘플 = 100(batch size) * 600 (total batch) \n",
    "        # 한번 할때 마다 total_cost에는 batch size가 들어가게됨 \n",
    "        # cost = 괄호안 구문 = 예측값 - 실제값 softmax을 통해 도출되는 cost 실행해서 \n",
    "        # cv 나온다 (100) 한번 트레이닝 할때마다 100 개 씩 한다 \n",
    "        # 1 - 100 번째 이미지 까지 그에 대한 CV 도출된다  CV ; 합이 저장됨\n",
    "        # TOTAL_COST / TOTAL_BATCH = 전체 평균 도출\n",
    "    print('에폭:', '%d' % ( epoch+1 ),\n",
    "         '평균 cost:',''.format(total_cost/total_batch))\n",
    "print('모델 생성됨')\n",
    "# 15에폭 다돌고난뒤에 모델생성완료\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model,1),tf.argmax(y,1))\n",
    "# 정확도(노드정의 accuracy)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct.tf.float32))\n",
    "# is_correct : true OR false\n",
    "print('정확도:', sess.run(accuracy, feed_dict={x:mnist.test.images.reshape(-1,28,28,1),\n",
    "                                           y:mnist.test.labels,\n",
    "                                           keep_prob:1}))\n",
    "# model : ([None, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor - layer 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers subpackage 활용한 cnn modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None, 28,28,1])\n",
    "y=tf.placeholder(tf.float32,[None, 10])\n",
    "# layer사용하면 코딩이 간결해진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-b1ddccd65262>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-39-b1ddccd65262>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    cost = tf.reduce_mean(tf.nn.softmax_crosss_entropy_with logits_v2(logits = model,\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "L1 = tf.layers.conv2d(x, 32, [3,3], activation=tf.nn.relu) # keras와 비슷, 출력 몇개할래\n",
    "L1 = tf.layers.max_pooling2d(L1,[2,2],[2,2])\n",
    "L1 = tf.layers.dropout(L1,0.7)\n",
    "\n",
    "L2 = tf.layers.conv2d(L1, 64, [3,3], activation=tf.nn.relu) # keras와 비슷, 출력 몇개할래\n",
    "L2 = tf.layers.max_pooling2d(L2,[2,2],[2,2])\n",
    "L2 = tf.layers.dropout(L2, 0.7)\n",
    "\n",
    "L3 = tf.contrib.layers.flatten(L2) # keras와 비슷, 출력 몇개할래3\n",
    "L3 = tf.layers.dense(L3,256,activation=tf.nn.relu)\n",
    "L3 = tf.layers.dropout(L1,0.)\n",
    "\n",
    "model =tf.layers.dense(L3, 10, activation =None)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_crosss_entropy_with logits_v2(logits = model, \n",
    "                                                               labels = y)) \n",
    "                      \n",
    "optimizer=tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keras 에서 mnist \n",
    "from keras import layers\n",
    "\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 14:59:18.709102 10072 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 14:59:18.711099 10072 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 14:59:18.713165 10072 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0819 14:59:18.713165 10072 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=( 28,28,1 )))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "\n",
    "model.summary()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "=================================================================\n",
      "Total params: 92,672\n",
      "Trainable params: 92,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.summary()\n",
    "\n",
    "model.add(layers.Dense(64,activation = 'relu'))\n",
    "model.summary()\n",
    "\n",
    "model.add(layers.Dense(10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(train_images, train_labels), (test_images, test_labels)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape\n",
    "train_images = train_images.reshape((60000,28,28,1))\n",
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.reshape((10000,28,28,1))\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape\n",
    "test_labels.shape \n",
    "# ohe 안되있는 상태\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 15:08:38.022243 10072 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0819 15:08:38.120956 10072 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 31s 515us/step - loss: 0.1723 - acc: 0.9463\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 30s 493us/step - loss: 0.0464 - acc: 0.9859\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 30s 495us/step - loss: 0.0319 - acc: 0.9900\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 30s 494us/step - loss: 0.0252 - acc: 0.9921\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.0195 - acc: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f63f753518>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs= 5, batch_size=64)\n",
    "# evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 152us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9891"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dogs vs cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_origin = os.path.join('.', 'hojin')\n",
    "\n",
    "string = '.\\\\hojin'\n",
    "\n",
    "dir_origin == string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터셋을 압축 해제한 디렉터리 경로\n",
    "original_dataset_dir = 'C:/Users/user/Desktop/data/dogs-vs-cats/train/train'\n",
    "\n",
    "# 소규모 데이터셋을 저장할 디렉터리\n",
    "base_dir = 'dogs-vs-cats/cats_and_dogs_small'\n",
    "\n",
    "if os.path.exists(base_dir):  # 반복적인 실행을 위해 디렉토리를 삭제합니다.\n",
    "    shutil.rmtree(base_dir)   # 이 코드는 책에 포함되어 있지 않습니다.\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# 훈련, 검증, 테스트 분할을 위한 디렉터리\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# 훈련용 고양이 사진 디렉터리\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "# 훈련용 강아지 사진 디렉터리\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "# 검증용 고양이 사진 디렉터리\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "# 검증용 강아지 사진 디렉터리\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# 테스트용 고양이 사진 디렉터리\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "\n",
    "# 테스트용 강아지 사진 디렉터리\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "# 처음 1,000개의 고양이 이미지를 train_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 다음 500개 고양이 이미지를 validation_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 고양이 이미지를 test_cats_dir에 복사합니다\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 처음 1,000개의 강아지 이미지를 train_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 강아지 이미지를 validation_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# 다음 500개 강아지 이미지를 test_dogs_dir에 복사합니다\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(train_cats_dir))\n",
    "# training 고양이, 강아지 각각 1000개 \n",
    "# 고양이, 강아지 분류기 제작\n",
    "\n",
    "# 준비완료\n",
    "\n",
    "# 연관규칙 ( apriori Algorithm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
