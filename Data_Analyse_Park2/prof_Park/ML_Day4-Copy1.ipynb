{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086526/remove-specific-brackets-from-string\n",
      "Remove specific brackets from string\n",
      "\n",
      "\n",
      "I have a list of say (UH[0], UH[1], UH[2], UH[3].... )\n",
      "I want to use re.sub to remove everything from each element of the list except the number so that it is (0 , 1 , 2 , 3 .....)\n",
      "I tried with re.sub ('[UH^[]]' ,'', each_element) but it doesn't work\n",
      "\n",
      "Answer\n",
      "\n",
      "You can try to replace them like\n",
      "In [1]: x = \"UH[0], UH[1], UH[2], UH[3]\"\n",
      "\n",
      "In [2]: result = x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"UH\", \"\")\n",
      "\n",
      "In [3]: result\n",
      "Out[3]: '0, 1, 2, 3'\n",
      "\n",
      "Hope it helps.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086522/how-to-convert-a-variable-name-to-string-name-in-python\n",
      "How to convert a variable name to string name in python?\n",
      "\n",
      "\n",
      "For example, we have the scores of three courses stored in LIST.\n",
      "English, Maths, Physics = 89, 92, 93\n",
      "LIST = [English, Maths, Physics]\n",
      "for i in range(len(LIST)):\n",
      "    print(LIST[i])\n",
      "\n",
      "And I want the print style to be like English, 89, Maths, 92, Physics, 93. Here is a solution that defines another list LIST_name\n",
      "English, Maths, Physics = 89, 92, 93\n",
      "LIST = [English, Maths, Physics]\n",
      "LIST_name = ['English', 'Maths', 'Physics']\n",
      "for i in range(len(LIST)):\n",
      "    print(LIST_name[i], LIST[i])\n",
      "\n",
      "I am wondering if there is a built-in function or some other tricks that can help me directly convert English to \"English\", without defining LIST_name? And if so, how?\n",
      "\n",
      "Answer\n",
      "\n",
      "You can have a method that takes variable keyword args as input and gives you dict with key value pair\n",
      " def marks(**m):\n",
      "  return m\n",
      "\n",
      " d=marks(English=90,Maths=100,Physics=90)  #call method with keyword args\n",
      " print(d)\n",
      "\n",
      "Output :\n",
      "   {'English': 90, 'Maths': 100, 'Physics': 90}\n",
      "An inefficient way would be:\n",
      "English, Maths, Physics = 89, 92, 93\n",
      "LIST = [English, Maths, Physics]\n",
      "for i in LIST:\n",
      "    print(next((k for k, v in globals().items() if v == i)), i)\n",
      "\n",
      "Output:\n",
      "English 89\n",
      "Maths 92\n",
      "Physics 93\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086495/runtime-error-element-0-of-tensors-does-not-require-grad-and-does-not-have-a\n",
      "[RUNTIME ERROR]: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "\n",
      "I’m working on a classification problem. I’m trying to classify URLs as malicious or benign. I’m implementing logistic regression for this problem, and here is my code:\n",
      "import torch\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import torch.nn as nn\n",
      "import torch.utils.data\n",
      "from torch.autograd import Variable\n",
      "\n",
      "class LogisticRegressionModel(nn.Module):\n",
      "\n",
      "    def __init__(self, in_dim, num_classes):\n",
      "        super().__init__()\n",
      "        self.linear = nn.Linear(in_dim, num_classes)\n",
      "\n",
      "    def forward(self, x):\n",
      "        out = self.linear(x)\n",
      "        return out\n",
      "\n",
      "class Train(LogisticRegressionModel):\n",
      "\n",
      "\n",
      "    def __init__(self, in_dim, num_classes, lr, batch_size):\n",
      "        super().__init__(in_dim, num_classes)\n",
      "        self.batch_size = batch_size\n",
      "        self.learning_rate = lr\n",
      "        self.input_layer_dim = in_dim\n",
      "        self.output_layer_dim = num_classes\n",
      "        self.criterion = nn.CrossEntropyLoss()\n",
      "        self.model = LogisticRegressionModel(self.input_layer_dim, self.output_layer_dim)\n",
      "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "        self.model = self.model.to(self.device)\n",
      "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr = self.learning_rate)  \n",
      "\n",
      "    def epochs(self, iterations, train_dataset, batch_size):\n",
      "        epochs = int(iterations/(len(train_dataset)/batch_size))\n",
      "        return epochs\n",
      "\n",
      "    def train_model(self, training_data, n_iters):\n",
      "        batch = self.batch_size\n",
      "        epochs = self.epochs(n_iters, training_data, batch)\n",
      "        training_data = torch.utils.data.DataLoader(dataset = training_data, batch_size = batch, shuffle = False)\n",
      "\n",
      "        for epoch in range(epochs):\n",
      "            for i, data in enumerate(training_data):\n",
      "\n",
      "                X_train = data[:, :-1]\n",
      "                Y_train = data[:, -1]\n",
      "\n",
      "                if torch.cuda.is_available():\n",
      "                    x = Variable(X_train).cuda()\n",
      "                    y = Variable(Y_train).cuda()\n",
      "\n",
      "                else:\n",
      "                    x = X_train.float()\n",
      "                    y = Y_train.type(torch.LongTensor)\n",
      "\n",
      "                self.optimizer.zero_grad()\n",
      "                out = self.model(x).data\n",
      "                loss = self.criterion(out, y)\n",
      "                loss.backward()\n",
      "                self.optimizer.step()\n",
      "\n",
      "batch_size = 5000\n",
      "train_class = Train((training_set.shape[1]-1), number_of_target_labels+1, 0.001, batch_size)\n",
      "rain_class.train_model(training_set, batch_size)\n",
      "\n",
      "However, I get the following error when I run this code block:\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      "I don't know why that is the case. If you'd like to have a look at my Notebook and the dataset, here is the link to it: https://github.com/islamaymansais/Malicious-URL-Classifier\n",
      "This is a classification project to classify URLs as benign or a malicious category (phishing, defacement, spam, malware). Let me know if you have any questions that I can clarify.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086486/accessing-the-list-of-list-specific-number-elements-and-merging-using-python\n",
      "Accessing the list of list specific number elements and merging using python\n",
      "\n",
      "\n",
      "I have a list of list elements in that i have to access specific number elements and merge them using python code.\n",
      "I have tried using list Comprehension but it is not working.\n",
      "myList = [['a:', 'b:', '4,80', 'c:', 'b:', '5,00', ':', '4,91', 'Pass'], ['a:', 'b:', '1,45', 'c:', 'b:', '1,55', 'd:', '1,51', 'Pass'], ['a:', 'b:', '-1,15', 'a:', 'b:', '-0,95', 'c:', '-1,07', 'Pass']]\n",
      "test = [myList [i] for i in [2,5,7]]\n",
      "            str1 = ''.join(test)\n",
      "            remove = int(str1.replace(',',''))\n",
      "            add_commas= \"{:,}\".format(remove)\n",
      "            conv_list = add_commas.split(',')\n",
      "            ac,ll,ut = conv_list[0],conv_list[1],conv_list[2]\n",
      "            print(ac,ll,ut)\n",
      "\n",
      "The expected output should be:\n",
      "[[480,500,491],[145,155,151],[-115,-095,-107]]\n",
      "\n",
      "Answer\n",
      "\n",
      "If you gather up just the characters you want, then you can return them with a function like:\n",
      "GOOD_CHARS = set('0123456789-+')\n",
      "\n",
      "def to_number(num_str):\n",
      "    return ''.join(c for c in num_str if c in GOOD_CHARS)\n",
      "\n",
      "Then if you drop any empty strings you will get what you are after.\n",
      "Test Code:\n",
      "my_list = [['a:', 'b:', '4,80', 'c:', 'b:', '5,00', ':', '4,91', 'Pass'],\n",
      "          ['a:', 'b:', '1,45', 'c:', 'b:', '1,55', 'd:', '1,51', 'Pass'],\n",
      "          ['a:', 'b:', '-1,15', 'a:', 'b:', '-0,95', 'c:', '-1,07', 'Pass']]\n",
      "\n",
      "print([[int(to_number(x)) for x in row if to_number(x)] for row in my_list])\n",
      "\n",
      "Results:\n",
      "[[480, 500, 491], [145, 155, 151], [-115, -95, -107]]\n",
      "Use isdigit() string method to check for number and then do int() to convert it to number\n",
      "In [1]: myList = [['a:', 'b:', '4,80', 'c:', 'b:', '5,00', ':', '4,91', 'Pass'], ['a:', 'b\n",
      "   ...: :', '1,45', 'c:', 'b:', '1,55', 'd:', '1,51', 'Pass'], ['a:', 'b:', '-1,15', 'a:',\n",
      "   ...:  'b:', '-0,95', 'c:', '-1,07', 'Pass']]\n",
      "In [2]: out = [[int(j.replace(',', '')) for j in i if j.replace(',', '').isdigit()] for i\n",
      "...:  in myList]\n",
      "\n",
      "In [3]: out \n",
      "Out[3]: [[480, 500, 491], [145, 155, 151], []]\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086454/removing-non-alphanumeric-unicode-characters-from-a-string-in-python\n",
      "Removing non-alphanumeric unicode characters from a string in Python\n",
      "\n",
      "\n",
      "How do I convert this string:\n",
      "\"\\xa0かかわらず\"\n",
      "\n",
      "to this string?:\n",
      "\"かかわらず\"\n",
      "\n",
      "i.e. How do I remove non-alphanumeric unicode characters? I've tried the solution that encodes the string as ascii, but it doesn't work for Japanese symbols.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086451/kivy-need-for-unschedule-for-event-created-using-clock-schedule-once\n",
      "Kivy - Need for unschedule for event created using Clock.schedule_once\n",
      "\n",
      "\n",
      "I am beginning to learn kivy and was just reading the documentation on events but I am unable to understand a certain part of it. \n",
      "Background\n",
      "The doc says to use Clock.schedule_once(callback,X) to execute callback after X seconds. However if X is 0, it will execute callback after the next frame.\n",
      "My Confusion\n",
      "Now the doc follows to say:\n",
      "\n",
      "Sometimes you may want to schedule a function to be called only once for the next frame, preventing duplicate calls.\n",
      "\n",
      "And advices NOT to do the following -\n",
      "# First, schedule once.\n",
      "event = Clock.schedule_once(my_callback, 0)\n",
      "\n",
      "# Then, in another place you will have to unschedule first\n",
      "# to avoid duplicate call. Then you can schedule again.\n",
      "Clock.unschedule(event)\n",
      "event = Clock.schedule_once(my_callback, 0)\n",
      "\n",
      "But instead use a trigger -\n",
      "trigger = Clock.create_trigger(my_callback)\n",
      "# later\n",
      "trigger()\n",
      "\n",
      "\n",
      "Each time you call trigger(), it will schedule a single call of your callback. If it was already scheduled, it will not be rescheduled.\n",
      "\n",
      "My confusion is why does the first method not work? Isn't the method schedule_once() to execute the callback exactly once? Why is there a possibility of duplicate as mentioned in the first approach?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086447/working-with-classes-and-setters-and-gettors\n",
      "Working with classes and setters and gettors\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to Create a class called Color.  \n",
      "\n",
      "Code 1 constructor\n",
      "That requires 2 parameters  \n",
      "Code 2 properties\n",
      "1 property is public\n",
      "1 property is private\n",
      "Create an accessor and setter for the 1 private property\n",
      "Instantiate the class created above\n",
      "Output the two properties\n",
      "\n",
      "\n",
      "I believe I have been able to create the class and as well the constructor but where am having my issues is the public/private properties as well as the other parts are troubling me.\n",
      "class Color:\n",
      "   def __init__(self,full_name,birthday ):\n",
      "       self.name = full_name\n",
      "       self.birthday = birthday\n",
      "\n",
      "   def age(self):\n",
      "      return self.birthday\n",
      "\n",
      "   def fname(self):\n",
      "       return _self.name\n",
      "\n",
      "object = Color()\n",
      "\n",
      "Answer\n",
      "\n",
      "Using python @property getters and setters decorators, the calls to these from an instance are undistinguishable.\n",
      "The inner workings follow the leading underscore convention for privacy.\n",
      "class Homework:\n",
      "\n",
      "    def __init__(self, param1, param2):\n",
      "        self._param1 = param1    # private\n",
      "        self.param2 = param2     # public\n",
      "\n",
      "    @property\n",
      "    def param1(self):\n",
      "        \"\"\"accessor for private parameter\n",
      "        \"\"\"\n",
      "        return self._param1\n",
      "\n",
      "    @param1.setter\n",
      "    def param1(self, value):\n",
      "        \"\"\"setter for private parameter\n",
      "        \"\"\" \n",
      "        self._param1 = value\n",
      "\n",
      "homework = Homework('The great secret', 'The public life of Napoleon')\n",
      "\n",
      "# accessing the parameters follow the same syntax\n",
      "print(homework.param1)\n",
      "print(homework.param2)\n",
      "\n",
      "# setting the parameters also follow the dotted syntax\n",
      "homework.param1 = \"you won't believe it\"    \n",
      "homework.param2 = 'but the dog ate it'    \n",
      "\n",
      "print(homework.param1)\n",
      "print(homework.param2)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086446/stats-f-oneway-scipy-anova-returns-2-arrays-with-4-values\n",
      "stats.f_oneway Scipy Anova returns 2 arrays with 4 values\n",
      "\n",
      "\n",
      "Trying to run one way Anova on data which looks approximately like this: \n",
      "    Year   | Diversity  |\n",
      "    2010   |   6        |\n",
      "    2010   |   8        |\n",
      "    ...    |   ...      |\n",
      "    2011   |   10       |\n",
      "    ...    |   ...      |\n",
      "    2019   |   7        |\n",
      "\n",
      "There are 1827 rows, diversity values for various points within the range of each year. I am comparing the variance year on year. \n",
      "When I do\n",
      "    F, p = stats.f_oneway(df.loc[df[\"Year\"] == 2010],\n",
      "                   df.loc[df[\"Year\"] == 2011],\n",
      "                   df.loc[df[\"Year\"] == 2012])\n",
      "\n",
      "(Here I omitted the rest of the groups because this is very ugly but I couldn't figure out how else to pass the different groups for the Anova test). I get an array with 2 values each for F and p: \n",
      "    F: type float64, size (2,),\n",
      "    -2.588805281700000000e+11, 4.908743340532151223e+00\n",
      "    p: type float64, size (2,),\n",
      "    nan, 0.00774507\n",
      "\n",
      "From what I read, I can't find anyone getting 2 arrays, it should be just one F value and one P value, I am doing something seriously wrong? \n",
      "(There are no zeroes or NANs in the df). \n",
      "When I do: \n",
      "    mod = ols('Diversity ~ (Year)', data = df).fit()\n",
      "    mod.summary()\n",
      "\n",
      "I get a normal Summary table, with F = 1.462, p = 0.227 (different to my attempts above). \n",
      "Any ideas on my mess would be greatly appreciated...\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086433/about-iteratively-accessing-a-function-itertools-method-in-python\n",
      "About iteratively accessing a function (“itertools” method) in python\n",
      "\n",
      "\n",
      "I wrote a python code using itertools method in python because i want to iterativly give the p_vec to the following function , \n",
      "import numpy as np\n",
      "from itertools import islice\n",
      "\n",
      "x1=np.array([1,2,3,4])\n",
      "p1=np.array([.1,.2,.3,.4])\n",
      "\n",
      "def fun1 (x_vec,p_vec):\n",
      "    x11=np.zeros(len(x_vec))\n",
      "    p11=np.zeros(len(p_vec))\n",
      "\n",
      "    for i in range (0,len(x_vec)):\n",
      "        x11[i] =x_vec[i]**2\n",
      "\n",
      "        while True:\n",
      "            p11[i]=x11[i]*p_vec[i]\n",
      "\n",
      "            yield x11 ,p11\n",
      "\n",
      "\n",
      "my_iterator = fun1(x1, p1) \n",
      "\n",
      "for values in islice(my_iterator, 0, 4):  \n",
      "    print(values)\n",
      "\n",
      "The code didnt give any errors. But the output i got appears follows,\n",
      "(array([1., 0., 0., 0.]), array([0.1, 0. , 0. , 0. ]))\n",
      "(array([1., 0., 0., 0.]), array([0.1, 0. , 0. , 0. ]))\n",
      "(array([1., 0., 0., 0.]), array([0.1, 0. , 0. , 0. ]))\n",
      "(array([1., 0., 0., 0.]), array([0.1, 0. , 0. , 0. ]))\n",
      "\n",
      "My desired output should be something like this (for 3 iterations)\n",
      "p [0.1 0.8 2.7 6.4]\n",
      "x [ 1.  4.  9. 16.]\n",
      "p [1.000e-01 3.200e+00 2.430e+01 1.024e+02]\n",
      "x [ 1.  4.  9. 16.]\n",
      "p [1.000e-01 3.200e+00 2.430e+01 1.024e+02]\n",
      "x [ 1.  4.  9. 16.]\n",
      "\n",
      "can anyone suggest what should i modify to get the correct result ?\n",
      "Thank you.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086398/how-do-you-clear-google-colabs-output-periodically\n",
      "How do you clear Google Colab's output periodically\n",
      "\n",
      "\n",
      "I am using Google Colab to train an object detection model using the tensorflow object detection api. When I run the cell train.py, it keeps printing the loss at each step and eventually after 30 minutes or so, the browser crashes because of the number of lines printed as the cell's output.\n",
      "Is there any script which one can use to clear the output periodically(say every 30 min) instead of manually pressing I am using Google Colab to train an object detection model using the tensorflow object detection api. When I run the cell train.py, it keeps printing the loss at each step and eventually after 30 minutes or so, the browser crashes because of the number of lines printed as the cell's output.\n",
      "the clear output button?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086368/pandas-dataframe-slicing-pythonic-idiom-for-order-of-row-v-column\n",
      "pandas dataframe slicing - pythonic idiom for order of row v column?\n",
      "\n",
      "\n",
      "Given a DataFrame of this format\n",
      "                     Temperature  DewPoint  Pressure\n",
      "Date                                                \n",
      "2010-01-01 00:00:00         46.2      37.5       1.0\n",
      "2010-01-01 01:00:00         44.6      37.1       1.0\n",
      "2010-01-01 02:00:00         44.1      36.9       1.0\n",
      "2010-01-01 03:00:00         43.8      36.9       1.0\n",
      "2010-01-01 04:00:00         43.5      36.8       1.0\n",
      "2010-01-01 05:00:00         43.3      37.3       1.0\n",
      "...\n",
      "2010-01-01 21:00:00         48.1      38.5       1.0\n",
      "2010-01-01 22:00:00         47.2      38.5       1.0\n",
      "2010-01-01 23:00:00         46.4      38.4       1.0\n",
      "2010-01-02 00:00:00         46.5      38.2       1.0\n",
      "2010-01-02 01:00:00         44.9      37.8       1.0\n",
      "...                          ...       ...       ...\n",
      "2010-12-31 22:00:00         46.9      37.9       1.0\n",
      "2010-12-31 23:00:00         46.2      37.7       1.0\n",
      "\n",
      "Using partial string indexing to extract temperature data from August 1 2010 to August 15 2010, the following appear to be equivalent\n",
      "d1 = df['Temperature']['2010-Aug-01':'2010-Aug-15']\n",
      "\n",
      "d2 = df['2010-Aug-01':'2010-Aug-15']['Temperature']\n",
      "\n",
      "I assume pandas is \"smart enough\" to do the right thing, but I was surprised. I was thinking dictionary format and would have assumed the index (key) should come first with the value (column) choice second.\n",
      "Is there a recommended order?  \n",
      "[column][index]\n",
      "\n",
      "vs\n",
      "[index][column]\n",
      "\n",
      "for writing the code or does it not matter how I write it because pandas understands and so would anyone reading the code?\n",
      "\n",
      "Answer\n",
      "\n",
      "You should using .loc\n",
      "d1 = df.loc['2010-08-01':'2010-08-15','Temperature']\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086340/python-flask-how-to-run-subprocess-unset-env-variable\n",
      "Python Flask - how to run subprocess (unset ENV variable)?\n",
      "\n",
      "\n",
      "I have a running Flask app but need to unset ENV variable in the moment of startup.\n",
      "In linux - command is:\n",
      "unset http_proxy\n",
      "How to execute that in the Flask app right after import block?\n",
      "Thanks.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086301/basic-neural-network-on-mnist-using-tensorflow-2-0\n",
      "Basic neural network on MNIST using tensorflow 2.0?\n",
      "\n",
      "\n",
      "I tried to write a basic neural network with two hidden layers on MNIST dataset using tensorflow 2.0 beta but I'm not sure what went wrong here but the loss/acc I got was incorrect. \n",
      "I'll appreciate if someone could help me out. Also If there's something I could improve in the code do let me know as well.\n",
      "Here's my full code for easy reproducibility: \n",
      "import numpy as np\n",
      "import os\n",
      "import logging\n",
      "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
      "import tensorflow as tf\n",
      "import tensorflow_datasets as tfds\n",
      "\n",
      "(x_train, y_train), (x_test, y_test) = tfds.load('mnist', split=['train', 'test'], \n",
      "                                                  batch_size=-1, as_supervised=True)\n",
      "\n",
      "# reshaping\n",
      "x_train = tf.reshape(x_train, shape=(x_train.shape[0], 784))\n",
      "x_test  = tf.reshape(x_test, shape=(x_test.shape[0], 784))\n",
      "\n",
      "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
      "# rescaling\n",
      "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y))\n",
      "\n",
      "class Model(object):\n",
      "    def __init__(self, hidden1_size, hidden2_size, device=None):\n",
      "        # layer sizes along with input and output\n",
      "        self.input_size, self.output_size, self.device = 784, 10, device\n",
      "        self.hidden1_size, self.hidden2_size = hidden1_size, hidden2_size\n",
      "        self.lr_rate = 1e-03\n",
      "\n",
      "        # weights initializationg\n",
      "        self.glorot_init = tf.initializers.glorot_uniform(seed=42)\n",
      "        # weights b/w input to hidden1 --> 1\n",
      "        self.w_h1 = tf.Variable(self.glorot_init((self.input_size, self.hidden1_size)))\n",
      "        # weights b/w hidden1 to hidden2 ---> 2\n",
      "        self.w_h2 = tf.Variable(self.glorot_init((self.hidden1_size, self.hidden2_size)))\n",
      "        # weights b/w hidden2 to output ---> 3\n",
      "        self.w_out = tf.Variable(self.glorot_init((self.hidden2_size, self.output_size)))\n",
      "\n",
      "        # bias initialization\n",
      "        self.b1 = tf.Variable(self.glorot_init((self.hidden1_size,)))\n",
      "        self.b2 = tf.Variable(self.glorot_init((self.hidden2_size,)))\n",
      "        self.b_out = tf.Variable(self.glorot_init((self.output_size,)))\n",
      "\n",
      "        self.variables = [self.w_h1, self.b1, self.w_h2, self.b2, self.w_out, self.b_out]\n",
      "\n",
      "\n",
      "    def feed_forward(self, x):\n",
      "        if self.device is not None:\n",
      "            with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
      "                # layer1\n",
      "                self.layer1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.w_h1), self.b1))\n",
      "                # layer2\n",
      "                self.layer2 = tf.nn.sigmoid(tf.add(tf.matmul(self.layer1,\n",
      "                                                             self.w_h2), self.b2))\n",
      "                # output layer\n",
      "                self.output = tf.nn.softmax(tf.add(tf.matmul(self.layer2,\n",
      "                                                             self.w_out), self.b_out))\n",
      "        return self.output\n",
      "\n",
      "    def loss_fn(self, y_pred, y_true):\n",
      "        self.loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, \n",
      "                                                                  logits=y_pred)\n",
      "        return tf.reduce_mean(self.loss)\n",
      "\n",
      "    def acc_fn(self, y_pred, y_true):\n",
      "        y_pred = tf.cast(tf.argmax(y_pred, axis=1), tf.int32)\n",
      "        y_true = tf.cast(y_true, tf.int32)\n",
      "        predictions = tf.cast(tf.equal(y_true, y_pred), tf.float32)\n",
      "        return tf.reduce_mean(predictions)\n",
      "\n",
      "    def backward_prop(self, batch_xs, batch_ys):\n",
      "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr_rate)\n",
      "        with tf.GradientTape() as tape:\n",
      "            predicted = self.feed_forward(batch_xs)\n",
      "            step_loss = self.loss_fn(predicted, batch_ys)\n",
      "        grads = tape.gradient(step_loss, self.variables)\n",
      "        optimizer.apply_gradients(zip(grads, self.variables))\n",
      "\n",
      "neural_net = Model(512, 256, 'gpu')\n",
      "\n",
      "for epoch in range(epochs):\n",
      "    no_steps = n_shape//batch_size\n",
      "    avg_loss = 0.\n",
      "    avg_acc = 0.\n",
      "    for (batch_xs, batch_ys) in ds_train.take(no_steps):\n",
      "        preds = neural_net.feed_forward(batch_xs)\n",
      "        avg_loss += neural_net.loss_fn(preds, batch_ys)\n",
      "        avg_acc += neural_net.acc_fn(preds, batch_ys)\n",
      "        neural_net.backward_prop(batch_xs, batch_ys)\n",
      "    print(f'Epoch: {epoch}, Training Loss: {avg_loss}, Training ACC: {avg_acc}')\n",
      "\n",
      "# output for 3 epochs:\n",
      "Epoch: 0, Training Loss: 796.0076293945312, Training ACC: 356.0390625\n",
      "Epoch: 1, Training Loss: 748.853515625, Training ACC: 401.9609375\n",
      "Epoch: 2, Training Loss: 742.2123413085938, Training ACC: 407.9453125\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086287/indexing-new-dataframes-into-new-columns-with-pandas\n",
      "Indexing new dataframes into new columns with pandas\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to create a new dataframe from an existing one by selecting multiple columns, and appending those column values to a new column with it's corresponding index as a new column\n",
      "So, lets say I have this as a dataframe:\n",
      "A B C D E F\n",
      "0 1 2 3 4 0\n",
      "0 7 8 9 1 0\n",
      "0 4 5 2 4 0\n",
      "\n",
      "Transform into this by selecting columns B through E:\n",
      "A index_value\n",
      "1 1\n",
      "7 1\n",
      "4 1\n",
      "2 2\n",
      "8 2\n",
      "5 2\n",
      "3 3\n",
      "9 3\n",
      "2 3\n",
      "4 4\n",
      "1 4\n",
      "4 4\n",
      "\n",
      "So, for the new dataframe, column A would be all of the values from columns B through E in the old dataframe, and column index_value would correspond to the index value [starting from zero] of the selected columns.\n",
      "I've been scratching my head for hours. Any help would be appreciated, thanks!\n",
      "Python3, Using pandas & numpy libraries.\n",
      "\n",
      "Answer\n",
      "\n",
      "This is just melt \n",
      "df.columns = range(df.shape[1])\n",
      "s = df.melt().loc[lambda x : x.value!=0]\n",
      "s\n",
      "    variable  value\n",
      "3          1      1\n",
      "4          1      7\n",
      "5          1      4\n",
      "6          2      2\n",
      "7          2      8\n",
      "8          2      5\n",
      "9          3      3\n",
      "10         3      9\n",
      "11         3      2\n",
      "12         4      4\n",
      "13         4      1\n",
      "14         4      4\n",
      "Try using:\n",
      "df = pd.melt(df[['B', 'C', 'D', 'E']])\n",
      "# Or df['variable'] = df[['B', 'C', 'D', 'E']].melt()\n",
      "df['variable'].shift().eq(df['variable'].shift(-1)).cumsum().shift(-1).ffill()\n",
      "print(df)\n",
      "\n",
      "Output:\n",
      "    variable  value\n",
      "0        1.0      1\n",
      "1        1.0      7\n",
      "2        1.0      4\n",
      "3        2.0      2\n",
      "4        2.0      8\n",
      "5        2.0      5\n",
      "6        3.0      3\n",
      "7        3.0      9\n",
      "8        3.0      2\n",
      "9        4.0      4\n",
      "10       4.0      1\n",
      "11       4.0      4\n",
      "#Another way\n",
      "\n",
      "    A   B   C   D   E   F\n",
      "0   0   1   2   3   4   0\n",
      "1   0   7   8   9   1   0\n",
      "2   0   4   5   2   4   0\n",
      "\n",
      "# Select columns to include\n",
      "\n",
      "start_colum ='B'\n",
      "end_column ='E'\n",
      "index_column_name ='A'\n",
      "\n",
      "#re-stack the dataframe\n",
      "\n",
      "df = df.loc[:,start_colum:end_column].stack().sort_index(level=1).reset_index(level=0, drop=True).to_frame()\n",
      "\n",
      "#Create the \"index_value\" column \n",
      "\n",
      "df['index_value'] =pd.Categorical(df.index).codes+1\n",
      "\n",
      "df.rename(columns={0:index_column_name}, inplace=True)\n",
      "\n",
      "df.set_index(index_column_name, inplace=True)\n",
      "\n",
      "df\n",
      "\n",
      "    index_value\n",
      "A   \n",
      "1   1\n",
      "7   1\n",
      "4   1\n",
      "2   2\n",
      "8   2\n",
      "5   2\n",
      "3   3\n",
      "9   3\n",
      "2   3\n",
      "4   4\n",
      "1   4\n",
      "4   4\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086268/is-there-a-viable-way-to-cluster-geo-spatial-data-while-considering-boundary-lin\n",
      "Is there a viable way to cluster geo-spatial data while considering boundary line segments?\n",
      "\n",
      "\n",
      "I am attempting to cluster lat/long coordinates into a specified number of densely created clusters but need to consider line segment boundaries - if the line segment between any two data points intersects a list of specified line segments (say 4 line segments --> Identified by start/end lat/long) then the points should not be clustered together. Because this is geo-spatial data I am looking to cluster around specific \"geographies\" that can not easily be interpreted from the clustering algorithms I am currently using. An initial thought was to modify the upper triangle of a distance matrix that is inputted into the clustering algorithm, looping through each entry of the triangle, checking the line segment against the \"boundaries\" and replacing the distance with a large value if intersection is found. This however is incredibly computationally hard (or at least the configuration I have set-up), and I am unable to manipulate the data in a reasonable amount of time.\n",
      "To give a representation of the scale, these data sets may consist of anywhere form 1,000-50,000 Lat/Long pairs.\n",
      "I have attempted to \"structure\" the data by utilizing the \"kneighbors_graph\" in Python to develop a connectivity matrix based on the KNN algorithm but it does not solve the issue (with varying values of k).Example followed: https://scikit-learn.org/stable/auto_examples/cluster/plot_ward_structured_vs_unstructured.html\n",
      "This ended up utilizing an Agglomerative Clustering approach which did not yield the results I was hoping (clusters still spanning across different geographies, and uneven cluster sizes - one as majority of the dataset).\n",
      "In R I have attempted the aforementioned line segment method to adjust the distance matrix being fed into the k-means algorithm, but stopped the code execution after about an hour of computation (and the upper triangle was barely processed!), which makes me think it has to do with my implementation. I will paste my method below (the line segments are read in from a csv file as a dataframe with start_lat,start_long,end_lat,end_long -hence the \"barrier[k,...]\" calls)\n",
      "Any and all help is appreciated in terms of general ideology on how to approach the problem or even specific code implementations that could speed up the processing idea I've mentioned. I also looked into the sweeping line algorithm but have not been able to wrap my head around an efficient way to implement that into the overall script.\n",
      "#Load CSV of barrier line segments\n",
      "barrier <- read.csv(\"LineSegments.csv\")\n",
      "\n",
      "#Create distance matrix from Lat/Long Dataframe\n",
      "distMatrix <- as.matrix(dist(LatLongDf))\n",
      "q <- nrow(distMatrix)\n",
      "\n",
      "#Loop through upper triangle of matrix without diagonal\n",
      "for (i in 1:(q-1)){\n",
      "    for (j in (i+1):q) {\n",
      "\n",
      "        #Grab row/column index of matrix (point IDs) and remap to original DF for point lat/longs\n",
      "        c1 <- c(LatLongDf[rownames(distMatrix)[i][1],LatLongDf[rownames(distMatrix)[i][2])\n",
      "        c2 <- c(LatLongDf[rownames(distMatrix)[j][1],LatLongDf[rownames(distMatrix)[j][2])\n",
      "\n",
      "        #Loop through inputted line segments\n",
      "        for (k in 1:nrow(barrier)) {\n",
      "             #Get point of intersection between two segments\n",
      "             dp <- line.line.intersection(c1,c2,c(barrier[k,2],barrier[k,3]),c(barrier[k,4],barrier[k,5]),interior.only = TRUE)\n",
      "             #If the lines do not intersect then set distance to max\n",
      "             if (is.na(dp[1])) {\n",
      "                  distMatrix[i,j] <- max(distMatrix)\n",
      "                  break\n",
      "             }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086256/finding-width-and-height-of-inward-curved-blob\n",
      "Finding Width and height of inward curved blob\n",
      "\n",
      "\n",
      "I have been scratching my head over this problem of calculation of width and height measurements of figure like below\n",
      "The major challenge is i cant use miBoundingrectangle and cant figure out a way for bounding from inside , either way i ll lose some pixels for height and width measurement. \n",
      "Sample Input :\n",
      "\n",
      "Sample Output:\n",
      "\n",
      "Is there any fail proof(the dimension measurement is as close to accurate) way i can get help with ?\n",
      "Below is a solution i was trying out to find inner bounding max rectangle. \n",
      "_,contour2,_=cv2.findContours(im,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_NONE)\n",
      "for c in contour2:\n",
      "    area=cv2.contourArea(c)\n",
      "    if area ==25224.0:\n",
      "        print(area)\n",
      "        n = np.squeeze(contour2[0])\n",
      "\n",
      "        x = sorted(n, key=lambda a:a[0])\n",
      "        left = x[0]\n",
      "        right = x[-1]\n",
      "        print(\"\",left,right)\n",
      "        y= sorted(n, key=lambda a:a[1])\n",
      "        top = y[0]\n",
      "        bottom = y[-1]\n",
      "        cv2.drawContours(im,[c],-1,(128,128,128),2)\n",
      "        cv2.circle(im, (left[0],left[1]), 4, (128,128,128), 8)\n",
      "        cv2.circle(im, (right[0],right[1]), 4, (128,128,128), 8)\n",
      "        cv2.circle(im, (top[0],top[1]), 4, (128,128,128), 8)\n",
      "        cv2.circle(im, (bottom[0],bottom[1]), 4, (128,128,128), 8)\n",
      "\n",
      "        roi_w = int(np.sqrt((top[0]-right[0])*(top[0]-right[0])(top[1]-right[1])*(top[1]-right[1])))\n",
      "        roi_h = int(np.sqrt((top[0]-left[0])*(top[0]-left[0])+(top[1]-left[1])*(top[1]-left[1])))\n",
      "                pts1 = np.float32([top,right,left])\n",
      "\n",
      "        new_top = top\n",
      "        new_right = [top[0] + roi_w, top[1]]\n",
      "        new_left = [top[0], top[1] + roi_h]\n",
      "        pts2 = np.float32([new_top,new_right,new_left])\n",
      "\n",
      "     cv2.imshow(\"threshed\", im)`\n",
      "\n",
      "Answer\n",
      "\n",
      "This is an Imagemagick solution. But the concept will give you a clue how to proceed with OpenCV. It is not quite the dimensions you want. But the closest way I could conceive. Basically, it is the maximum inside bounding box. Perhaps there is something similar in OpenCV.\n",
      "Iterate around each edge of the image from outside towards the inside until each remaining edge is fully black with no white (or reasonably close to that).\n",
      "Input:\n",
      "\n",
      "convert img.png -threshold 0 -define trim:percent-background=0% -trim +repage -format \"%wx%h\" +write info: result.png\n",
      "\n",
      "returns: widthxheight => 144x317\n",
      "\n",
      "\n",
      "\n",
      "ADDITION:\n",
      "Here is another solution that should be easy to do in OpenCV.\n",
      "Trim to get the minimum outer bounding box. Extract the center row and column, which may have some white on the ends. Then pad with white all around. Then trim all the white again so you have one black row and column remaining with no white. Then get the dimensions of the single black row and single black column.\n",
      "width=`convert img.png -threshold 0 -trim +repage -gravity center -crop x1+0+0 +repage -bordercolor white -border 1x1 -trim +repage -format \"%w\" info:`\n",
      "height=`convert img.png -threshold 0 -trim +repage -gravity center -crop 1x+0+0 +repage -bordercolor white -border 1x1 -trim +repage -format \"%h\" info:`\n",
      "echo \"width=$width; height=$height;\"\n",
      "returns: => width=145; height=352;\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086250/how-to-extract-xml-attribute-using-beautifulsoup-and-python\n",
      "How to extract xml attribute using beautifulsoup and python\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm trying to extract the 'totalvotes' value from this xml:\n",
      "<poll title=\"User Suggested Number of Players\" totalvotes=\"0\" name=\"suggested_numplayers\">\n",
      "<results numplayers=\"3+\"> </results>\n",
      "</poll>\n",
      "\n",
      "I've messed around with so many different combinations of the following code, but none of them work.\n",
      "soup.find_all('poll',{'title':'User Suggested Number of Players'})[0].find_all('totalvotes')\n",
      "\n",
      "I'm simply trying to retrieve the value of 0, in this case. How do I do this?\n",
      "Thank you.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086239/how-to-fix-indexing-or-reading-a-specific-value-of-a-key-were-the-occurrence-of\n",
      "How to fix indexing or reading a specific value of a key, were the occurrence of the key changes dynamically\n",
      "\n",
      "\n",
      "I have a code to capture the values associated to the below keys from a json file. were i have converted the json file into dict function and reading the value. At a point were the occurrence / line number of the key varies based on the json file i choose.\n",
      "Keys:\n",
      "In\n",
      "Name\n",
      "required\n",
      "type\n",
      "Need help to have a standard code / customizing the existing code even if the occurrence or line number changes in the json file.\n",
      "Given below the sample json content i am trying, Please have a detailed look into the below json content. as the occurrence will vary from one API endpoint to other.\n",
      "swagger: '2.0'\n",
      "info:\n",
      "  description: >-\n",
      "    This is a sample server Petstore server.  You can find out more about\n",
      "    Swagger at http://swagger.io or on irc.freenode.net,\n",
      "    #swagger.      For this sample, you can use the api\n",
      "    key special-key to test the authorization     filters.\n",
      "  version: 1.0.0\n",
      "  title: Swagger Petstore\n",
      "  termsOfService: 'http://swagger.io/terms/'\n",
      "  contact:\n",
      "    email: apiteam@swagger.io\n",
      "  license:\n",
      "    name: Apache 2.0\n",
      "    url: 'http://www.apache.org/licenses/LICENSE-2.0.html'\n",
      "host: petstore.swagger.io\n",
      "basePath: /v2\n",
      "tags:\n",
      "  - name: pet\n",
      "    description: Everything about your Pets\n",
      "    externalDocs:\n",
      "      description: Find out more\n",
      "      url: 'http://swagger.io'\n",
      "  - name: store\n",
      "    description: Access to Petstore orders\n",
      "  - name: user\n",
      "    description: Operations about user\n",
      "    externalDocs:\n",
      "      description: Find out more about our store\n",
      "      url: 'http://swagger.io'\n",
      "schemes:\n",
      "  - https\n",
      "  - http\n",
      "paths:\n",
      "  /pet:\n",
      "    post:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Add a new pet to the store\n",
      "      description: ''\n",
      "      operationId: addPet\n",
      "      consumes:\n",
      "        - application/json\n",
      "        - application/xml\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - $ref: '#/parameters/Pets'\n",
      "        - $ref: '#/parameters/petname'\n",
      "        - $ref: '#/parameters/petid'\n",
      "        - $ref: '#/parameters/petsd'\n",
      "        - $ref: '#/parameters/sampletag'\n",
      "        - $ref: '#/parameters/report-pets'\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: Pet object that needs to be added to the store\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/Pet'\n",
      "      responses:\n",
      "        '405':\n",
      "          description: Invalid input\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "    put:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Update an existing pet\n",
      "      description: ''\n",
      "      operationId: updatePet\n",
      "      consumes:\n",
      "        - application/json\n",
      "        - application/xml\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: Pet object that needs to be added to the store\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/Pet'\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Pet not found\n",
      "        '405':\n",
      "          description: Validation exception\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "  /pet/findByStatus:\n",
      "    get:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Finds Pets by status\n",
      "      description: Multiple status values can be provided with comma separated strings\n",
      "      operationId: findPetsByStatus\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - $ref: '#/parameters/dummy'\n",
      "        - $ref: '#/parameters/X-sample'\n",
      "        - $ref: '#/parameters/X-pets'\n",
      "        - $ref: '#/parameters/X-pet-id'\n",
      "        - $ref: '#/parameters/application-id'\n",
      "        - $ref: '#/parameters/report-id'\n",
      "        - $ref: \"#/parameters/limit\"\n",
      "        - $ref: \"#/parameters/offset\"\n",
      "        - name: status\n",
      "          in: query\n",
      "          description: Status values that need to be considered for filter\n",
      "          required: true\n",
      "          type: array\n",
      "          items:\n",
      "            type: string\n",
      "            enum:\n",
      "              - available\n",
      "              - pending\n",
      "              - sold\n",
      "            default: available\n",
      "          collectionFormat: multi\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            type: array\n",
      "            items:\n",
      "              $ref: '#/definitions/Pet'\n",
      "        '400':\n",
      "          description: Invalid status value\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "  /pet/findByTags:\n",
      "    get:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Finds Pets by tags\n",
      "      description: >-\n",
      "        Muliple tags can be provided with comma separated strings. Use\n",
      "        tag1, tag2, tag3 for testing.\n",
      "      operationId: findPetsByTags\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: tags\n",
      "          in: query\n",
      "          description: Tags to filter by\n",
      "          required: true\n",
      "          type: array\n",
      "          items:\n",
      "            type: string\n",
      "          collectionFormat: multi\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            type: array\n",
      "            items:\n",
      "              $ref: '#/definitions/Pet'\n",
      "        '400':\n",
      "          description: Invalid tag value\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "      deprecated: true\n",
      "  '/pet/{petId}':\n",
      "    get:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Find pet by ID\n",
      "      description: Returns a single pet\n",
      "      operationId: getPetById\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - $ref: '#/parameters/dummnies'\n",
      "        - $ref: '#/parameters/X-B3-pet'\n",
      "        - $ref: '#/parameters/X-B3-id'\n",
      "        - $ref: '#/parameters/X-B3-petname'\n",
      "        - $ref: '#/parameters/pets-id'\n",
      "        - $ref: '#/parameters/name-id'\n",
      "        - name: petId\n",
      "          in: path\n",
      "          description: ID of pet to return\n",
      "          required: true\n",
      "          type: integer\n",
      "          format: int64\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/Pet'\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Pet not found\n",
      "      security:\n",
      "        - api_key: []\n",
      "    post:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Updates a pet in the store with form data\n",
      "      description: ''\n",
      "      operationId: updatePetWithForm\n",
      "      consumes:\n",
      "        - application/x-www-form-urlencoded\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: petId\n",
      "          in: path\n",
      "          description: ID of pet that needs to be updated\n",
      "          required: true\n",
      "          type: integer\n",
      "          format: int64\n",
      "        - name: name\n",
      "          in: formData\n",
      "          description: Updated name of the pet\n",
      "          required: false\n",
      "          type: string\n",
      "        - name: status\n",
      "          in: formData\n",
      "          description: Updated status of the pet\n",
      "          required: false\n",
      "          type: string\n",
      "      responses:\n",
      "        '405':\n",
      "          description: Invalid input\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "    delete:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: Deletes a pet\n",
      "      description: ''\n",
      "      operationId: deletePet\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: api_key\n",
      "          in: header\n",
      "          required: false\n",
      "          type: string\n",
      "        - name: petId\n",
      "          in: path\n",
      "          description: Pet id to delete\n",
      "          required: true\n",
      "          type: integer\n",
      "          format: int64\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Pet not found\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "  '/pet/{petId}/uploadImage':\n",
      "    post:\n",
      "      tags:\n",
      "        - pet\n",
      "      summary: uploads an image\n",
      "      description: ''\n",
      "      operationId: uploadFile\n",
      "      consumes:\n",
      "        - multipart/form-data\n",
      "      produces:\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: petId\n",
      "          in: path\n",
      "          description: ID of pet to update\n",
      "          required: true\n",
      "          type: integer\n",
      "          format: int64\n",
      "        - name: additionalMetadata\n",
      "          in: formData\n",
      "          description: Additional data to pass to server\n",
      "          required: false\n",
      "          type: string\n",
      "        - name: file\n",
      "          in: formData\n",
      "          description: file to upload\n",
      "          required: false\n",
      "          type: file\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/ApiResponse'\n",
      "      security:\n",
      "        - petstore_auth:\n",
      "            - 'write:pets'\n",
      "            - 'read:pets'\n",
      "  /store/inventory:\n",
      "    get:\n",
      "      tags:\n",
      "        - store\n",
      "      summary: Returns pet inventories by status\n",
      "      description: Returns a map of status codes to quantities\n",
      "      operationId: getInventory\n",
      "      produces:\n",
      "        - application/json\n",
      "      parameters: []\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            type: object\n",
      "            additionalProperties:\n",
      "              type: integer\n",
      "              format: int32\n",
      "      security:\n",
      "        - api_key: []\n",
      "  /store/order:\n",
      "    post:\n",
      "      tags:\n",
      "        - store\n",
      "      summary: Place an order for a pet\n",
      "      description: ''\n",
      "      operationId: placeOrder\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: order placed for purchasing the pet\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/Order'\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/Order'\n",
      "        '400':\n",
      "          description: Invalid Order\n",
      "  '/store/order/{orderId}':\n",
      "    get:\n",
      "      tags:\n",
      "        - store\n",
      "      summary: Find purchase order by ID\n",
      "      description: >-\n",
      "        For valid response try integer IDs with value >= 1 and <= 10.\n",
      "        Other values will generated exceptions\n",
      "      operationId: getOrderById\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: orderId\n",
      "          in: path\n",
      "          description: ID of pet that needs to be fetched\n",
      "          required: true\n",
      "          type: integer\n",
      "          maximum: 10\n",
      "          minimum: 1\n",
      "          format: int64\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/Order'\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Order not found\n",
      "    delete:\n",
      "      tags:\n",
      "        - store\n",
      "      summary: Delete purchase order by ID\n",
      "      description: >-\n",
      "        For valid response try integer IDs with positive integer value.\n",
      "        Negative or non-integer values will generate API errors\n",
      "      operationId: deleteOrder\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: orderId\n",
      "          in: path\n",
      "          description: ID of the order that needs to be deleted\n",
      "          required: true\n",
      "          type: integer\n",
      "          minimum: 1\n",
      "          format: int64\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid ID supplied\n",
      "        '404':\n",
      "          description: Order not found\n",
      "  /user:\n",
      "    post:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Create user\n",
      "      description: This can only be done by the logged in user.\n",
      "      operationId: createUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: Created user object\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/User'\n",
      "      responses:\n",
      "        default:\n",
      "          description: successful operation\n",
      "  /user/createWithArray:\n",
      "    post:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Creates list of users with given input array\n",
      "      description: ''\n",
      "      operationId: createUsersWithArrayInput\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: List of user object\n",
      "          required: true\n",
      "          schema:\n",
      "            type: array\n",
      "            items:\n",
      "              $ref: '#/definitions/User'\n",
      "      responses:\n",
      "        default:\n",
      "          description: successful operation\n",
      "  /user/createWithList:\n",
      "    post:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Creates list of users with given input array\n",
      "      description: ''\n",
      "      operationId: createUsersWithListInput\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: List of user object\n",
      "          required: true\n",
      "          schema:\n",
      "            type: array\n",
      "            items:\n",
      "              $ref: '#/definitions/User'\n",
      "      responses:\n",
      "        default:\n",
      "          description: successful operation\n",
      "  /user/login:\n",
      "    get:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Logs user into the system\n",
      "      description: ''\n",
      "      operationId: loginUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: username\n",
      "          in: query\n",
      "          description: The user name for login\n",
      "          required: true\n",
      "          type: string\n",
      "        - name: password\n",
      "          in: query\n",
      "          description: The password for login in clear text\n",
      "          required: true\n",
      "          type: string\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            type: string\n",
      "          headers:\n",
      "            X-Rate-Limit:\n",
      "              type: integer\n",
      "              format: int32\n",
      "              description: calls per hour allowed by the user\n",
      "            X-Expires-After:\n",
      "              type: string\n",
      "              format: date-time\n",
      "              description: date in UTC when token expires\n",
      "        '400':\n",
      "          description: Invalid username/password supplied\n",
      "  /user/logout:\n",
      "    get:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Logs out current logged in user session\n",
      "      description: ''\n",
      "      operationId: logoutUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters: []\n",
      "      responses:\n",
      "        default:\n",
      "          description: successful operation\n",
      "  '/user/{username}':\n",
      "    get:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Get user by user name\n",
      "      description: ''\n",
      "      operationId: getUserByName\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: username\n",
      "          in: path\n",
      "          description: 'The name that needs to be fetched. Use user1 for testing. '\n",
      "          required: true\n",
      "          type: string\n",
      "      responses:\n",
      "        '200':\n",
      "          description: successful operation\n",
      "          schema:\n",
      "            $ref: '#/definitions/User'\n",
      "        '400':\n",
      "          description: Invalid username supplied\n",
      "        '404':\n",
      "          description: User not found\n",
      "    put:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Updated user\n",
      "      description: This can only be done by the logged in user.\n",
      "      operationId: updateUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: username\n",
      "          in: path\n",
      "          description: name that need to be updated\n",
      "          required: true\n",
      "          type: string\n",
      "        - in: body\n",
      "          name: body\n",
      "          description: Updated user object\n",
      "          required: true\n",
      "          schema:\n",
      "            $ref: '#/definitions/User'\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid user supplied\n",
      "        '404':\n",
      "          description: User not found\n",
      "    delete:\n",
      "      tags:\n",
      "        - user\n",
      "      summary: Delete user\n",
      "      description: This can only be done by the logged in user.\n",
      "      operationId: deleteUser\n",
      "      produces:\n",
      "        - application/xml\n",
      "        - application/json\n",
      "      parameters:\n",
      "        - name: username\n",
      "          in: path\n",
      "          description: The name that needs to be deleted\n",
      "          required: true\n",
      "          type: string\n",
      "      responses:\n",
      "        '400':\n",
      "          description: Invalid username supplied\n",
      "        '404':\n",
      "          description: User not found\n",
      "securityDefinitions:\n",
      "  petstore_auth:\n",
      "    type: oauth2\n",
      "    authorizationUrl: 'http://petstore.swagger.io/oauth/dialog'\n",
      "    flow: implicit\n",
      "    scopes:\n",
      "      'write:pets': modify pets in your account\n",
      "      'read:pets': read your pets\n",
      "  api_key:\n",
      "    type: apiKey\n",
      "    name: api_key\n",
      "    in: header\n",
      "definitions:\n",
      "  Order:\n",
      "    type: object\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      petId:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      quantity:\n",
      "        type: integer\n",
      "        format: int32\n",
      "      shipDate:\n",
      "        type: string\n",
      "        format: date-time\n",
      "      status:\n",
      "        type: string\n",
      "        description: Order Status\n",
      "        enum:\n",
      "          - placed\n",
      "          - approved\n",
      "          - delivered\n",
      "      complete:\n",
      "        type: boolean\n",
      "        default: false\n",
      "    xml:\n",
      "      name: Order\n",
      "  Category:\n",
      "    type: object\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      name:\n",
      "        type: string\n",
      "    xml:\n",
      "      name: Category\n",
      "  User:\n",
      "    type: object\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      username:\n",
      "        type: string\n",
      "      firstName:\n",
      "        type: string\n",
      "      lastName:\n",
      "        type: string\n",
      "      email:\n",
      "        type: string\n",
      "      password:\n",
      "        type: string\n",
      "      phone:\n",
      "        type: string\n",
      "      userStatus:\n",
      "        type: integer\n",
      "        format: int32\n",
      "        description: User Status\n",
      "    xml:\n",
      "      name: User\n",
      "  Tag:\n",
      "    type: object\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      name:\n",
      "        type: string\n",
      "    xml:\n",
      "      name: Tag\n",
      "  Pet:\n",
      "    type: object\n",
      "    required:\n",
      "      - name\n",
      "      - photoUrls\n",
      "    properties:\n",
      "      id:\n",
      "        type: integer\n",
      "        format: int64\n",
      "      category:\n",
      "        $ref: '#/definitions/Category'\n",
      "      name:\n",
      "        type: string\n",
      "        example: doggie\n",
      "      photoUrls:\n",
      "        type: array\n",
      "        xml:\n",
      "          name: photoUrl\n",
      "          wrapped: true\n",
      "        items:\n",
      "          type: string\n",
      "      tags:\n",
      "        type: array\n",
      "        xml:\n",
      "          name: tag\n",
      "          wrapped: true\n",
      "        items:\n",
      "          $ref: '#/definitions/Tag'\n",
      "      status:\n",
      "        type: string\n",
      "        description: pet status in the store\n",
      "        enum:\n",
      "          - available\n",
      "          - pending\n",
      "          - sold\n",
      "    xml:\n",
      "      name: Pet\n",
      "  ApiResponse:\n",
      "    type: object\n",
      "    properties:\n",
      "      code:\n",
      "        type: integer\n",
      "        format: int32\n",
      "      type:\n",
      "        type: string\n",
      "      message:\n",
      "        type: string\n",
      "externalDocs:\n",
      "  description: Find out more about Swagger\n",
      "  url: 'http://swagger.io'\n",
      "i have written the below code to capture the values based on the index [0], but the index value are dynamic. Example at 0 In key word present, for next content it might occur in 5.\n",
      "import yaml\n",
      "import json\n",
      "with open(\"pets.yaml\", 'r') as yaml_in, open(\"yml_test.json\", \"w\") as json_out:\n",
      "    data = json.loads(json.dumps(yaml.load(yaml_in, Loader=yaml.FullLoader)))\n",
      "    output_dict = {}\n",
      "    for url in data[\"paths\"]:\n",
      "        for method in data[\"paths\"][url]:\n",
      "            output_dict[url + \"/\" + method] = {}\n",
      "            output_dict[url + \"/\" + method][\"parameters\"] = {}\n",
      "            if \"consumes\" in data[\"paths\"][url][method]:\n",
      "                output_dict[url+\"/\"+method][\"consumes\"] = data[\"paths\"][url][method][\"consumes\"]\n",
      "                print(\"Consumes Parameter: \", data[\"paths\"][url][method][\"consumes\"])\n",
      "            if \"produces\" in data[\"paths\"][url][method]:\n",
      "                output_dict[url+\"/\"+method][\"produces\"] = data[\"paths\"][url][method][\"produces\"]\n",
      "                print(\"Produces parameter: \", data[\"paths\"][url][method][\"produces\"])\n",
      "            if data[\"paths\"][url][method][\"parameters\"]:\n",
      "                if \"in\" in data[\"paths\"][url][method][\"parameters\"][0]:\n",
      "                    output_dict[url+\"/\"+method][\"parameters\"][\"in\"] = data[\"paths\"][url][method][\"parameters\"][0][\"in\"]\n",
      "                    print(\"In Parameter: \", data[\"paths\"][url][method][\"parameters\"][0][\"in\"])\n",
      "                if \"name\" in data[\"paths\"][url][method][\"parameters\"][0]:\n",
      "                    output_dict[url+\"/\"+method][\"parameters\"][\"name\"] = data[\"paths\"][url][method][\"parameters\"][0][\"name\"]\n",
      "                    print(\"Name parameter: \", data[\"paths\"][url][method][\"parameters\"][0][\"name\"])\n",
      "                if \"required\" in data[\"paths\"][url][method][\"parameters\"][0]:\n",
      "                    output_dict[url+\"/\"+method][\"parameters\"][\"required\"] = data[\"paths\"][url][method][\"parameters\"][0][\"required\"]\n",
      "                    print(\"Required Parameter: \", data[\"paths\"][url][method][\"parameters\"][0][\"required\"])\n",
      "                if \"type\" in  data[\"paths\"][url][method][\"parameters\"][0]:\n",
      "                    output_dict[url+\"/\"+method][\"parameters\"][\"type\"] = data[\"paths\"][url][method][\"parameters\"][0][\"type\"]\n",
      "                    print(\"Type Parameter: \", data[\"paths\"][url][method][\"parameters\"][0][\"type\"])\n",
      "\n",
      "    json.dump(output_dict, json_out)\n",
      "\n",
      "Below is the sample output, but were i need to capture required, Name, Type.\n",
      "\n",
      "The below output occurred when i changed the index 0 to 5.But for next occurrence it might be within 6 or 7 or 3,...\n",
      "Produces parameter:  ['application/json']\n",
      "In Parameter:  query\n",
      "Produces parameter:  ['application/octet-stream']\n",
      "In Parameter:  path\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086230/how-to-make-a-bar-plot-in-python\n",
      "How to make a bar plot in Python?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am trying to build graphs in Python, using this dataset:   \n",
      "    df  = pd.read_csv(\"Sales.csv\")\n",
      "    df\n",
      "\n",
      "\n",
      "Then I try to build a bar chart using this code:\n",
      "df_product_group = df.groupby('Product').sum()\n",
      "product_group = df_product_group.groupby(['Total Amount'])\n",
      "product_group.plot(kind='barh', stacked=True, figsize=[16,6], colormap='winter') \n",
      "\n",
      "It produces a lot of error codes, including this at the end of the line:\n",
      "~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py in _get_grouper(obj, key, axis, level, sort, observed, mutated, validate)\n",
      "   3289                 in_axis, name, level, gpr = False, None, gpr, None\n",
      "   3290             else:\n",
      "-> 3291                 raise KeyError(gpr)\n",
      "   3292         elif isinstance(gpr, Grouper) and gpr.key is not None:\n",
      "   3293             # Add key to exclusions\n",
      "\n",
      "KeyError: 'Total Amount'\n",
      "\n",
      "What did I do wrong here? And how do I make a bar plot the right way here?\n",
      "Thank you beforehand.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086194/how-to-manage-a-multilayered-dictionary-customize-the-columns-subtract-column\n",
      "How to manage a multilayered dictionary, customize the columns, subtract column data, and add a new column?\n",
      "\n",
      "\n",
      "Thanks so much for the help!\n",
      "I'm doing a json pull from Alphavantage. I'm trying to:\n",
      "\n",
      "Convert the json data to a Pandas dataframe\n",
      "Get the correct data to display correctly\n",
      "Customize the column labels ('Open', 'High', 'Low', 'Close', 'Volume')\n",
      "Subtract data in column 'Close' from data in column 'Open'\n",
      "Create a new column called 'Net' with data from number 4 above\n",
      "\n",
      "I'm a total noob. This is actually my first real project and first time posting here. I'm still learning and experimenting. I'm sure there is a much easier way to do what I'm doing. I've spent countless hours researching and trying to figure this out. Here is what I have so far:\n",
      "import pandas as pd\n",
      "import requests as rq\n",
      "\n",
      "pull_type = 'TIME_SERIES_DAILY'\n",
      "symbol = 'GOOG'\n",
      "size = 'compact'\n",
      "data_type = 'json'\n",
      "api_key = 'XXX_MY_KEY_XXX'\n",
      "url = 'https://www.alphavantage.co/query?'\n",
      "pull_parameters = {\n",
      "    'function': pull_type,\n",
      "    'symbol': symbol,\n",
      "    'outputsize': size,\n",
      "    'datatype': data_type,\n",
      "    'apikey': api_key\n",
      "}\n",
      "\n",
      "pull = rq.get(url, params=pull_parameters)\n",
      "\n",
      "data = pull.json()\n",
      "\n",
      "df = pd.DataFrame.from_dict(data['Time Series (Daily)'], orient='index')\n",
      "\n",
      "df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "\n",
      "df.index = pd.to_datetime(df.index)\n",
      "\n",
      "day_net = df['Open'] - df['Close']\n",
      "\n",
      "print(day_net)\n",
      "\n",
      "I'm getting so many exception errors. Too many to list. Still learning what they all mean. Any input and direction would be welcomed and much appreciated. Thanks!\n",
      "\n",
      "Answer\n",
      "\n",
      "Try changing this line:\n",
      "df = pd.DataFrame.from_dict(data['Time Series (Daily)'], orient='index')\n",
      "\n",
      "To:\n",
      "df = pd.DataFrame.from_dict(data['Time Series (Daily)'], orient='index').astype(float)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086154/beautifulsoup-cannot-bring-bodys-contents\n",
      "BeautifulSoup cannot bring <body>'s contents\n",
      "\n",
      "\n",
      "http://bus.asan.go.kr/web/bus_arrInfo_pop?busStopId=288000863\n",
      "The link is the bus information system page provided by a Korean local government.\n",
      "I want to crawl the information on the page. but I couldn't.\n",
      "When I tried using BeautifulSoup, Some codes were read but other parts weren't.\n",
      "My code is as below.\n",
      "from urllib.request import urlopen\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "html = urlopen(\"http://bus.asan.go.kr/web/bus_arrInfo_pop?busStopId=288000863\")\n",
      "\n",
      "bsObj = BeautifulSoup(html.read(), \"html.parser\")\n",
      "print(bsObj)\n",
      "\n",
      "and the result is below.\n",
      "There are no any body-contents in the result.\n",
      "What should I do to get contents from the page?\n",
      "Thank you in advance.\n",
      "\n",
      "\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n",
      "\n",
      "<html lang=\"ko\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\">\n",
      "<title>아산시 버스정보시스템</title>\n",
      "<link href=\"../resources/css/common.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"../resources/css/w/scrollbar.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"../resources/css/w/bus_arrInfo_pop.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<script src=\"../resources/js/jquery-1.9.1.js\" type=\"text/javascript\"></script>\n",
      "<script src=\"../resources/js/hashMap.js\" type=\"text/javascript\"></script>\n",
      "<script src=\"../resources/js/w/commonTraffic.js\" type=\"text/javascript\"></script>\n",
      "<script type=\"text/javascript\">\n",
      "\n",
      "        $(document).ready(function(){\n",
      "                var paramStop_id = '288000863';\n",
      "                if(paramStop_id != \"\" && paramStop_id != null){\n",
      "                        var form_data = {\n",
      "                                        busStopId: paramStop_id\n",
      "            };\n",
      "\n",
      "                ajaxCall(\"../mobile/traffic/searchBusStopRoute\", form_data, ajaxBeforeSendMapRouteInfo, ajaxSuccessMapRouteInfo);\n",
      "                }\n",
      "\n",
      "                $('.btn_print').click(function(){\n",
      "                        $('.stationInfo_wrap .cont').css('max-height','inherit');\n",
      "                        $('.stationInfo_wrap .cont').css('overflow-y','auto');\n",
      "                        window.print();\n",
      "                        $('.stationInfo_wrap .cont').css('max-height','670px');\n",
      "                        $('.stationInfo_wrap .cont').css('overflow-y','scroll');\n",
      "                });\n",
      "        });\n",
      "\n",
      "        function ajaxBeforeSendMapRouteInfo(xhr){\n",
      "                var strTemp = \"\";\n",
      "                strTemp += \"<div style='height: 144px;width: 573px;border-left: 1px solid #d0d0d0;'><img style='width: 20px; height: 20px; margin-top:60px;' alt='로딩중' src='../resources/images/w/loader.gif'></div>\";\n",
      "                $(\"#map_route_data\").empty().append(strTemp);\n",
      "        }\n",
      "\n",
      "        function ajaxSuccessMapRouteInfo(data){\n",
      "                var strTemp = \"\";\n",
      "                var stopInfo = data.stopInfo;\n",
      "                if(data.busStopRouteList.length == 0){\n",
      "                        var id = stopInfo.service_id;\n",
      "                        if(id==\"\"||id==null||id==\" \"){\n",
      "                                id = \"ID 없음\";\n",
      "                        }\n",
      "\n",
      "                        $(\"#map_service_id\").text(\"[\" + id + \"]\");\n",
      "                        $(\"#map_stop_name\").text(stopInfo.stop_name);\n",
      "\n",
      "                        strTemp += \"<div style='height: 152px;width: 573px;border-left: 1px solid #d0d0d0;line-height: 144px;'>검색결과가 없습니다.</div>\";\n",
      "                } else {\n",
      "                        var id = data.busStopRouteList[0].service_id;\n",
      "                        if(id==\"\"||id==null||id==\" \"){\n",
      "                                id = \"ID 없음\";\n",
      "                        }\n",
      "                        $(\"#map_service_id\").text(\"[\" + id + \"]\");\n",
      "                        $(\"#map_stop_name\").text(data.busStopRouteList[0].stop_name);\n",
      "\n",
      "                        $.each( data.busStopRouteList, function( index, value ) {\n",
      "                                var routeName = value.route_name;\n",
      "                                if(value.relay_areacode==285){\n",
      "                                        routeName = routeName + \" (천안)\";\n",
      "                                }\n",
      "                                if(index==0){\n",
      "                                        if(value.eb_flag==0){\n",
      "                                                strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                        }else{\n",
      "                                                if(value.route_type == 11) {\n",
      "                                                        strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                }else {\n",
      "                                                        strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                }\n",
      "                                        }\n",
      "                                        strTemp += \"<div class='st_waitTime'>\"+value.provide_type+\"</div><div class='st_where'>\"+value.rstop+\"</div><div class='st_XXX'>\"+value.last_stop_name+\"</div>\";\n",
      "\n",
      "                                        if(index!=(data.busStopRouteList.length-1)){\n",
      "                                                line=1;\n",
      "                                        }else{\n",
      "                                                //strTemp += \"<div class='st_waitTime'></div><div class='st_where'></div><div class='st_XXX' style='margin-bottom:6px;'></div>\";\n",
      "                                                line=2;\n",
      "                                        }\n",
      "                                        temp_route_id=value.route_id;\n",
      "                                }else{\n",
      "                                        if(temp_route_id==value.route_id){\n",
      "                                                //strTemp += \"<div class='st_waitTime line2'>\"+value.provide_type+\"</div><div class='st_where line2'>\"+value.rstop+\"</div><div class='st_XXX line2'>\"+value.last_stop_name+\"</div>\";\n",
      "                                                line=2;\n",
      "                                                temp_route_id=\"-1\";\n",
      "                                        }else{\n",
      "                                                if(line==1){\n",
      "                                                        //strTemp += \"<div class='st_waitTime\n",
      "line2'></div><div class='st_where line2'></div><div class='st_XXX line2'></div>\";\n",
      "                                                        temp_route_id=\"-1\";\n",
      "                                                        line=2;\n",
      "                                                }\n",
      "                                                if(value.eb_flag==0){\n",
      "                                                        strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                }else{\n",
      "                                                        if(value.route_type == 11) {\n",
      "                                                                strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                        }else {\n",
      "                                                                strTemp += \"<div class='st_busNum'>\"+routeName+\"</div>\";\n",
      "                                                        }\n",
      "                                                }\n",
      "\n",
      "                                                if(index!=(data.busStopRouteList.length-1)){\n",
      "                                                        strTemp += \"<div class='st_waitTime'>\"+value.provide_type+\"</div><div class='st_where'>\"+value.rstop+\"</div><div class='st_XXX'>\"+value.last_stop_name+\"</div>\";\n",
      "                                                        line=1;\n",
      "                                                }else{\n",
      "                                                        strTemp += \"<div class='st_waitTime'>\"+value.provide_type+\"</div><div class='st_where'>\"+value.rstop+\"</div><div class='st_XXX' style='margin-bottom:10px;'>\"+value.last_stop_name+\"</div>\";\n",
      "                                                        //strTemp += \"<div class='st_waitTime'></div><div class='st_where'></div><div class='st_XXX' style='margin-bottom:10px;'></div>\";\n",
      "                                                        line=2;\n",
      "                                                }\n",
      "\n",
      "                                                temp_route_id=value.route_id;\n",
      "                                        }\n",
      "                                }\n",
      "                        });\n",
      "\n",
      "                }\n",
      "                $(\"#map_route_data\").empty().append(strTemp);\n",
      "        }\n",
      "\n",
      "        </script>\n",
      "</meta></head>\n",
      "<body style=\"width:100%;min-width:615px;\">\n",
      "<div class=\"wrap\" style=\"width:615px;\">\n",
      "<div class=\"stationInfo_wrap\">\n",
      "<div class=\"st_header\">\n",
      "<div class=\"st_info\">\n",
      "<p>\n",
      "<span id=\"map_service_id\"></span>\n",
      "<span id=\"map_stop_name\" style=\"padding-left: 5px;\"></span>\n",
      "<a class=\"btn_print extraBtnBg\" href=\"#\" style=\"  margin-top: 13px; font-size: 12px; line-height: 19px; width:90px;\">도착정보 출력</a></p>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cont\">\n",
      "<div class=\"st_title\">\n",
      "<div class=\"st_busNum\">노선번호</div>\n",
      "<div class=\"st_waitTime\">도착예정</div>\n",
      "<div class=\"st_where\">현재위치</div>\n",
      "<div class=\"st_XXX\">현재정류장</div>\n",
      "</div>\n",
      "<div class=\"st_list\">\n",
      "<div class=\"map_route_data\" id=\"map_route_data\">\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Answer\n",
      "\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "url = 'http://bus.asan.go.kr/web/bus_arrInfo_pop?busStopId=288000863'\n",
      "res = requests.get(url)\n",
      "html_page = res.content\n",
      "soup = BeautifulSoup(html_page, 'html.parser')\n",
      "text = soup.find_all(text=True)\n",
      "\n",
      "output = ''\n",
      "blacklist = [\n",
      "    '[document]',\n",
      "    'noscript',\n",
      "    'header',\n",
      "    'html',\n",
      "    'meta',\n",
      "    'head', \n",
      "    'input',\n",
      "    'script',\n",
      "    # there may be more elements you don't want, such as \"style\", etc.\n",
      "]\n",
      "\n",
      "for t in text:\n",
      "    if t.parent.name not in blacklist:\n",
      "        output += '{} '.format(t)\n",
      "\n",
      "print(output)\n",
      "\n",
      "\n",
      "result:\n",
      "'아산시 버스정보시스템\\n\\n\\n\\n\\n\\n\\n\\n도착정보 출력\\n\\n\\n\\n\\n\\n노선번호\\n도착예정\\n현재위치\\n현재정류장\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "you can also replace \\n if you want.\n",
      "sourcecode from:https://matix.io/extract-text-from-webpage-using-beautifulsoup-and-python/\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086150/web-scraping-python-using-my-subscriptions\n",
      "Web scraping python - using my subscriptions\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am scraping multiple news sites, some of which require a subscription to access. Is there a way to proxy python web requests through my browser which has all of these subscriptions logged in?\n",
      "Or is there a better way to use my subscription log in details through python web requests?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086144/unable-to-convert-json-response-to-pandas-data-frame\n",
      "Unable to convert json response to pandas data frame\n",
      "\n",
      "\n",
      "I am trying to convert a json response of type below, however I am unable to do so.\n",
      "[entity {\n",
      "  entity_id: \"/m/025l19\"\n",
      "  description: \"recording\"\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "category_entities {\n",
      "  entity_id: \"/m/0h91fqv\"\n",
      "  description: \"audio\"\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "segments {\n",
      "  segment {\n",
      "    start_time_offset {\n",
      "    }\n",
      "    end_time_offset {\n",
      "      seconds: 599\n",
      "      nanos: 682416000\n",
      "    }\n",
      "  }\n",
      "  confidence: 0.7370531558990479\n",
      "}\n",
      ", entity {\n",
      "  entity_id: \"/m/0gfj96l\"\n",
      "  description: \"engineer\"\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "category_entities {\n",
      "  entity_id: \"/m/01g317\"\n",
      "  description: \"person\"\n",
      "  language_code: \"en-US\"\n",
      "}\n",
      "segments {\n",
      "  segment {\n",
      "    start_time_offset {\n",
      "    }\n",
      "    end_time_offset {\n",
      "      seconds: 599\n",
      "      nanos: 682416000\n",
      "    }\n",
      "  }\n",
      "  confidence: 0.5298324227333069\n",
      "}\n",
      "]\n",
      "\n",
      "I went through the stackoverflow and they suggests to use from pandas.io.json import json_normalize for example\n",
      "Convert JSON API response to pandas Dataframe\n",
      "However I keep getting the following error\n",
      ">>> df = json_normalize(segment_labels, 'entity')\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\json\\normalize.py\", line 267, in json_normalize\n",
      "    _recursive_extract(data, record_path, {}, level=0)\n",
      "  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\json\\normalize.py\", line 244, in _recursive_extract\n",
      "    recs = _pull_field(obj, path[0])\n",
      "  File \"C:\\Python37\\lib\\site-packages\\pandas\\io\\json\\normalize.py\", line 189, in _pull_field\n",
      "    result = result[spec]\n",
      "TypeError: 'Annotation' object is not subscriptable\n",
      "\n",
      "\n",
      "What I am trying to achieve a result something as below\n",
      "entity       category   start_time end_time   confidence\n",
      "recording    audio      0           599s      0.6780350804328918\n",
      "engineer     person     0           599s      0.8203253149986267\n",
      "\n",
      "I was hoping if someone can please help to convert the json response to pandas. \n",
      "Thanks a lot in advance !!\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086138/how-to-fix-syntaxerror-invalid-syntax-with-assigning-variable\n",
      "How to fix “SyntaxError: invalid syntax” with assigning variable [on hold]\n",
      "\n",
      "\n",
      "Halfway through my code, I come across SyntaxError: invalid syntax when assigning a variable. The variable is assigned just like the ones before it so I can't tell what is wrong. \n",
      "\n",
      "import numpy as np\n",
      "from tensorflow import nn\n",
      "from nn import sigmoid\n",
      "\n",
      "class NeuralNet:\n",
      "    def __init__(self, inputs, output):\n",
      "        self.input    = inputs\n",
      "        assert inputs <= 0, print(\"test\")\n",
      "        self.weights1 = np.random.rand(self.input.shape[1],units1 = 4)\n",
      "        self.weights2 = np.random.rand(units1             ,units2 = 4)\n",
      "        self.weights3 = np.random.rand(units2             ,units3 = 4)\n",
      "        self.weights4 = np.random.rand(units3             ,final  = 1)\n",
      "#       self.output   = output\n",
      "        self.output   = np.zeros(self.output.shape)\n",
      "        self.score    = None\n",
      "\n",
      "    def feedForward(self):\n",
      "        self.layer1 = sigmoid(np.dot(self.input   , self.weights1)\n",
      "        self.layer2 = sigmoid(np.dot(self.weights1, self.weights2) #line 23\n",
      "        self.layer3 = sigmoid(np.dot(self.weights2, self.weights3)\n",
      "        self.output = sigmoid(np.dot(self.weights3, self.weights4)\n",
      "\n",
      "NNet = NeuralNet(0,0)\n",
      "\n",
      "I expected it to work fine and output \"test\" but the program is interrupted with an invalid syntax error at line 23.\n",
      "What am I doing wrong?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086133/pygame-spritesheet-images-not-stacking\n",
      "Pygame Spritesheet Images Not Stacking\n",
      "\n",
      "\n",
      "I modified my original hard-coded program, but I should have backed it up since it was working before I made the program variable. The images come off a file with 20x20px cells with 18 cells in total in this case.\n",
      "The images go to the center of the screen like I want, but my for loop is not stacking the images.\n",
      "I've been reviewing the YouTube video I originally watched and going over my code over and over. The best I can get is the whole sprite sheet being draw and stacking, but not the individual images.\n",
      "#def __init__(self) fields\n",
      "#self.windowWidth = 800\n",
      "#self.windowHeight = 600\n",
      "#self.imageScale = 2\n",
      "#self.imageSpacing = 2\n",
      "\n",
      "    def drawImage(self):\n",
      "        imageCells = []\n",
      "\n",
      "        # number of cells determines loop length\n",
      "            for i in range(self.imageWidth // self.imageHeight):\n",
      "            rectangle = pygame.Rect(self.imageWidth * self.imageScale * i, 0, self.imageWidth * self.imageScale, self.imageHeight * self.imageScale)\n",
      "            processedImage = pygame.Surface(rectangle.size)\n",
      "\n",
      "            # draw image\n",
      "            self.window.blit(self.userImage, (self.windowWidth // 2, self.windowHeight // 2 - (self.imageSpacing * i)), rectangle)\n",
      "\n",
      "            # keep alpha\n",
      "            alpha = processedImage.get_at((0, 0))\n",
      "            processedImage.set_colorkey(alpha)\n",
      "            imageCells.append(processedImage)\n",
      "\n",
      "            # update window\n",
      "            pygame.display.flip()\n",
      "\n",
      "I want each increment of i to draw the next cell 2 pixels above the last, instead of drawing the whole sprite sheet left to right.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086131/attributeerror-response-object-has-no-attribute-add-header\n",
      "AttributeError: 'Response' object has no attribute 'add_header'\n",
      "\n",
      "\n",
      "I am new to API calling. I heard that it is simple, but I am struggling to get my script done. \n",
      "I've tried altering the code, however I think I may have screwed things up. I am currently using python 3.6.8 and my packages are installed in a virtual env.\n",
      "import pandas as pd\n",
      "import json\n",
      "import requests\n",
      "\n",
      "df = pd.read_csv('lusha_domain.csv')\n",
      "req = requests.get('https://api.fullcontact.com/v3/company.enrich')\n",
      "req.add_header('Authorization', 'Bearer {xxxxxxx}')\n",
      "data = json.dumps({\n",
      "    'domain': 'fullcontact.com'\n",
      "})\n",
      "\n",
      "response = requests.urlopen(req, data)\n",
      "\n",
      "originals code is below from link(http://docs.fullcontact.com/?python#company-enrichment) \n",
      "import urllib.request, json\n",
      "\n",
      "req = urllib.request.Request('https://api.fullcontact.com/v3/company.enrich')\n",
      "req.add_header('Authorization', 'Bearer {Your API Key}')\n",
      "data = json.dumps({\n",
      "    \"domain\": \"fullcontact.com\"\n",
      "})\n",
      "\n",
      "response = urllib.request.urlopen(req,data)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  line 15, in \n",
      "    req.add_header('Authorization', 'Bearer {xxxxxxx}')\n",
      "AttributeError: 'Response' object has no attribute 'add_header'\n",
      "\n",
      "Answer\n",
      "\n",
      "What is the ouput that you expect to get?\n",
      "The reason of the error is because your response (req variable) has no attribute 'add_header', you can inspect req as below:\n",
      "dir(req)\n",
      "\n",
      "['attrs', 'bool', 'class', 'delattr', 'dict', 'dir', 'doc', 'enter', 'eq', 'exit', 'format', 'ge', 'getattribute', 'getstate', 'gt', 'hash', 'init', 'iter', 'le', 'lt', 'module', 'ne', 'new', 'nonzero', 'reduce', 'reduce_ex', 'repr', 'setattr', 'setstate', 'sizeof', 'str', 'subclasshook', 'weakref', '_content', '_content_consumed', '_next', 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'is_permanent_redirect', 'is_redirect', 'iter_content', 'iter_lines', 'json', 'links', 'next', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url']\n",
      "It seem like the original code is asking you for a token authentication, to send by header. However, you can see the content of your response, e.g:\n",
      "req.content\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086124/writing-data-to-resized-hdf5-dataset-fails-in-surprising-ways\n",
      "Writing data to resized hdf5 dataset fails in surprising ways\n",
      "\n",
      "\n",
      "I'm trying to create a dataset which I don't know the full size of initially.\n",
      "I create my dataset with the following properties.\n",
      "file['data'].create_dataset(\n",
      "   name='test', shape=(10, len(arr1)), \n",
      "   maxshape=(10, None), dtype=float,\n",
      "   scaleoffset=3, chunks=True, \n",
      "   compression='gzip', compression_opts=4, fillvalue=np.nan)\n",
      "\n",
      "where the final dimension in shape is the dimension I need to expand (initial shape given by first input).\n",
      "When I resize the dataset for the arr2, everything works fine, but when I try to extend it to the much larger size for arr3, things start to behave strangely. \n",
      "If I incrementally resize and write each array one after the other, the contents of the dataset becomes corrupted, and values outside of the first arrays length (arr1), in this case 100, are written to the fill value (nan), while the first 100 values are stored correctly. Note that this doesn't happen when resizing and writing arr2, this will correctly write all values of arr2, while extending the first entry with nan.\n",
      "I've also tried manually increasing the chunk size, but this fails at using the correct fill value (defaults to 0, rather than nan) when I write smaller arrays, and unless the chunk size is explicitly larger than the largest array, the largest array is still truncated to the fill value outside of the chunk size.\n",
      "arr1 = np.arange(0, 100, step=1, dtype=float)\n",
      "arr2 = np.arange(0, 233, step=1, dtype=float)\n",
      "arr3 = np.arange(0, 50000, step=1, dtype=float)\n",
      "\n",
      "file = h5py.File(my_data_file, 'w')\n",
      "file.create_group('data')\n",
      "file['data'].create_dataset(\n",
      "   name='test', shape=(10, len(arr1)), \n",
      "   maxshape=(10, None), dtype=float,\n",
      "   scaleoffset=3, chunks=True, \n",
      "   compression='gzip', compression_opts=4, fillvalue=np.nan)\n",
      "\n",
      "file['data']['test'][0, :len(arr1)] = arr1\n",
      "try:\n",
      "    file['data']['test'][1, :len(arr2)] = arr2\n",
      "except TypeError as e:\n",
      "    print('New data too large for old dataset, resizing')\n",
      "    file['data']['test'].resize((10, len(arr2)))\n",
      "    file['data']['test'][1, :len(arr2)] = arr2\n",
      "\n",
      "If I stop here, everything looks as expected, but the main problem arises when I run the following code.\n",
      "try:\n",
      "    file['data']['test'][2, :len(arr3)] = arr3\n",
      "except TypeError as e:\n",
      "    print('New data too large for old dataset, resizing')\n",
      "    file['data']['test'].resize((10, len(arr3)))\n",
      "    file['data']['test'][2, :len(arr3)] = arr3\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086097/how-to-extract-the-corresponding-key-whose-value-contains-the-item-from-a-list\n",
      "How to extract the corresponding key whose value contains the item from a list?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a list and a dictionary. For each item in the list, i want to retrieve the key in the dictionary whose value contains that item.\n",
      "I tried writing the code that takes an item from the list and loops through the dictionary each time to see if the value contains that item and return the key. I think this would be O(n2) complexity.\n",
      "   my_list = [1.1.1.1, 2.2.2.2, 3.3.3.3]\n",
      "   my_dict = {\n",
      "               1234 : '4.4.4.4, 5.5.5.5, 2.2.2.2',\n",
      "               4567 : '6.6.6.6, 7.7.7.7, 1.1.1.1',\n",
      "               8910 : '8.8.8.8, 9.9.9.9, 3.3.3.3'\n",
      "             }\n",
      "   for item in mylist:\n",
      "       for key, value in my_dict.items():\n",
      "             temp_list = value.split(',')\n",
      "             if item in temp_list:\n",
      "                  return key\n",
      "\n",
      "For the item 2.2.2.2, the key 1234 should be returned and so on.\n",
      "Is there a more optimized way to achieve this?\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086076/python-drop-row-which-contains-nanind\n",
      "python drop row which contains -nan(ind)\n",
      "\n",
      "\n",
      "I have one csv file. I use pd.read_csv to import into the dataframe tmp1. Now\n",
      "tmp1 is like below one.How could I delete the rows which contain -nan(ind)? Thanks.\n",
      "    A     B      C     D\n",
      "0  -5     0   -nan(ind)   2.3\n",
      "1  -5     0   25.1   2.3\n",
      "2  -2    12  235.0   6.8\n",
      "3  10  1000  -25.0   8.8\n",
      "4  -4    15   40.0   5.0\n",
      "5  77     7   -8.0  15.8\n",
      "\n",
      "I use \n",
      "tmp1=tmp1.replace(-nan(ind),np.nan)\n",
      "tmp1.dropna()\n",
      "\n",
      "But it gets error:NameError: name 'nan' is not defined.\n",
      "The below is part of my csv file:\n",
      "43222.39444 #NAME?  #NAME?  #NAME?  #NAME?  #NAME?  #NAME?  #NAME?  #NAME?  #NAME?\n",
      "43222.39514 2671    2671    2671    2671    34  27244200    #NAME?  #NAME?  15993\n",
      "43222.39583 2670.8  2672.6  2665    2666.6  351 281012880   -4.4    -0.001647323    15781\n",
      "43222.39653 2667    2668.4  2664.4  2664.6  244 195205080   -2  -0.000750019    15628\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086051/get-lenght-of-searched-output\n",
      "Get lenght of searched output\n",
      "\n",
      "\n",
      "I have a ListView in Django to return all users that match a keyword(username, first_name, last_name) from search bar on my page. \n",
      "Code looks like this \n",
      "class SearchView(ListView):\n",
      "    model = User\n",
      "    template_name = 'blog/list_of_users.html'\n",
      "\n",
      "    def get_context_data(self, **kwargs):\n",
      "        context = super().get_context_data(**kwargs)\n",
      "        user_name = self.request.GET.get('search', '')\n",
      "        if len(user_name) < 1:\n",
      "            context['all_search_results'] = False\n",
      "            return context\n",
      "        context['all_search_results'] = User.objects.filter(username__icontains=user_name ) or User.objects.filter(last_name__icontains=user_name ) or User.objects.filter(first_name__icontains=user_name )\n",
      "        return context\n",
      "\n",
      "And I'm showing in in template this way :\n",
      "{% if not all_search_results %}\n",
      "  <div class=\"alert alert-danger\">\n",
      "    No User\n",
      "  </div>\n",
      "{% else %}\n",
      "  {% for result in all_search_results %}\n",
      "      {{ result.username }}\n",
      "\n",
      "\n",
      "etc.....\n",
      "\n",
      "And I would like to show length(number) of matched results on my template. How should I change my code for that?\n",
      "\n",
      "Answer\n",
      "\n",
      "Since the all_search_results context var contain queryset, you can go for count,\n",
      "{{all_search_results.count}}\n",
      "Since both work\n",
      "{{all_search_results|length}}\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086044/how-do-i-get-free-ports-in-the-specific-range-in-python\n",
      "How do I get free ports in the specific range in python\n",
      "\n",
      "\n",
      "I can use python to get free ports, but I want to get a specific range of free ports. \n",
      "I try to get it using a while loop, but I can't get the vaule I wanted, maybe take a long time\n",
      "import socket\n",
      "\n",
      "SO_BINDTODEVICE=25\n",
      "\n",
      "def get_free_port(iface=None):\n",
      "    s = socket.socket()\n",
      "\n",
      "    if iface:\n",
      "        s.setsockopt(socket.SOL_SOCKET, SO_BINDTODEVICE, bytes(iface,'utf8'))\n",
      "\n",
      "    s.bind(('',0))\n",
      "    port = 0\n",
      "    while(port<60100 or port>60300):\n",
      "        ip = s.getsockname()[0]\n",
      "        port = s.getsockname()[1]\n",
      "    s.close()\n",
      "\n",
      "    return ip,port\n",
      "\n",
      "\n",
      "print(get_free_port())\n",
      "\n",
      "I hope to get the port I want in a short time\n",
      "\n",
      "Answer\n",
      "\n",
      "def next_free_port( port=1024, max_port=65535 ):\n",
      "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
      "    while port <= max_port:\n",
      "        try:\n",
      "            sock.bind(('', port))\n",
      "            sock.close()\n",
      "            return port\n",
      "        except OSError:\n",
      "            port += 1\n",
      "    raise IOError('no free ports')\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086036/simulating-the-transition-of-packages-in-a-distribution-line\n",
      "Simulating the transition of packages in a distribution line\n",
      "\n",
      "\n",
      "I am new to python and am trying to run a simulation of a warehouse logistics. The problem is composed of four main agents:\n",
      "a shed, trucks, motorcycles and a distribution line. The truck enters the shed in one side with a specified amount of boxes, it goes to center of the shed, stops and start unloading the boxes to the distribution line, the distribution line moves the boxes to the other side of the shed where motorcycles pickup one box each. \n",
      "The objective is to vary the size of the shed and distribution line to find the shape that can deliver more boxes in fixed amount of time (or compute the time taken to distribute a fixed amount of boxes, as in my code for now)\n",
      "The distribution line is a rectangle, a grid with variable amount of rows and columns, depending on the size of the shed, let's say each cell has 0,50m on each side. \n",
      "In the code I simulated the truck passing through the shed, and the amount of trucks passing as iterations, the problems is:\n",
      "how to simulate the boxes moving through the grid (distribution line) from one side to the other, maybe accumulating in the stock until a bike arrives, and have the motorcycles \"grab\" them and go out after the boxes arrive?\n",
      "I tried to count the boxes with \"+= 1\" function but I don't know why it's not working (would not be very realistic as well)\n",
      "This is the main code:\n",
      "import time\n",
      "from Vehicles import Truck, Motorbike\n",
      "\n",
      "bike1 = Motorbike(10, 1)\n",
      "truck1 = Truck(10, int(input(\"Enter how many loads the truck has: \")))\n",
      "num_iterations = int(input(\"Enter number of iterations: \"))\n",
      "\n",
      "start = time.time()\n",
      "\n",
      "shed_width = 4\n",
      "shed_length = 12\n",
      "truck_path = int(shed_length * truck1.truck_speed/2)\n",
      "\n",
      "for n in range(num_iterations):\n",
      "    truck_middle = False\n",
      "    while truck_middle is not True:\n",
      "        for i in range(truck_path):\n",
      "            x = 100/truck_path\n",
      "            if i == truck_path/2:\n",
      "                truck_middle = True\n",
      "            else:\n",
      "    #the bar here is to just have some visual feedback while the code runs\n",
      "                print(\"\\r[%-60s] %d%%\" % ('=' * i, x * i), end='')\n",
      "                time.sleep(0.1)\n",
      "\n",
      "        print(\"\\ntruck is in the middle\")\n",
      "        truck_middle = True\n",
      "\n",
      "    # while truck_middle is True:\n",
      "    #     box = 0\n",
      "    #     if box < truck1.truck_load:\n",
      "    #         box += 1\n",
      "    #     else:\n",
      "    #         truck_middle = False\n",
      "    print(\"This was iteration: \" + str(n+1))\n",
      "    time.sleep(0.01)\n",
      "\n",
      "\n",
      "end = time.time()\n",
      "\n",
      "print(\"\\nDone! \\nThe simulation took \" + str(end - start) + \" seconds to complete!\")\n",
      "\n",
      "\n",
      "I also created a class in a file called \"Vehicles\" for the truck and the motorcycles, where I can define their speed and the load they can carry:\n",
      "class Truck:\n",
      "    def __init__(self, truck_speed, truck_load):\n",
      "        self.truck_speed = truck_speed\n",
      "        self.truck_load = truck_load\n",
      "\n",
      "class Motorbike:\n",
      "    def __init__(self, motorbike_speed, motorbike_load):\n",
      "        self.motorbike_speed = motorbike_speed\n",
      "        self.motorbike_load = motorbike_load\n",
      "\n",
      "I am open to code suggestions, indications of libraries and other resources I can search and study, any help will be much appreciated! thanks!\n",
      "\n",
      "Answer\n",
      "\n",
      "box = 0\n",
      "while truck_middle == True:\n",
      "\n",
      "    if box < truck1.truck_load:\n",
      "        box += 1\n",
      "    else:\n",
      "        truck_middle = False\n",
      "\n",
      "In your way, box will always be 1 and truck_middle is always  True, and it goes in a dead loop\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086033/python-pandas-dataframe-error-dataframe-object-has-no-attribute-dataframe\n",
      "python pandas dataframe error 'DataFrame' object has no attribute 'DataFrame'\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I read csv file and write a code, but this code have a error.\n",
      "list_PAL is Dataframe code that have Patient Sex, and PatientAge information.\n",
      "for i, fil in enumerate(list_PAL):\n",
      "print(type(fil))\n",
      "if fil.empty == True:\n",
      "    fil.DataFrame({\"PatientAge\" : [np.nan, np.nan], \"Patient Sex\" : [M,F]})\n",
      "elif fil.empty == False:\n",
      "    if (fil[fil['Patient Sex'] == 'M'].empty == True &\n",
      "        fil[fil['Patient Sex'] == 'F'].empty == False):\n",
      "        fil.DataFrame({\"PatientAge\" : [np.nan], \"Patient Sex\" : ['M']})\n",
      "    elif (fil[fil['Patient Sex'] == 'M'].empty == False &\n",
      "          fil[fil['Patient Sex'] == 'F'].empty == True):\n",
      "        fil.DataFrame({\"PatientAge\" : [np.nan], \"Patient Sex\" : ['F']})\n",
      "    elif (fil[fil['Patient Sex'] == 'M'].empty == True &\n",
      "          fil[fil['Patient Sex'] == 'F'].empty == True):\n",
      "        fil\n",
      "list_PAL[i] = fil\n",
      "\n",
      "line 4 fil.DataFrame({\"PatientAge\" : [np.nan], \"Patient Sex\" : ['M']}) this code have an error\n",
      "\n",
      "AttributeError: 'DataFrame' object has no attribute 'DataFrame'\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086011/2019-07-17t000000-000000000z-does-not-match-format-y-m-dthms-fz\n",
      "'2019-07-17T00:00:00.000000000Z' does not match format '%Y-%m-%dT%H:%M:%S.%fZ'\n",
      "\n",
      "\n",
      "I have checked this line over and over and cannot find where the mismatch is on this error. Maybe another set of eyes can tell me?\n",
      "ValueError: time data \n",
      "'2019-07-17T00:00:00.000000000Z' does not match format '%Y-%m-%dT%H:%M:%S.%fZ'\n",
      "\n",
      "Where is the mismatch?\n",
      "**UPDATE*****\n",
      "The 2019-07-17T00:00:00.000000000Z is part of a JSON stream:\n",
      "{\n",
      "  \"volume\": 82, \n",
      "  \"mid\": {\n",
      "    \"h\": \"1.12286\", \n",
      "    \"c\": \"1.12272\", \n",
      "    \"l\": \"1.12267\", \n",
      "    \"o\": \"1.12274\"\n",
      "  }, \n",
      "  \"complete\": true, \n",
      "  \"time\": \"2019-07-17T23:00:00.000000000Z\"\n",
      "}, \n",
      "{\n",
      "  \"volume\": 10, \n",
      "  \"mid\": {\n",
      "    \"h\": \"1.12284\", \n",
      "    \"c\": \"1.12272\", \n",
      "    \"l\": \"1.12272\", \n",
      "    \"o\": \"1.12274\"\n",
      "  }, \n",
      "  \"complete\": false, \n",
      "  \"time\": \"2019-07-18T00:00:00.000000000Z\"\n",
      "}\n",
      "\n",
      "This is exactly as received, and I am sending the time value into this function:\n",
      "time.mktime(time.strptime(str(json['time']), '%Y-%m-%dT%H:%M:%S.%fZ')))\n",
      "\n",
      "Answer\n",
      "\n",
      "The documentation has a note about %f (to be fair a footnote):\n",
      "\n",
      "When used with the strptime() method, the %f directive accepts from one to six digits and zero pads on the right. %f is an extension to the set of format characters in the C standard (but implemented separately in datetime objects, and therefore always available).\n",
      "\n",
      "If you remove some of the zeros from the microseconds the format string works fine:\n",
      "datetime.strptime('2019-07-17T00:00:00.000000Z', '%Y-%m-%dT%H:%M:%S.%fZ')\n",
      "# datetime.datetime(2019, 7, 17, 0, 0)\n",
      "It is a problem you can find out by yourselves simply by adjusting the date and format:\n",
      "Fail:\n",
      "d = datetime.strptime(\"2019-07-17T00:00:00.000000000Z\", \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
      "\n",
      "Success:\n",
      "d = datetime.strptime(\"2019-07-17T00:00:00\", \"%Y-%m-%dT%H:%M:%S\")\n",
      "\n",
      "Which means the problem comes from the %fZ part.\n",
      "From Python document, %f means microsecond which means 6 digits.\n",
      "d = datetime.strptime(\"2019-07-17T00:00:00.000000Z\", \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
      "\n",
      "That's the above will work\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57086009/valueerror-attempted-relative-import-beyond-top-level-package-despite-pycharm-a\n",
      "ValueError attempted relative import beyond top-level package, despite PyCharm autofilling suggestions\n",
      "\n",
      "\n",
      "I am attempting to import a model from a sibling package and am getting\n",
      "ValueError: attempted relative import beyond top-level package\n",
      "\n",
      "Strangely, I am auto-filling based on PyCharm suggestions, so the IDE is registering the module, but my build is failing...\n",
      "]1\n",
      "Here is my project structure:\n",
      "app\n",
      " \\\n",
      " +-core\n",
      " |  \\\n",
      " |   +- __init__.py\n",
      " |   +- models.py   <- the Tag model is present here\n",
      " |\n",
      " +-scheduler\n",
      "    \\\n",
      "     +- __init__.py\n",
      "     +- serializers.py  <- importing app.core.models.Tag in this file\n",
      "\n",
      "app.scheduler.serializers.py:\n",
      "from rest_framework import serializers\n",
      "from ..core.models import Tag\n",
      "\n",
      "\n",
      "class TagSerializer(serializers.ModelSerializer):\n",
      "    \"\"\"Serializer for tag objects\"\"\"\n",
      "\n",
      "    class Meta:\n",
      "        model = Tag\n",
      "        fields = ('id', 'name')\n",
      "        read_only_fields = ('id',)\n",
      "\n",
      "I've been scratching my head about this and can't seem to figure it out...\n",
      "I've tried using an absolute path, even adding it using the PyCharm import utility:\n",
      "from rest_framework import serializers\n",
      "from app.core.models import Tag\n",
      "\n",
      "\n",
      "class TagSerializer(serializers.ModelSerializer):\n",
      "    \"\"\"Serializer for tag objects\"\"\"\n",
      "\n",
      "    class Meta:\n",
      "        model = Tag\n",
      "        fields = ('id', 'name')\n",
      "        read_only_fields = ('id',)\n",
      "\n",
      "but then I get:\n",
      "ModuleNotFoundError: No module named 'app.core'\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085979/how-to-authenticate-a-user-in-a-unit-test-for-the-django-admin-page\n",
      "How to authenticate a user in a unit test for the Django admin page?\n",
      "\n",
      "\n",
      "I'm trying to adapt the answer from Testing custom admin actions in django, but I'm running into some unexpected behavior. I've created a simplified Django app, myapp, which has a Worker and Invoice model:\n",
      "class Worker(models.Model):\n",
      "    name = models.CharField(max_length=255)\n",
      "\n",
      "\n",
      "class Invoice(models.Model):\n",
      "    UNPAID = 0\n",
      "    PAID = 1\n",
      "\n",
      "    worker = models.ForeignKey(\n",
      "        'Worker', on_delete=models.CASCADE)\n",
      "    amount = models.DecimalField(\n",
      "        max_digits=10, decimal_places=2)\n",
      "    amount_paid = models.DecimalField(\n",
      "        max_digits=10, decimal_places=2, default=Decimal('0.00'))\n",
      "    status = models.IntegerField(\n",
      "        choices=[(UNPAID, 'Unpaid'), (PAID, 'Paid')], default=0)\n",
      "\n",
      "I've create a custom admin action called mark_as_paid which changes the status of the selected invoices to Invoice.PAID in admin.py:\n",
      "from django.contrib import admin\n",
      "from django.db.models import F\n",
      "\n",
      "from .models import Invoice\n",
      "\n",
      "\n",
      "@admin.register(Invoice)\n",
      "class InvoiceAdmin(admin.ModelAdmin):\n",
      "    list_display = ('worker', 'status', 'amount', 'amount_paid')\n",
      "    actions = ['mark_as_paid']\n",
      "\n",
      "    def mark_as_paid(self, request, queryset):\n",
      "        queryset.update(amount_paid=F('amount'))\n",
      "\n",
      "I'm trying to test this like so:\n",
      "from decimal import Decimal\n",
      "\n",
      "from django.contrib import admin\n",
      "from django.contrib.auth.models import User\n",
      "from django.test import TestCase\n",
      "from django.urls import reverse\n",
      "\n",
      "from myapp.models import Invoice, Worker\n",
      "\n",
      "\n",
      "class InvoiceAdminTests(TestCase):\n",
      "    def setUp(self):\n",
      "        self.user = User.objects.create_user(\n",
      "            username='foobar',\n",
      "            email='foo@bar.com',\n",
      "            password='barbaz',\n",
      "            is_superuser=True)\n",
      "        self.client.force_login(user=self.user)\n",
      "\n",
      "    def test_mark_as_paid(self):\n",
      "        worker = Worker.objects.create(name=\"John Doe\")\n",
      "        invoice = Invoice.objects.create(\n",
      "            worker=worker, amount=Decimal('100.00'))\n",
      "\n",
      "        response = self.client.post(\n",
      "            reverse('admin:myapp_invoice_changelist'),\n",
      "            data={\n",
      "                'action': 'mark_as_paid',\n",
      "                admin.ACTION_CHECKBOX_NAME: [invoice.id]})\n",
      "\n",
      "        import ipdb; ipdb.set_trace()\n",
      "\n",
      "        invoice.refresh_from_db()\n",
      "        self.assertEqual(invoice.amount_paid, Decimal('100.00'))\n",
      "\n",
      "I've set a debugger trace in the test, but ultimately I would expect it to pass. Currently, however, it is failing because invoice.amount_paid is still Decimal('0.00').\n",
      "Strangely, the response has a status code of 302 (not 200) and empty content:\n",
      "ipdb> response.status_code                                                               \n",
      "302\n",
      "ipdb> response.content                                                                   \n",
      "b''\n",
      "\n",
      "I've also set a trace in the mark_as_paid() method and it's not getting hit, so I suspect there is something wrong about the way I'm mocking the authentication of the user, since if I create a superuser with python manage.py createsuperuser and test this manually, everything works as expected.\n",
      "Any idea what is wrong with this approach?\n",
      "\n",
      "Answer\n",
      "\n",
      "Looking at the example at Testing custom admin actions in django more closely, it turns out I need to user the create_superuser() method instead of create_user() with is_superuser=True. The test passes with the following modified setUp() method:\n",
      "class InvoiceAdminTests(TestCase):\n",
      "    def setUp(self):\n",
      "        self.user = User.objects.create_superuser(\n",
      "            username='foobar',\n",
      "            email='foo@bar.com',\n",
      "            password='barbaz')\n",
      "        self.client.force_login(user=self.user)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085978/from-collection-of-strings-i-need-to-extract-specific-string-and-write-it-into-t\n",
      "From collection of strings i need to extract specific string and write it into the CSV file, specifically into columns\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like to extract a specific string from a collections of string and write that specific string value into CSV file columns. Also the append operation. At the same time if duplicate column name found, we need to write it only once into the column.\n",
      "\n",
      "From below example, i would like to extract keywords surrounded by ${} and write it into the CSV column. At the same there repeats of ${one} exists, in this scenario i need to check for duplicates and write it only once, if already exists then eliminate that keyword / string and move on to the next.\n",
      "\n",
      "Example:\n",
      "/function/${one}\n",
      "/functions/one/${two}\n",
      "/functions/${one}/${three}\n",
      "\n",
      "Thanks in advance !\n",
      "By referring the example from problem statement, the output expected as below,\n",
      "\n",
      "Column 1 in CSV file should hold - one\n",
      "Column 2 in CSV file should hold - two\n",
      "Column 3 in CSV file should hols - three\n",
      "\n",
      "NOTE: while writing the string value into the CSV columns, i would like to check for the duplicates as well.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085933/trying-to-use-a-canvas-oval-item-as-a-status-indicator\n",
      "Trying to use a canvas oval item as a status indicator\n",
      "\n",
      "\n",
      "I am trying to color the canvas oval item, indicating when the program is busy (status indicator). The expected behavior is to turn the canvas oval red when clicking the check button, and turn it back off (to blue ) when the function is complete.\n",
      "Here is the code I have so far\n",
      "class App(tk.Tk):\n",
      "    def __init__(self):  \n",
      "        tk.Tk.__init__(self)\n",
      "        self.entryframe = Frame(self, width=800, height=500)\n",
      "        self.entryframe.pack(fill=X, padx=8, pady=8)\n",
      "        self.canvas = Canvas(self.entryframe, width=30, height=30)\n",
      "        # change fill color of the status oval\n",
      "        self.status = self.canvas.create_oval(10, 10, 30, 30, fill=\"blue\", tags=\"state\")\n",
      "        self.canvas.grid(row=0, column=1)\n",
      "        self.label = Label(self.entryframe, text=\"Enter your sentence:\").grid(row=3, column=0, sticky=W)\n",
      "        self.text = Text(self.entryframe, wrap=WORD, width=70, height=10)\n",
      "        self.text.grid(row=4, column=0, sticky=W)\n",
      "        self.btn_h = Button(self.entryframe, text=\"Check\", width=\"15\", command=self.check_input).grid(row=5, column=0, padx=8, pady=8)\n",
      "\n",
      "    def check_input(self):\n",
      "        #change status oval color to red\n",
      "        self.canvas.itemconfig(status, fill='red')\n",
      "\n",
      "        # after the function is complete turn it back off\n",
      "        canvas.itemconfig(light_1, fill='blue')\n",
      "\n",
      "root = App()\n",
      "root.mainloop()\n",
      "\n",
      "The current behavior is the item stays blue color, and does not change at all.\n",
      "\n",
      "Answer\n",
      "\n",
      "You saved the reference to the oval as a class attribute. So you will need to access it the same way by passing self:\n",
      "import tkinter as tk\n",
      "\n",
      "class App(tk.Tk):\n",
      "    def __init__(self):\n",
      "        tk.Tk.__init__(self)\n",
      "        self.entryframe = tk.Frame(self, width=800, height=500)\n",
      "        self.entryframe.pack(fill=tk.X, padx=8, pady=8)\n",
      "        self.canvas = tk.Canvas(self.entryframe, width=30, height=30)\n",
      "        # change fill color of the status oval\n",
      "        self.status = self.canvas.create_oval(10, 10, 30, 30, fill=\"blue\", tags=\"state\")\n",
      "        self.canvas.grid(row=0, column=1)\n",
      "        self.label = tk.Label(self.entryframe, text=\"Enter your sentence:\").grid(row=3, column=0, sticky=tk.W)\n",
      "        self.text = tk.Text(self.entryframe, wrap=tk.WORD, width=70, height=10)\n",
      "        self.text.grid(row=4, column=0, sticky=tk.W)\n",
      "        self.btn_h = tk.Button(self.entryframe, text=\"Check\", width=\"15\", command=self.check_input).grid(row=5, column=0, padx=8, pady=8)\n",
      "\n",
      "    def check_input(self):\n",
      "        #change status oval color to red\n",
      "        self.canvas.itemconfig(self.status, fill='red') #use self.status instead\n",
      "\n",
      "        # after the function is complete turn it back off\n",
      "        root.after(2000, lambda: self.canvas.itemconfig(self.status, fill='blue'))\n",
      "\n",
      "root = App()\n",
      "root.mainloop()\n",
      "\n",
      "Also, judging from how you inherit the instance of tk and create the rest of the widgets, it looks like you have a mix of both import tkinter as tk and from tkinter import *. This is generally considered bad practice - it is more reasonable to simply use import tkinter as tk so you know which widgets belong to tk, and which belongs to ttk if required. Also read Why is “import *” bad?\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085931/finding-percentage-difference-between-difference-values-and-the-target\n",
      "Finding percentage difference between 'difference values' and the target\n",
      "\n",
      "\n",
      "I want to find percentage difference between difference values against its target threshold. I have a time series data frame shown below. Where i first need to find difference between date columns, and then Calculate the percentage difference between its target and difference values for every row.\n",
      "Code:\n",
      "import pandas as pd \n",
      "\n",
      "# Create sample dataframe\n",
      "raw_data = {'ID': ['A1', 'B1', 'C1', 'D1'], \n",
      "  'Domain': ['Finance', 'IT', 'IT', 'Finance'], \n",
      "  'Target': [1, 2, 3, 0.9%], \n",
      "  'Criteria':['<=', '<=', '>=', '>='],\n",
      "  \"1/01\":[0.9, 1.1, 2.1, 1],\n",
      "  \"1/02\":[0.4, 0.3, 0.5, 0.9], \n",
      "  \"1/03\":[1, 1, 4, 1.1], \n",
      "  \"1/04\":[0.7, 0.7, 0.1, 0.7],\n",
      "  \"1/05\":[0.7, 0.7, 0.1, 1], \n",
      "  \"1/06\":[0.9, 1.1, 2.1, 0.6],}\n",
      "\n",
      "df = pd.DataFrame(raw_data, columns = ['ID', 'Domain', 'Target','Criteria', '1/01', \n",
      "  '1/02','1/03', '1/04','1/05', '1/06'])\n",
      "\n",
      "   ID   Domain  Target Criteria  1/01  1/02  1/03  1/04  1/05  1/06  \n",
      "0  A1  Finance       1       <=   0.9   0.4   1.0   0.7   0.7   0.9  \n",
      "1  B1       IT       2       <=   1.1   0.3   1.0   0.7   0.7   1.1  \n",
      "2  C1       IT       3       >=   2.1   0.5   4.0   0.1   0.1   2.1  \n",
      "3  D1  Finance     0.9%      >=   1.0   0.9   1.1   0.7   1.0   0.6\n",
      "\n",
      "I managed to find the difference between columns. However, to calculate the percentage difference between difference values, the code shown below I could only manage to assign up to target values. \n",
      "#Finding difference between columns\n",
      "date_columns = df.iloc[:,4:]\n",
      "diff_col = np.abs(np.diff(df[date_columns].values))\n",
      "\n",
      "#Finding percentage difference between difference values \n",
      "target = df[['Target']].values\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085921/is-possible-repeat-a-predefined-message-class\n",
      "Is possible repeat a predefined message class?\n",
      "\n",
      "\n",
      "Hi I am trying decoding NAV-SAT ublox frame, I found a nice parser here a link!, and work perfect with fixed length frame for example problem NAV-sAT frame is variable lenght,and depends of satellite numbers so if I have 3 sats I need tha predefined messagle class repeat the block\n",
      "I tried coding for inside of list but, not working\n",
      "Is just a example NAV-SAT is bigger, here definition of the frame [1]https://ibb.co/BVH61D3 \"tooltip\"\n",
      "Blockquote\n",
      "ACK_CLS = core.Cls(0x05, 'ACK', [\n",
      "    core.Message(0x01, 'ACK', [\n",
      "        core.Field('clsID', 'U1'),\n",
      "        core.Field('msgID', 'U1'),\n",
      "    ]),\n",
      "    core.Message(0x01, 'NAK', [\n",
      "        core.Field('clsID', 'U1'),\n",
      "        core.Field('msgID', 'U1'),\n",
      "    ])\n",
      "])\n",
      "\n",
      "I expect that the predefined message addapt to the length of sats\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085903/how-do-i-upload-images-on-my-computer-to-pycharm\n",
      "How do I upload images on my computer to PyCharm?\n",
      "\n",
      "\n",
      "I'm currently learning how to use Pygame and I am having a little trouble uploading images from my computer folders to PyCharm. I'm using a Macbook by the way.\n",
      "The error I keep getting is \"pygame.error: Couldn't open R1.png\".\n",
      "import pygame\n",
      "\n",
      "pygame.init()\n",
      "win = pygame.display.set_mode([500, 500])\n",
      "\n",
      "pygame.display.set_caption(\"First Game\")\n",
      "\n",
      "screenWidth = 500\n",
      "\n",
      "walkRight = [\n",
      "    pygame.image.load(\"R1.png\"),\n",
      "    pygame.image.load(\"R2.png\"),\n",
      "    pygame.image.load(\"R3.png\"), \n",
      "    pygame.image.load(\"R4.png\"),\n",
      "    pygame.image.load(\"R5.png\"), \n",
      "    pygame.image.load(\"R6.png\"),\n",
      "    pygame.image.load(\"R7.png\"), \n",
      "    pygame.image.load(\"R8.png\"),\n",
      "    pygame.image.load(\"R9.png\")\n",
      "]\n",
      "walkLeft = [\n",
      "    pygame.image.load(\"L1.png\"),\n",
      "    pygame.image.load(\"L2.png\"), \n",
      "    pygame.image.load(\"L3.png\"),\n",
      "    pygame.image.load(\"L4.png\"), \n",
      "    pygame.image.load(\"L5.png\"),\n",
      "    pygame.image.load(\"L6.png\"), \n",
      "    pygame.image.load(\"L7.png\"),\n",
      "    pygame.image.load(\"L8.png\"), \n",
      "    pygame.image.load(\"L9.png\")\n",
      "]\n",
      "bg = pygame.image.load(\"bg.jpg\")\n",
      "char = pygame.image.load(\"standing.png\")\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085897/python-logistic-regression-max-iter-parameter-is-reducing-the-accuracy\n",
      "Python: Logistic regression max_iter parameter is reducing the accuracy\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing multiclass/multilabel text classification. I trying to get rid of the \"ConvergenceWarning\". \n",
      "When I tuned the max_iter from default to 4000, the warning is disappeared. However, my model accuracy is reduced from 78 to 75. \n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "logreg = Pipeline([('vect', CountVectorizer()),\n",
      "            ('tfidf', TfidfTransformer()),\n",
      "            ('clf', LogisticRegression(n_jobs=1, C=1e5, solver='lbfgs',multi_class='ovr' ,random_state=0, class_weight='balanced' )),\n",
      "           ])\n",
      "logreg.fit(X_train, y_train)\n",
      "\n",
      "\n",
      "y_pred = logreg.predict(X_test)\n",
      "\n",
      "print('Logistic Regression Accuracy %s' % accuracy_score(y_pred, y_test))\n",
      "\n",
      "cv_score = cross_val_score(logreg, train_tfidf, y_train, cv=10, scoring='accuracy')\n",
      "print(\"CV Score : Mean : %.7g | Std : %.7g | Min : %.7g | Max : %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
      "\n",
      "Why my accuracy is reducing when max_iter =4000?\n",
      "Is there any other way to fix \n",
      "* \"ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations. \"of iterations.\", ConvergenceWarning)\" *\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085878/python-threading-threads-runs-twice\n",
      "Python threading : Threads runs twice?\n",
      "\n",
      "\n",
      "I'm totally new to python, I was trying threading module when I faced this problem:\n",
      "-Threads runs twice for some reason, and I have no idea why. I searched everywhere, but didn't manage to find any answer.\n",
      "Hopefully I can get some help here\n",
      "import time\n",
      "from threading import Thread\n",
      "import requests as requests\n",
      "import threading as threading \n",
      "\n",
      "\n",
      "threads = []\n",
      "i = 0\n",
      "time.sleep(0.5)\n",
      "def whatever():\n",
      "    global i\n",
      "    while i < 10:\n",
      "        get = requests.get(\"http://www.exemple.com\")\n",
      "        print(i)\n",
      "        i += 1\n",
      "\n",
      "for t in range(5):\n",
      "    t = threading.Thread(target=whatever)\n",
      "    threads.append(t)\n",
      "    t.start()\n",
      "\n",
      "What i want:\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "\n",
      "output:\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "\n",
      "Answer\n",
      "\n",
      "Modifying a global variable from multiple threads is inherently unsafe. You need to lock access to prevent a race condition, like thread A reading i, then thread B running and incrementing i and storing it back, then thread A coming back in and storing back its incremented copy of i, so instead of being incremented twice, it's only incremented once.\n",
      "The fix is to either lock access, or come up with an innately thread-safe way of doing what you want. On the CPython reference interpreter, you're guaranteed no GIL releases between bytecodes, so there are tricks to do this without a lock:\n",
      "import time\n",
      "from threading import Thread\n",
      "\n",
      "threads = []\n",
      "igen = iter(range(10))\n",
      "time.sleep(0.5)\n",
      "def whatever():\n",
      "    for i in igen:\n",
      "        get = requests.get(\"http://www.exemple.com\")\n",
      "        print(i)\n",
      "\n",
      "for t in range(5):\n",
      "    t = threading.Thread(target=whatever)\n",
      "    threads.append(t)\n",
      "    t.start()\n",
      "\n",
      "Using a lock is more complicated, but should be portable to any Python interpreter with predictable(ish, it's still threading after all) behavior:\n",
      "import time\n",
      "from threading import Thread, Lock\n",
      "\n",
      "threads = []\n",
      "i = 0\n",
      "ilock = Lock()\n",
      "time.sleep(0.5)\n",
      "def whatever():\n",
      "    global i\n",
      "    while True:\n",
      "        with ilock:\n",
      "            if i >= 10:\n",
      "                break\n",
      "            icopy = i\n",
      "            i += 1\n",
      "        get = requests.get(\"http://www.exemple.com\")\n",
      "        print(icopy)\n",
      "\n",
      "for t in range(5):\n",
      "    t = threading.Thread(target=whatever)\n",
      "    threads.append(t)\n",
      "    t.start()\n",
      "\n",
      "This won't print out in numerical order, but it will run the requests in parallel, and it will only print out any given value for i once.\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085874/why-do-i-need-to-use-asynchronous-tools-for-sending-django-email\n",
      "Why do I need to use asynchronous tools for sending Django email\n",
      "\n",
      "\n",
      "While using Django, I had noticed when I send an ​email there is a delay and to overcome this I had to use Celery tool. So I wanted to know what is actually happening under the hood. Why does Django/Python need an async tool to accomplish this task. I have learned about MultiThreading, MultiProcessing in Python but if somebody could give me a brief idea about what exactly is happening when Django is trying to send an email without using Celery.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085870/python-xml-rpc-tcp-persistent-connection\n",
      "Python xml-rpc tcp persistent connection\n",
      "\n",
      "\n",
      "I'm using Python's xml-rpc server to handle client/server requests, and noticed like many others who have used xml-rpc libraries that the client by default uses a new TCP connection for every request.  Is there a way to get it to keep reusing the same TCP connection so that the TLS handshake doesn't have to be performed for each TCP connection?  I've read similar questions on many forums, but haven't found a solution yet.\n",
      "\n",
      "Answer\n",
      "\n",
      "no answer\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085868/using-matplotlib-how-do-i-scale-the-x-y-axes-of-a-bubble-scatter-plot-to-repr\n",
      "Using matplotlib, how do I scale the x/y axes of a bubble (scatter) plot to represent the size of the bubbles? [duplicate]\n",
      "\n",
      "\n",
      "I would like to scale the markersize of matplotlib.pyplot.Axes.scatter plot based on the number of points on the x/y-axis.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "vmin = 1\n",
      "vmax = 11\n",
      "\n",
      "x = np.random.randint(vmin, vmax, 5)\n",
      "y = np.random.randint(vmin, vmax, 5)\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "for v in np.arange(vmin, vmax):\n",
      "    ax.axvline(v - 0.5)\n",
      "    ax.axvline(v + 0.5)\n",
      "    ax.axhline(v - 0.5)\n",
      "    ax.axhline(v + 0.5)\n",
      "\n",
      "ax.set_xlim(vmin - 0.5, vmax + 0.5)\n",
      "ax.set_ylim(vmin - 0.5, vmax + 0.5)\n",
      "ax.scatter(x, y)\n",
      "\n",
      "ax.set_aspect(1)\n",
      "plt.show()\n",
      "\n",
      "ax is always using an equal aspect ratio and both axes have the same lim values. \n",
      "Currently, running the above generates the following plot ...\n",
      "\n",
      "...and changing the value of vmax = 41\n",
      "\n",
      "The markersize in both plots is left to the default, i.e. markersize=6. \n",
      "My question is, how could I compute the markersize value so the markers touch the edges of each cell? (Each cell has a maximum of one data point.)\n",
      "\n",
      "Answer\n",
      "\n",
      "Using Circles\n",
      "An easy option is to replace the scatter by a PatchCollection consisting of Circles of radius 0.5.\n",
      "circles = [plt.Circle((xi,yi), radius=0.5, linewidth=0) for xi,yi in zip(x,y)]\n",
      "c = matplotlib.collections.PatchCollection(circles)\n",
      "ax.add_collection(c)\n",
      "\n",
      "\n",
      "Using scatter with markers of size in data units\n",
      "The alternative, if a scatter plot is desired, would be to update the markersize to be in data units. \n",
      "The easy solution here would be to first draw the figure once, then take the axes size and calculate the markersize in points from it.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "vmin = 1\n",
      "vmax = 11\n",
      "\n",
      "x = np.random.randint(vmin, vmax, 5)\n",
      "y = np.random.randint(vmin, vmax, 5)\n",
      "\n",
      "fig, ax = plt.subplots(dpi=141)\n",
      "for v in np.arange(vmin, vmax):\n",
      "    ax.axvline(v - 0.5)\n",
      "    ax.axvline(v + 0.5)\n",
      "    ax.axhline(v - 0.5)\n",
      "    ax.axhline(v + 0.5)\n",
      "\n",
      "ax.set_xlim(vmin - 0.5, vmax + 0.5)\n",
      "ax.set_ylim(vmin - 0.5, vmax + 0.5)\n",
      "\n",
      "ax.set_aspect(1)\n",
      "fig.canvas.draw()\n",
      "s = ((ax.get_window_extent().width  / (vmax-vmin+1.) * 72./fig.dpi) ** 2)\n",
      "\n",
      "ax.scatter(x, y, s = s, linewidth=0)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "For some background on how markersize of scatters is used, see e.g. this answer. The drawback of the above solution is that is fixes the marker size to the size and state of the plot. In case the axes limits would change or the plot is zoomed, the scatter plot would again have the wrong sizing. \n",
      "Hence the following solution would be more generic.\n",
      "This is a little involved and would work similarly as Plotting a line with width in data units.\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "vmin = 1\n",
      "vmax = 32\n",
      "\n",
      "x = np.random.randint(vmin, vmax, 5)\n",
      "y = np.random.randint(vmin, vmax, 5)\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "for v in np.arange(vmin, vmax):\n",
      "    ax.axvline(v - 0.5)\n",
      "    ax.axvline(v + 0.5)\n",
      "    ax.axhline(v - 0.5)\n",
      "    ax.axhline(v + 0.5)\n",
      "\n",
      "ax.set_xlim(vmin - 0.5, vmax + 0.5)\n",
      "ax.set_ylim(vmin - 0.5, vmax + 0.5)\n",
      "\n",
      "class scatter():\n",
      "    def __init__(self,x,y,ax,size=1,**kwargs):\n",
      "        self.n = len(x)\n",
      "        self.ax = ax\n",
      "        self.ax.figure.canvas.draw()\n",
      "        self.size_data=size\n",
      "        self.size = size\n",
      "        self.sc = ax.scatter(x,y,s=self.size,**kwargs)\n",
      "        self._resize()\n",
      "        self.cid = ax.figure.canvas.mpl_connect('draw_event', self._resize)\n",
      "\n",
      "    def _resize(self,event=None):\n",
      "        ppd=72./self.ax.figure.dpi\n",
      "        trans = self.ax.transData.transform\n",
      "        s =  ((trans((1,self.size_data))-trans((0,0)))*ppd)[1]\n",
      "        if s != self.size:\n",
      "            self.sc.set_sizes(s**2*np.ones(self.n))\n",
      "            self.size = s\n",
      "            self._redraw_later()\n",
      "\n",
      "    def _redraw_later(self):\n",
      "        self.timer = self.ax.figure.canvas.new_timer(interval=10)\n",
      "        self.timer.single_shot = True\n",
      "        self.timer.add_callback(lambda : self.ax.figure.canvas.draw_idle())\n",
      "        self.timer.start()\n",
      "\n",
      "\n",
      "sc = scatter(x,y,ax, linewidth=0)\n",
      "\n",
      "ax.set_aspect(1)\n",
      "plt.show()\n",
      "\n",
      "(I updated the code to use a timer to redraw the canvas, due to this issue)\n",
      "======================================== \n",
      "\n",
      "Question\n",
      "\n",
      "http://stackoverflow.com/questions/57085865/correct-syntax-for-import-statement\n",
      "Correct syntax for import statement\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "page= urlopen(\"https://stackoverflow.com/questions/tagged/python\")\n",
    "document=page.read()\n",
    "soup=BeautifulSoup(document, 'html.parser')\n",
    "questions=soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "# questions=[]\n",
    "for questions in questions_list:\n",
    "    print(\"Question\\n\")\n",
    "    print('http://stackoverflow.com'+questions.get('href'))\n",
    "    print(questions.get_text())\n",
    "    print(\"\\n\")\n",
    "    url='https://stackoverflow.com'+questions.get('href')\n",
    "    response = req.urlopen(url)\n",
    "    soup= BeautifulSoup(response,'html.parser')\n",
    "    for question in soup.select(\"div.postcell div.post-text\"):\n",
    "        print(question.get_text().strip())\n",
    "    print(\"\\nAnswer\\n\")\n",
    "    if len(soup.select(\"div.answercell div.post-text\"))==0:\n",
    "        print('no answer')\n",
    "    else:\n",
    "        for answer in soup.select(\"div.answercell div.post-text\"):\n",
    "            print(answer.get_text().strip())\n",
    "\n",
    "    print('='*40,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"https://kin.naver.com/search/list.nhn?\"\n",
    "tag = input(\"검색어를 입력해주십시오-->\")\n",
    "num = input(\"검색할 페이지 번호를 입력하십시오-->\")\n",
    "temp_url = site + \"sort=none&query=\" + tag \n",
    "temp_url_encode=parse.urlparse(temp_url)\n",
    "query = parse.parse_qs(temp_url_encode.query)\n",
    "query_encode = parse.urlencode(query, doseq=True)\n",
    "\n",
    "url = site+query_encode+\"&section=kin&page=\"+ num\n",
    "\n",
    "#\n",
    "\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "soup = BeautifulSoup(document.decode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "temp_qna = soup.find(class_=\"basic1\")\n",
    "qna_list = temp_qna.select(\"li > dl > dt > a\")\n",
    "\n",
    "for qna in qna_list:\n",
    "    \n",
    "    # 링크 생성\n",
    "    qna_url = qna.attrs[\"href\"]\n",
    "    print(\"=\"*30+\"링크\"+\"=\"*30)\n",
    "    print(qna_url)\n",
    "    \n",
    "    # 링크 읽기\n",
    "    qna_page = urlopen(qna_url.encode(\"ascii\",\"ignore\").decode(\"ascii\",\"ignore\")) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성\n",
    "    soup_qna = BeautifulSoup(qna_document.decode(\"utf-8\"), \"html.parser\")\n",
    "    \n",
    "    # 질문\n",
    "    print(\"*\"*10 + \"질문 제목\")\n",
    "    qna_questions = soup_qna.find(class_=\"question-content__inner\")\n",
    "    \n",
    "    if qna_questions == None:\n",
    "        pass\n",
    "    else:\n",
    "        title_q = qna_questions.select_one(\"div.c-heading > div.c-heading__title > div.c-heading__title-inner > div.title\").text\n",
    "        print(title_q.strip())\n",
    "    \n",
    "    content_q = qna_questions.select_one(\"div.c-heading > div.c-heading__content\")\n",
    "    if content_q == None:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*10 + \"질문 내용\")\n",
    "        print(content_q.text.strip())\n",
    "        \n",
    "    # 답변\n",
    "    qna_answers = soup_qna.find(class_=\"answer-content__inner\")\n",
    "    \n",
    "    title_q_list = qna_answers.select(\"div.c-heading-answer__title > p\")\n",
    "    content_q_list = qna_answers.select(\"div._endContentsText\")\n",
    "    \n",
    "    if title_q == None:\n",
    "        print(\"답변이 없습니다\")\n",
    "    else:\n",
    "        for title_q in title_q_list:\n",
    "            for content_q in content_q_list:\n",
    "                print(\"\\n\")\n",
    "                print(\"+\"*10 + \"답변자\" + \"+\"*10)\n",
    "                print(title_q.text.strip())\n",
    "                print(\"+\"*26)\n",
    "                print(\"\\n\")\n",
    "                print(\"-\"*10 + \"답변 내용\" + \"-\"*10)\n",
    "                print(content_q.text.strip())\n",
    "                print(\"-\"*29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# 검색어 설정\n",
    "tag = input(\"검색어를 입력하십시오-->\")\n",
    "\n",
    "# url 설정 및 url 읽기\n",
    "url = \"https://stackoverflow.com/questions/tagged/\" + tag\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "\n",
    "# 객체 생성 및 파일 읽기\n",
    "soup = BeautifulSoup(document, \"html.parser\")\n",
    "questions = soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "\n",
    "# 메인 알고리즘\n",
    "for questions in questions_list:\n",
    "    \n",
    "    print(\"@\"*50, \"제목\", \"@\"*50)\n",
    "    \n",
    "    # Q&A 질문 요약\n",
    "    print(\"질문\",questions.get_text()) # 조금 더 가벼움!\n",
    "    \n",
    "    # Q&A 링크 생성\n",
    "    print(\"=\"*100)\n",
    "    print(\"링크:\",\"https://stackoverflow.com\"+questions.get(\"href\"))\n",
    "          \n",
    "    \n",
    "    # Q&A 링크 읽기\n",
    "    qna_url=\"https://stackoverflow.com\"+questions.get(\"href\")\n",
    "    qna_page = urlopen(qna_url) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성 및 파일 읽기\n",
    "    soup_qna = BeautifulSoup(qna_document, \"html.parser\")\n",
    "    qna_questions = soup_qna.find(class_=\"question\")\n",
    "    \n",
    "    # 질문 내용 출력\n",
    "    print(\"*\"*50 ,\"질문 내용\", \"*\"*50)\n",
    "    print(qna_questions.select(\"div.post-text\")[0].text)\n",
    "    \n",
    "    # 답변 내용 출력\n",
    "    print(\"*\"*50 ,\"답변 내용\", \"*\"*50)\n",
    "    qna_answers = soup_qna.find(id=\"answers\")\n",
    "    if qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\") == None:\n",
    "        print(\"#\"*50,\"답변이 없습니다\",\"#\"*50)\n",
    "    else:\n",
    "        print(qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\").text)\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib import parse\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# 검색어 설정\n",
    "tag = input(\"검색어를 입력하십시오-->\")\n",
    "\n",
    "# url 설정 및 url 읽기\n",
    "url = \"https://stackoverflow.com/questions/tagged/\" + tag\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "\n",
    "# 객체 생성 및 파일 읽기\n",
    "soup = BeautifulSoup(document, \"html.parser\")\n",
    "questions = soup.find(id=\"questions\")\n",
    "questions_list=questions.find_all(\"a\", class_=\"question-hyperlink\")\n",
    "\n",
    "# 메인 알고리즘\n",
    "for questions in questions_list:\n",
    "    \n",
    "    print(\"@\"*50, \"제목\", \"@\"*50)\n",
    "    \n",
    "    # Q&A 질문 요약\n",
    "    print(\"질문\",questions.get_text()) # 조금 더 가벼움!\n",
    "    \n",
    "    # Q&A 링크 생성\n",
    "    print(\"=\"*100)\n",
    "    print(\"링크:\",\"https://stackoverflow.com\"+questions.get(\"href\"))\n",
    "          \n",
    "    \n",
    "    # Q&A 링크 읽기\n",
    "    qna_url=\"https://stackoverflow.com\"+questions.get(\"href\")\n",
    "    qna_page = urlopen(qna_url) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성 및 파일 읽기\n",
    "    soup_qna = BeautifulSoup(qna_document, \"html.parser\")\n",
    "    qna_questions = soup_qna.find(class_=\"question\")\n",
    "    \n",
    "    # 질문 내용 출력\n",
    "    print(\"*\"*50 ,\"질문 내용\", \"*\"*50)\n",
    "    print(qna_questions.select(\"div.post-text\")[0].text)\n",
    "    \n",
    "    # 답변 내용 출력\n",
    "    print(\"*\"*50 ,\"답변 내용\", \"*\"*50)\n",
    "    qna_answers = soup_qna.find(id=\"answers\")\n",
    "    if qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\") == None:\n",
    "        print(\"#\"*50,\"답변이 없습니다\",\"#\"*50)\n",
    "    else:\n",
    "        print(qna_answers.select_one(\"div.answer > div.post-layout > div.answercell > div.post-text\").text)\n",
    "    print(\"=\"*100)\n",
    "\n",
    "\n",
    "# In[223]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지식인 검색\n",
    "site = \"https://kin.naver.com/search/list.nhn?\"\n",
    "tag = input(\"검색어를 입력해주십시오-->\")\n",
    "num = input(\"검색할 페이지 번호를 입력하십시오-->\")\n",
    "temp_url = site + \"sort=none&query=\" + tag \n",
    "temp_url_encode=parse.urlparse(temp_url)\n",
    "query = parse.parse_qs(temp_url_encode.query)\n",
    "query_encode = parse.urlencode(query, doseq=True)\n",
    "\n",
    "url = site+query_encode+\"&section=kin&page=\"+ num\n",
    "\n",
    "#\n",
    "\n",
    "page = urlopen(url) \n",
    "document = page.read()\n",
    "soup = BeautifulSoup(document.decode(\"utf-8\"), \"html.parser\")\n",
    "\n",
    "temp_qna = soup.find(class_=\"basic1\")\n",
    "qna_list = temp_qna.select(\"li > dl > dt > a\")\n",
    "\n",
    "for qna in qna_list:\n",
    "    \n",
    "    # 링크 생성\n",
    "    qna_url = qna.attrs[\"href\"]\n",
    "    print(\"=\"*30+\"링크\"+\"=\"*30)\n",
    "    print(qna_url)\n",
    "    \n",
    "    # 링크 읽기\n",
    "    qna_page = urlopen(qna_url.encode(\"ascii\",\"ignore\").decode(\"ascii\",\"ignore\")) \n",
    "    qna_document = qna_page.read()\n",
    "    \n",
    "    # 객체 생성\n",
    "    soup_qna = BeautifulSoup(qna_document.decode(\"utf-8\"), \"html.parser\")\n",
    "    \n",
    "    # 질문\n",
    "    print(\"*\"*10 + \"질문 제목\")\n",
    "    qna_questions = soup_qna.find(class_=\"question-content__inner\")\n",
    "    \n",
    "    if qna_questions == None:\n",
    "        pass\n",
    "    else:\n",
    "        title_q = qna_questions.select_one(\"div.c-heading > div.c-heading__title > div.c-heading__title-inner > div.title\").text\n",
    "        print(title_q.strip())\n",
    "    \n",
    "    content_q = qna_questions.select_one(\"div.c-heading > div.c-heading__content\")\n",
    "    if content_q == None:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(\"*\"*10 + \"질문 내용\")\n",
    "        print(content_q.text.strip())\n",
    "        \n",
    "    # 답변\n",
    "    qna_answers = soup_qna.find(class_=\"answer-content__inner\")\n",
    "    \n",
    "    title_q_list = qna_answers.select(\"div.c-heading-answer__title > p\")\n",
    "    content_q_list = qna_answers.select(\"div._endContentsText\")\n",
    "    \n",
    "    if title_q == None:\n",
    "        print(\"답변이 없습니다\")\n",
    "    else:\n",
    "        for title_q in title_q_list:\n",
    "            for content_q in content_q_list:\n",
    "                print(\"\\n\")\n",
    "                print(\"+\"*10 + \"답변자\" + \"+\"*10)\n",
    "                print(title_q.text.strip())\n",
    "                print(\"+\"*26)\n",
    "                print(\"\\n\")\n",
    "                print(\"-\"*10 + \"답변 내용\" + \"-\"*10)\n",
    "                print(content_q.text.strip())\n",
    "                print(\"-\"*29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 -> 수치화(DTM, Word2Vec 등)\n",
    "#문서간 단어들의 차이를 계산? 유클리드, 코사인 유사도 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서1     1         1         0         1\n",
    "# 문서2     1         0         1         1\n",
    "# 문서3     2         0         2         2\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(x,y):\n",
    "     return np.dot(x,y)/(norm(x)*norm(y))\n",
    "    \n",
    "doc1=np.array([1,1,0,1])\n",
    "doc2=np.array([1,0,1,1])\n",
    "doc3=np.array([2,0,2,2])\n",
    "\n",
    "print(cos_sim(doc1, doc2))\n",
    "print(cos_sim(doc1, doc3))\n",
    "print(cos_sim(doc3, doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"movies_metadata.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()['overview']\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#단순 코사인 유사도 기반 계산(연습)\n",
    "tfidf=TfidfVectorizer(stop_words='english')\n",
    "tfidf\n",
    "#data['overview'].isnull().value_counts()\n",
    "data['overview']=data['overview'].fillna('') \n",
    "#NaN의 경우는 ''로 (tfidf 작업시 NaN있으면 에러가 발생)\n",
    "data['overview'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat=tfidf.fit_transform(data['overview'])\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cos_sim=cos_sim):\n",
    "    idx_title=idx[title] # 12356 = idx['Rambo']\n",
    "    sim_score=list(enumerate(cos_sim[idx_title]))\n",
    "    sim_score=sorted(sim_score, key=lambda x:x[1] ,reverse=True)\n",
    "    mi=(sim_score[1:11])\n",
    "    res=[i[0]for i in mi]\n",
    "    print(data['title'].iloc[res])\n",
    "#     print(sim_score[1:11])\n",
    "#     mi=[i[0]for i in sim_score]\n",
    "#     print(mi)\n",
    "#     print(sim_score)\n",
    "#     idx_title #12356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('Rambo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
